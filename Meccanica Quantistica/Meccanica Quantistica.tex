\documentclass[10pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[pagebackref=true]{hyperref}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{latexsym}
\usepackage{fullpage}
\usepackage{quoting}
\usepackage{booktabs}
\theoremstyle{definition}
\newtheorem{thm}{Teorema}[section]
\newtheorem{dfn}{Definizione}[section]
\newtheorem{exm}{Esempio}
\newcommand{\pdev}[3][]{\frac{\partial^{#1} #2}{\partial #3^{#1}}}
\newcommand{\dev}[3][]{\frac{\mathrm{d}^{#1} #2}{\mathrm{d} #3^{#1}}}
\newcommand{\ham}{\mathcal{H}}
\newcommand{\lag}{\mathcal{L}}
\numberwithin{equation}{section}
\newcommand{\Div}{\mathrm{div}}
\newcommand{\grad}{\mathrm{grad}}
\newcommand{\diff}[1][]{\mathrm{d}#1}
\newcommand{\bra}{\langle}
\newcommand{\ket}{\rangle}
\newcommand{\bnabla}{\boldsymbol{\nabla}}
\newcommand{\Sch}{Schrödinger}
\newcommand{\adj}[1]{#1^{\dagger}}
\newcommand{\tr}{\mathrm{tr}}
\quotingsetup{font=small}

\begin{document}
\begin{titlepage}
\centering
{\Huge Meccanica Quantistica}\\
\vspace*{0.5cm}
{\normalsize «Voi avete la tendenza a cercare una realtà delle cose. È sbagliato.» [G.P.]} \\
\vspace*{0.5cm}
{\small Appunti (non rivisti) delle lezioni del professor Paffuti}
\vspace*{\stretch{0.5}} \\
\includegraphics[width=250pt,keepaspectratio=true]{eigenLibrichiaro}
\begin{center}
un progetto di
\end{center}
\includegraphics[width=250pt,keepaspectratio=true]{eigenlabinvertito2.png} \\
\url{www.eigenlab.org}
\vspace*{\stretch{1}} \\
{\small a cura di}\\
\vspace*{0.5cm}
{\normalsize Francesco Cicciarella\par}
\end{titlepage}
\pagebreak

\section*{Note legali}
\begin{center}
\begin{figure}[htbp]
\centering
\includegraphics[scale=1]{88x31.png}
\end{figure}
\vspace{0.5cm}
Copyright \copyright \; 2012-2013 di Francesco Cicciarella \\
\textit{Appunti di Meccanica Quantistica} \\	
è rilasciato sotto i termini della licenza \\
Creative Commons Attribuzione - Non commerciale - Condividi allo stesso modo 3.0 Italia. \\
Per visionare una copia completa della licenza, visita \\
\url{http://creativecommons.org/licenses/by-nc-sa/3.0/it/legalcode}
\end{center}
\section*{Liberatoria, mantenimento e segnalazione errori}
Questo documento viene pubblicato, in formato elettronico, senza alcuna garanzia di correttezza del suo contenuto. Il testo, nella sua interezza, è opera di \\

\vspace{0.3cm}
\begin{flushleft}
\texttt{Francesco Cicciarella}\\
\texttt{<f[DOT]cicciarella[AT]inventati[DOT]org>}
\end{flushleft}
\vspace{0.3cm}
e viene mantenuto dallo stesso, a cui possono essere inviate eventuali segnalazioni di errori.
\vspace{1cm}
\begin{flushright}
Pisa, 10 Ottobre 2012
\end{flushright}
\pagebreak


\tableofcontents
\pagebreak
\chapter{La nascita della Meccanica Quantistica}
\section{Il problema della radiazione di corpo nero}
Prendiamo in considerazione un "corpo nero", ossia una scatola riscaldata di volume $V$ in grado di assorbire tutta la radiazione che riceve, all'equilibrio termico (cioè dopo un tempo sufficientemente lungo). Chiamiamo $u= \mathcal{E}/V$ la densità di energia del corpo. Vogliamo sapere qual è la forma della distribuzione spettrale della densità di energia $u_{\nu}$, legata alla densità $u$ di energia dalla relazione:
\begin{equation}
u=\int_0^{\infty} u_{\nu}\;\diff{\nu}\;.
\end{equation}
La distribuzione spettrale è una funzione universale indipendente dalle particolari proprietà del corpo, deve quindi essere funzione unicamente delle costanti fondamentali e della temperatura. Dai principi della termodinamica sappiamo che:
\begin{itemize}
\item la pressione di radiazione $p$ è legata alla densità di energia $u$ dalla relazione $p=u/3$;
\item esiste la funzione di stato entropia $S$ data da $T\diff{S}=\diff{\mathcal{E}}+p\diff{V}$, dove $T$ è la temperatura assoluta, $\mathcal{E}$ è l'energia del sistema, $p$ la pressione e $V$ il volume. Sapendo che $\mathcal{E}=uV$ possiamo scrivere:
$$
T\diff{S}=\diff{(uV)}+p\diff{V}=u\diff{V}+V\diff{u}+p\diff{V}=u\diff{V}+V\diff{u}+\frac{u}{3}\diff{V}=V\diff{u}+\frac{4}{3}u\diff{V}\;.
$$
Essendo inoltre $u$ funzione solamente della temperatura, possiamo scrivere $\diff{u}=u'\diff{T}$. Dividendo per $T$ otteniamo infine:
$$
\diff{S}=\frac{Vu'}{T}\diff{T}+\frac{4}{3}u\diff{V}\stackrel{!}{=}\pdev{S}{T}\diff{T}+\pdev{S}{V}\diff{V}\;.
$$
L'entropia $S$ è una funzione di stato, dunque $\diff{S}$ è un differenziale esatto; di conseguenza deve valere la condizione di Schwarz $\partial_{TV}S=\partial_{VT}S$, cioè:
$$
\frac{u'}{T}=\frac{4}{3}\left(\frac{u'}{T}-\frac{u}{T^2}\right)\;.
$$
Sommando i termini simili otteniamo l'equazione differenziale:
\begin{equation}
u'=4\frac{u}{T}\;,
\end{equation}
che ha come soluzione:
\begin{equation}
u=\alpha T^4\;,
\end{equation}
che sostituita nell'espressione $TS=uV+pV$ ci dà la relazione tra l'entropia e la densità di energia:
\begin{equation}
S=\frac{4}{3}\alpha T^3 V\;.
\end{equation}
\end{itemize}
La densità spettrale, per la legge di Wien, deve essere della forma:
$$
u_{\nu}=\nu^3 f\left(\frac{\nu}{T}\right)\;,
$$
dove $f(\nu/T)$ è una funzione incognita da determinare empiricamente. A tal scopo, consideriamo l'analogia tra l'equilibrio termico del corpo nero e quello della materia. Prendiamo ad esempio un oscillatore armonico di frequenza $\nu$, la cui distribuzione spettrale è data da:
\begin{equation}
u_{\nu}=8\pi\frac{\nu^2}{c^3}\bar{\mathcal{E}}\;, \label{ch1_spectraldistrib}
\end{equation}
dove $\bar{\mathcal{E}}$ è l'energia media. Per un oscillatore armonico, l'energia media è data dalla somma del contributo termico e cinetico, che valgono entrambi $kT/2$, dove $k$ è la costante di Boltzmann, e pertanto $\bar{\mathcal{E}}=kT$. Se però sostituiamo questo valore nella \eqref{ch1_spectraldistrib} e integriamo su tutto lo spettro, la densità di energia diverge come $\nu^2$, e questo è un risultato fisicamente inaccettabile. \\
Prendiamo adesso in esame una superficie $\diff{S}$ e vogliamo studiare l'energia della radiazione emessa nella direzione $\vartheta$ per unità di angolo solido $\diff{\Omega}$, di tempo $\diff{t}$ e nell'intervallo di frequenze compreso tra $\nu$ e $\nu+\diff{\nu}$: essa sarà della forma:
\begin{equation}
\diff{\mathcal{E}_{\mathrm{emessa}}}=\diff{S}\;\diff{t}\;\diff{\Omega}\;\diff{\nu}J(\nu,\vartheta)\;,
\end{equation}
dove $J(\nu,\vartheta)$ è detto \textit{coefficiente di emissione}. Se invece mandiamo contro la superficie della radiazione di lunghezza $c\cdot \diff{t}$, a incidenza $\vartheta$, l'energia della radiazione assorbita nell'intervallo di frequenze che va da $\nu$ a $\nu+\diff{\nu}$ sarà data da:
\begin{equation}
\diff{\mathcal{E}_{\mathrm{ass}}}=(c\;\diff{t}\;\diff{S}\cos\vartheta)u_{\nu}\frac{\diff{\Omega}}{4\pi}\;\diff{\nu}A(\nu,\vartheta)\;,
\end{equation}
dove $A(\nu,\vartheta)$ è detto \textit{coefficiente di assorbimento}. All'equilibrio deve essere ovviamente $\diff{\mathcal{E}_{\mathrm{emessa}}}=\diff{\mathcal{E}_{\mathrm{ass}}}$. Ricaviamo così la \textit{legge di Kirchoff}:
\begin{equation}
\frac{J}{A}=\frac{c}{4\pi}u_{\nu}\cos\vartheta\;. \label{ch1_kirchofflaw}
\end{equation}
Per un corpo nero (per cui per definizione $A=1$) nella direzione normale alla superficie ($\vartheta=0$), si ha $J=c\cdot u_{\nu}/4\pi$. \\
Alla luce di queste considerazioni, Max Planck concluse che l'energia dell'oscillatore armonico non potesse assumere qualunque valore con continuità, anzi, la sua energia doveva essere in qualche modo discretizzata. Planck ipotizzò che tali livelli discreti fossero dati da:
\begin{equation}
\mathcal{E}_n = nh\nu\;,
\end{equation}
dove $h$ è la \textit{costante di Planck}. L'energia media dell'oscillatore adesso sarà data dalla media statistica:
\begin{equation}
\bar{\mathcal{E}}=\frac{\sum_{n=0}^{\infty}nh\nu e^{-\mathcal{E}_n/kT}}{\sum_{n=0}^{\infty}e^{-\mathcal{E}_n/kT}}=\frac{h\nu\sum_{n=0}^{\infty}n e^{-nh\nu/kT}}{\sum_{n=0}^{\infty} e^{-nh\nu/kT}}\;.
\end{equation}
Calcoliamo il valore di $\bar{\mathcal{E}}$. Posto $x=e^{-h\nu/kT}$, $|x|<1$ si ha:
\begin{align}
\bar{\mathcal{E}} &= \frac{h\nu\sum_{n=0}^{\infty}n x^n}{\sum_{n=0}^{\infty} x^n}=\frac{h\nu x\sum_{n=1}^{\infty}n x^{n-1}}{\sum_{n=0}^{\infty} x^n}=\frac{h\nu x D_x\left[\sum_{n=0}^{\infty} x^n\right]}{\sum_{n=0}^{\infty} x^n} = \notag \\
&= h\nu x \frac{\mathrm{d}}{\diff{x}}\left[\log\left(\sum_{n=0}^{\infty} x^n\right)\right]=
h\nu x \frac{\mathrm{d}}{\diff{x}}\left[\log\left(\frac{1}{1-x}\right)\right]= \notag \\
&= h\nu x (1-x)\frac{1}{(1-x)^2}=\frac{h\nu x}{1-x}=\frac{h\nu e^{-h\nu/kT}}{1-e^{h\nu/kT}}= \notag \\
&= \frac{h\nu}{e^{h\nu/kT}-1}\;.
\end{align}
che sostituito nella \eqref{ch1_spectraldistrib} restituisce la \textit{legge della radiazione di Planck}:
\begin{equation}
u_{\nu}=8\pi h\frac{v^3}{c^3}\frac{1}{e^{h\nu/kT}-1}\;. \label{ch1_plancklaw}
\end{equation}
Osserviamo che nel regime di basse frequenze, cioè $h\nu\ll kT$, sviluppando al primo ordine $e^{h\nu/kT}\simeq 1+h\nu/kT$, si ottiene:
$$
u_{\nu}\simeq 8\pi h\frac{\nu^3}{c^3}\frac{kT}{h\nu}=8\pi \frac{v^2}{c^3}kT\;,
$$
cioè la formula classica è il caso limite della formula di Planck per basse frequenze. \\
Per quanto riguarda la costante di Planck $h$, sperimentalmente si è ottenuto il valore $6.6 \cdot 10^{-27}\; \mathrm{erg\cdot s}$. È interessante osservare che $h$ ha le stesse dimensioni di un momento angolare.
\section{Effetto fotoelettrico}
Einstein ipotizzò nel 1905 per spiegare l'effetto fotoelettrico che la luce fosse un qualcosa di discreto e non continuo, cioè che fosse essenzialmente composta da particelle. Assumendo che tale ipotesi fosse vera, sorgeva il problema di trovare un modo per contare tali particelle. Innanzitutto, ci poniamo nel regime di alte frequenze (ciò implica basse energie e meno particelle da contare), cioè $e^{h\nu/kT}\gg 1$, e quindi la formula di Planck può essere approssimata come:
\begin{equation}
u_{\nu}\simeq 8\pi \frac{h\nu^3}{c^3}e^{-h\nu/kT}\;. \label{ch1_planckapprox}
\end{equation}
Consideriamo un volume $V$. La probabilità di trovare una particella in una porzione $v$ di $V$ è data da $v/V$. Se le particelle non interagiscono, la probabilità di trovarne $n$ nello stesso volumetto è $(v/V)^n$. Sappiamo dalla statistica che l'entropia di un ensemble è legata alla probabilità dalla relazione:
\begin{equation}
S=k\log\left(\frac{v}{V}\right)^n=nk\log v+\mathrm{cost}\;.
\end{equation}
A questo punto calcoliamo l'entropia: se nella sua espressione compare il logaritmo del volume, allora l'ipotesi della composizione discreta risulta essere vera e saremo in grado di calcolare $n$. Poniamo $S=S_{\nu}v \delta\nu$, dove con $S_{\nu}$ abbiamo indicato l'entropia per unità volume riferita allle frequenze comprese tra $\nu$ e $\nu+\delta\nu$. A volume costante l'espressione dell'entropia sarà $T\;\diff{S_{\nu}}=\diff{u_{\nu}}$, cioè:
$$
\dev{S_{\nu}}{u_{\nu}}=\frac{1}{T}\;.
$$
Ricaviamo $T$ in funzione di $u_{\nu}$ dalla \eqref{ch1_planckapprox}, ottenendo:
\begin{equation}
\frac{1}{T}=-\frac{k}{h\nu}\log u_{\nu}+B\;.
\end{equation}
Sostituendo troviamo l'equazione differenziale:
$$
\dev{S_{\nu}}{u_{\nu}}=-\frac{k}{h\nu}\log u_{\nu}+B\;,
$$
che integrata restituisce:
\begin{equation}
S_{\nu}=-\frac{k}{h\nu}u_{\nu}(\log u_{\nu}-1)+Bu_{\nu}=-\frac{k}{h\nu}u_{\nu}\log u_{\nu}\;, \label{ch1_entropysol}
\end{equation}
dove abbiamo trascurato i termini lineari in $u_{\nu}$ in quanto irrilevanti ai fini del calcolo. Adesso, ricordando che $v u_{\nu}\delta\nu=\mathcal{E}$, dove $\mathcal{E}$ è l'energia totale relativa al volume $v$, ricaviamo $u_{\nu}=\mathcal{E}/v\delta\nu$ e sostituiamo nella \eqref{ch1_entropysol}:
$$
S_{\nu}=-\frac{k}{h\nu}\frac{\mathcal{E}}{v\delta\nu}\log\left(\frac{\mathcal{E}/\delta\nu}{v}\right)\;.
$$
Ritenendo solo il termine in $\log v$ si ottiene:
\begin{equation}
S_{\nu}=\frac{k}{h\nu}\frac{\mathcal{E}}{v\delta\nu}\log v\;,
\end{equation}
da cui:
\begin{equation}
S_{\nu}v\delta\nu\equiv S= k\frac{\mathcal{E}}{h\nu}\log v\quad  \Longrightarrow \quad n=\frac{\mathcal{E}}{h\nu}\;.
\end{equation}
In definitiva, ciò conferma che è possibile descrivere la luce come particelle, dette \textit{fotoni}, ciascuno di energia $h\nu$. Questo risultato spiegherebbe anche l'effetto fotoelettrico: mandando della luce in un metallo, l'energia massima degli elettroni emessi è proporzionale alla frequenza della luce; sperimentalmente, $\mathcal{E}_{\mathrm{max}}=h\nu-W$, dove $W$ è il potenziale di estrazione e $h$ è proprio la costante di Planck. Ciò è in netto contrasto con la Fisica classica, che afferma che l'energia di un'onda non può dipendere dalla frequenza, ma esclusivamente dalla sua intensità.
\subsection{Effetto Compton}
Per verificare sperimentalmente che la luce fosse fatta di particelle, si è effettuato il seguente esperimento: consideriamo un elettrone in quiete e mandiamo contro di lui un fotone $\gamma$ di energia $h\nu$. Si osserva dopo l'urto un fenomeno di scattering, cioè il fotone e l'elettrone si muovono in direzione rispettivamente $\theta$ e $\varphi$ rispetto alla direzione di incidenza. Imponendo la conservazione dell'energia e dell'impulso, si ottiene il sistema di equazioni:
$$
\begin{cases}
h\nu + mc^2=h\nu'+\mathcal{E}\;, \\
\\
h\nu/c=(h\nu'/c)\cos\theta+p\cos\varphi\;, \\
\\
0=(h\nu'/c)\sin\theta-p\sin\varphi\;,
\end{cases}
$$
dove $\mathcal{E}=\sqrt{m^2c^4+p^2c^2}$. Eseguendo i calcoli (in termini della lunghezza d'onda $\lambda=c/v$) si ottiene la relazione:
\begin{equation}
\lambda'-\lambda =\frac{h}{mc}(1-\cos\theta)\;,
\end{equation}
dove la quantità $h/mc$ è il \textit{raggio Compton dell'elettrone}.
\section{Il modello atomico di Bohr}
\subsection{Invarianti adiabatici}
In un sistema controllato da un certo parametro $\lambda$, facciamo variare lentamente il parametro con variazione $\dot{\lambda}$ in un intervallo di tempo $T$. Si definisce \textit{limite adiabatico} il limite:
\begin{equation}
\lim_{\dot{\lambda}\to 0} \dot{\lambda}T\;.
\end{equation}
Quindi una quantità è detta \textit{invariante adiabatico} se è invariante per limite adiabatico. \\
\\
Sappiamo che per un oscillatore armonico unidimensionale i livelli energetici sono discreti: $\mathcal{E}_n=nh\nu \quad (n=0,1,\ldots)$. Per un sistema generico, cosa rappresenta la quantità $\mathcal{E}/\nu$? \\
Consideriamo un moto periodico nello spazio delle fasi $(p,q)$, allora la quantità:
$$
\oint p\,\diff{q}\;,
$$
è un invariante adiabatico. Per l'oscillatore armonico, valeva:
$$
\mathcal{E}=\frac{p^2}{2m}+\frac{1}{2}m\omega^2q^2\quad \implies\quad \frac{p^2}{2m\mathcal{E}}+\frac{m\omega^2q^2}{2\mathcal{E}}=1\;,
$$
cioè l'orbita come ben sappiamo è un ellisse. In questo caso $\oint p\diff{q}$ rappresenta l'area dell'ellisse che è data da:
$$
A=\pi a b= \pi \sqrt{2m\mathcal{E}}\sqrt{\frac{2\mathcal{E}}{m\omega^2}}=2\pi\frac{\mathcal{E}}{\omega}=\frac{\mathcal{E}}{\nu}\;,
$$
cioè:
\begin{equation*}
\oint p\,\diff{q}=\frac{\mathcal{E}}{\nu}=nh\;.
\end{equation*}
Questa è una condizione generale, e per un moto qualsiasi la condizione:
\begin{equation}
\oint p\,\diff{q}=nh\;,
\end{equation}
è detta \textit{condizione di quantizzazione di Bohr-Sommerfeld}.
\subsection{Principio di Ritz}
Dall'osservazione degli spettri di luce emessa dai gas ad alta temperatura, Ritz e Rydberg notarono che era possibile riordinare le frequenze delle righe dello spettro di emissione assegnando a ciascuna di esse due indici. Le frequenze erano legate dalla relazione:
\begin{equation}
\nu_{n,m}=T(n)-T(m) \qquad n,m\in \mathbb{Z}\;,
\end{equation}
dove $T(n)$ è una particolare funzione che dipende dal tipo di atomo in esame. Per l'atomo di idrogeno si è osservato sperimentalmente che $T(n)=-R/n^2$ dove $R$ è la \textit{costante di Rydberg}, mentre per gli atomi alcalini, $T(n)=-R/(n+\mu)^2$, dove $\mu$ è un fattore di correzione che dipende dall'elemento. Inoltre, vale il \textit{principio di combinazione di di Raylegh-Ritz}:
\begin{equation}
\nu_{n,m}+\nu_{m,k}=T(n)-T(m)+T(m)-T(k)=T(n)-T(k)=\nu_{n,k}\;.
\end{equation}
Per interpretare la formula di Rydberg, Bohr formulò le seguenti ipotesi che prendono il nome di \textit{modello atomico di Bohr}:
\begin{itemize}
\item i valori possibili dell'energia di un atomo sono discreti. Finché l'atomo è in uno degli stati possibili (\textit{stati stazionari}) non emette luce;
\item l'atomo emette o assorbe luce quando un elettrone compie una transizione da uno stato $n$ ad uno $m$ e la luce emessa o assorbita in tale transizione ha frequenza data da:
$$
h\nu_{n,m}=\mathcal{E}_n-\mathcal{E}_m\;;
$$
\item l'elettrone negli stati stazionari si muove secondo la meccanica classica (orbite circolari);
\item per $n$ abbastanza grande, i risultati sperimentali coincidono con quelli della meccanica classica (\textit{Principio di corrispondenza di Bohr}).
\end{itemize}
Prendiamo in esame l'atomo di idrogeno, costituito da un elettrone (massa $m$, carica $-e$) che orbita intorno a un nucleo (carica $+e$): l'energia dell'orbita circolare è data da:
$$
\mathcal{E}=\frac{p^2}{2m}-\frac{e^2}{r}\;.
$$
Il teorema del viriale, inoltre, ci garantisce che $\mathcal{E}_{cin}=-U_{pot}/2$, quindi l'espressione dell'energia è:
\begin{equation}
\mathcal{E}=-\frac{1}{2}\frac{e^2}{r}\;. \label{ch1_energy}
\end{equation}
Applico adesso la condizione di quantizzazione (ricordando che $p=$ costante):
$$
\oint p\;\diff{q}=p\cdot 2\pi r=nh\quad  \Longrightarrow\quad  p^2=\frac{n^2 h^2}{4\pi^2 r^2}=\frac{n^2 \hbar^2}{r^2}\;,
$$
dove abbiamo introdotto la costante $\hbar=h/2\pi$. Sostituendo l'espressione di $p^2$ nel teorema del viriale, troviamo:
$$
\frac{p^2}{2m}=\frac{1}{2}\frac{e^2}{r}\quad  \Longrightarrow \quad \frac{1}{2m}\frac{n^2\hbar^2}{r^2}=\frac{1}{2}\frac{e^2}{r}\;,
$$
cioè otteniamo che i raggi delle orbite sono quantizzati e i valori possibili sono dati da:
\begin{equation}
r=n^2\frac{\hbar^2}{me^2}\equiv n^2 a_B\;,
\end{equation}
dove $a_B$ è il \textit{raggio di Bohr} e vale circa $0.5$ \AA= $0.5\cdot 10^{-8}$cm. Le energie associate si ottengono sostituendo l'espressione appena ricavata nella \eqref{ch1_energy}:
\begin{equation}
\mathcal{E}_n =-\frac{1}{n^2}\frac{e^2}{2a_B^2}=-\frac{1}{2n^2}\frac{me^4}{\hbar^2}\;.
\end{equation}
Osserviamo che $\mathcal{E}_1\simeq 13.6$ eV, che è l'energia di ionizzazione dell'atomo di idrogeno. In generale, per un atomo di numero atomico $Z$ l'espressione dell'energia è:
\begin{equation}
\mathcal{E}_n^{(Z)}=-\frac{1}{2n^2}\frac{mZ^2e^4}{\hbar^2}\;.
\end{equation}
Nel caso dell'elio, $Z=2$ e, teoricamente, tutti gli stati pari dell'elio $(n=2k, k=0,1,\ldots)$ dovrebbero corrispondere ad uno stato dell'idrogeno. Tuttavia, c'è una differenza dovuta alle masse, in quanto la $m$ che compare nell'espressione degli stati energetici è la massa ridotta tra quella dell'elettrone e quella del nucleo:
\begin{align*}
&m=\frac{m_eM_H}{m_e+M_H}\;, &\mbox{idrogeno}\;, \\
&m=\frac{m_eM_{He}}{m_e+M_{He}}\;, &\mbox{elio}\;.
\end{align*}
Nel passare da uno stato al successivo il salto energetico è:
$$
E_{n+1}-E_n=\frac{1}{2}\frac{e^2}{a_B}\left[\frac{1}{n^2}-\frac{1}{(n+1)^2}\right] \stackrel{n\to\infty}{\simeq} \frac{e^2}{a_Bn^3}\;.
$$
Quindi nel limite $n\gg 1$, $h\nu \simeq e^2/(a_Bn^3)$, dove $\nu$ è la frequenza classica propria dell'orbita dell'elettrone.
\subsection{L'ipotesi di De Broglie}
Abbiamo visto che la luce può essere trattata come particelle, ma vale anche il contrario? In altre parole, è possibile trattare le particelle come onde? \textbf{De Broglie} ipotizzò che ciò fosse possibile, associando ad una particella di impulso $p$ un'onda di lunghezza $\lambda=h/p$. L'ipotesi fu sperimentalmente confermata da esperimenti di diffrazione ed interferenza.
\chapter{Approccio di Schrödinger alla Meccanica Quantistica}
\section{L'esperimento di Young}
Consideriamo una superficie verticale con due fori posti a distanza $d$ e uno schermo dotato di rivelatori a distanza $L$ da essa. Spariamo inizialmente contro la superficie delle particelle. Se lasciamo aperto solo il foro 1, allora tutte le particelle passeranno da quel foro e la distribuzione rivelata sullo schermo sarà una gaussiana centrata nel punto dello schermo corrispondente al foro. Lo stesso discorso vale se lasciamo aperto solo il foro 2. Se invece apriamo entrambi i fori, ci aspettiamo che la distribuzione sia la somma delle precedenti, cioè se $P_1$ è la probabilità che una particella passi dal primo foro e $P_2$ la probabilità che passi dal secondo foro, allora la probabilità di rivelare una particella sullo schermo è $P=P_1+P_2$, cioè o passa dal foro 1, o dal foro 2. \\
\\
Adesso mettiamo una sorgente puntiforme di onde: se lasciamo aperto solo il foro 1, quando le onde vi arriveranno esso si comporterà, per il principio di Huygens, come una sorgente puntiforme di onde. Allora sullo schermo riveleremo una distribuzione del tipo $h e^{i\phi_1}$, dove $\phi_1$ indica la fase e $h$ l'ampiezza dell'onda. Viceversa (a foro 2 aperto) avremo $h e^{i\phi_2}$. Se apriamo entrambi i fori, sommo le ampiezze ottenendo $he^{i\phi_1}+he^{i\phi_2}$. L'intensità dell'onda è proporzionale al modulo quadro delle ampiezze, cioè:
$$
\left|he^{i\phi_1}+he^{i\phi_2}\right|^2=h^2\left|e^{i(\phi_1-\phi_2)/2}\right|^2\left|e^{i(\phi_1-\phi_2)/2}+e^{-i(\phi_1-\phi_2)/2}\right|^2=4h^2\cos^2\left(\frac{\phi_1-\phi_2}{2}\right)\;.
$$
Avremo dunque dei massimi dell'ampiezza quando $\phi_1=\phi_2$, cioè quando le onde sono in fase, mentre degli zeri in corrispondenza di uno sfasamento di $\pi$. Sullo schermo registreremo la classica figura di interferenza. \\
\\
Adesso ripetiamo l'esperimento con gli elettroni. Essendo comunque particelle, ci aspettiamo di ottenere una distribuzione simile al primo caso. Tuttavia sullo schermo si registrò la figura di interferenza tipica delle onde. Allora si provò ad osservare l'elettrone con una lampadina, avendo cioè la certezza di sapere da quale foro sia esso passato. Il risultato fu che sullo schermo non si registrarono le frange di interferenza, ma la distribuzione tipica delle particelle. \\
\\
La conclusione fu che se sappiamo da dove sia passato l'elettrone, non registriamo le frange, altrimenti sì.
\section{L'equazione di Schrödinger}
Vogliamo adesso scrivere un'equazione per descrivere la propagazione dell'elettrone, dato che non si comporta totalmente né come particella né come onda. L'equazione dovrà essere innanzitutto lineare. Partiamo dall'espressione di un'onda piana stazionaria, $\psi(x)=e^{ikx}$. Sappiamo che (ipotesi di de Broglie):
$$
p=\frac{h}{\lambda}=\frac{2\pi}{\lambda}\frac{h}{2\pi}=k\hbar\;,
$$
allora:
\begin{equation}
\psi(x)=e^{ikx}=e^{ikx\hbar/\hbar}=e^{ipx/\hbar}\;. \label{ch2_planewave}
\end{equation}
Vogliamo inoltre che valga il principio di sovrapposizione, ossia la nostra funzione $\psi$ dovrà avere la stessa espressione della sovrapposizione di onde piane in trasformata di Fourier:
\begin{equation}
\psi(x)=\int \frac{\diff{k}}{2\pi}e^{ikx}\hat{\psi}(k)\;.
\end{equation}
Dalla \eqref{ch2_planewave} notiamo che:
$$
\frac{\hbar}{i}\frac{\partial}{\partial x}e^{ipx/\hbar}=pe^{ipx/\hbar}\;,
$$
cioè moltiplicare per $p$ la funzione $\psi$ corrisponde ad una derivazione e una moltiplicazione per due costanti. Ricordando che per la particella libera $\mathcal{E}=p^2/2m$, interpretiamo $p^2$ come due derivazioni. Possiamo dunque scrivere:
\begin{equation}
\frac{1}{2m}\left(\frac{\hbar}{i}\frac{\partial}{\partial x}\right)^2\psi=\mathcal{E}\psi\quad  \Longrightarrow\quad -\frac{\hbar^2}{2m}\dev[2]{\psi}{x}=\mathcal{E}\psi\;.
\end{equation}
L'equazione cercata ancora non è soddisfacente. Bisogna ancora:
\begin{enumerate}
\item riuscire a scrivere l'equazione anche in presenza di potenziale esterno;
\item esplicitare la dipendenza dal tempo.
\end{enumerate}
Il primo punto si risolve facilmente assumendo che per $\Delta x$ sufficientemente piccoli il potenziale $V(x)$ si mantenga costante, lo approssimiamo cioè con una scalinata avente i gradini costanti. Quindi basta semplicemente togliere l'energia potenziale all'energia cinetica senza preoccuparci della dipendenza da $x$. Otteniamo così \textit{l'equazione di Schrödinger indipendente dal tempo}:
\begin{equation}
-\frac{\hbar^2}{2m}\frac{\mathrm{d}^2}{\diff{x}^2}\psi(x)= (\mathcal{E}-V(x))\psi(x)\;. \label{ch2_schrotimeindip}
\end{equation}
Adesso dobbiamo esplicitare la dipendenza dal tempo. Partiamo adesso dall'espressione di un'onda piana non stazionaria, la cui forma più generale è:
$$
\psi(x,t)=e^{ikx-i\omega t}\;.
$$
Sappiamo che $h\nu=\mathcal{E}$, oppure $\hbar\omega=\mathcal{E}$, da cui $\omega=\mathcal{E}/\hbar$. Allora l'espressione diventa:
$$
\psi(x,t)=e^{i(px/\hbar-\mathcal{E}t/\hbar)}\;.
$$
Notiamo adesso che moltiplicare per $\mathcal{E}$ significa derivare rispetto al tempo. Alla luce di ciò, possiamo modificare la \eqref{ch2_schrotimeindip} per scrivere, più in generale, \textit{l'equazione di Schrödinger dipendente dal tempo}:
\begin{equation}
i\hbar\frac{\partial}{\partial t}\psi(x,t)=\left(-\frac{\hbar^2}{2m}\frac{\mathrm{d}^2}{\diff{x}^2}+V\right)\psi(x,t)\;. \label{ch2_schrotimedip}
\end{equation}
La $\psi$ è in generale una funzione complessa. Il suo modulo quadro $|\psi|^2$ non rappresenta, come nel caso delle onde, l'intensità dell'onda propagata, perché l'elettrone può solo essere o non essere in un punto dello spazio. In effetti, la quantità $|\psi|^2\diff{x}$ è una densità di probabilità, cioè la probabilità di trovare l'elettrone nell'intervallo infinitesimo $\diff{x}$. \\
L'espressione di $\psi$ fa però sorgere un problema: la velocità di propagazione dovrebbe essere data da $p/m$, mentre se applichiamo la formula per trovare la velocità di fase di un'onda piana, $v_f=\omega/k$, otteniamo:
$$
\frac{\mathcal{E}}{\hbar}\frac{\hbar}{p}=\frac{p^2}{2m}\frac{1}{p}=\frac{p}{2m}\;,
$$
cioè la velocità di fase dell'onda risulta essere la metà di quanto dovrebbe teoricamente essere. Il fattore 2 è dovuto al fatto che la relazione di dispersione non è lineare (infatti $\mathcal{E}=p^2/2m$). Notiamo quindi che $p/m$ è la velocità di gruppo dell'onda $\partial\omega/\partial k=\partial\mathcal{E}/\partial p=p/m$.
\linebreak
Abbiamo detto che il modulo quadro della funzione d'onda $|\psi(x)|^2$ moltiplicato per l'intervallo infinitesimo $\diff{x}$ rappresenta la probabilità di trovare l'elettrone nell'intervallo $\diff{x}$. Inoltre, $|\psi(x)|^2$ deve soddisfare la condizione di normalizzazione:
$$
\int_{-\infty}^{\infty} |\psi(x)|^2\;\diff{x}=1\;.
$$
Per descrivere l'elettrone, dobbiamo conoscere la sua posizione e il suo impulso, o quantomeno i loro valori medi. Il valor medio di $x$ è facilmente dato dalla media di $x^n$ sulla distribuzione $\psi$:
\begin{equation}
\int x^n|\psi(x)|^2\;\diff{x}\;,
\end{equation}
nel caso $n=0$, cioè:
\begin{equation}
\bar{x}=\int x|\psi(x)|^2\;\diff{x}\;.
\end{equation}
Vogliamo adesso definire una probabilità legata all'impulso dell'elettrone, per far questo, prendiamo come funzione d'onda la sovrapposizione di due onde piane:
\begin{equation}
\psi(x)=\int \diff{p}[\varphi_1(p)e^{ip_1x}+\varphi_2(p)e^{ip_2x}]\;.
\end{equation}
Mandando l'onda su un reticolo di diffrazione, sappiamo che l'intensità dell'onda diffratta, fissati l'angolo $\theta$ e la frequenza $\nu$, è proporzionale all'intensità dell'onda incidente, pertanto possiamo definire la densità di propabilità di impulso $\diff{P(p)}\equiv|\varphi(p)|^2\;\diff{p}$. Passando in trasformata di Fourier:
\begin{equation}
\psi(x)=\int \frac{\diff{p}}{2\pi\hbar}e^{ipx/\hbar}\varphi(p)\;, \label{ch2_psifourier}
\end{equation}
la densità di probabilità di impulso si scrive:
\begin{equation}
\diff{P(p)}=|\varphi(p)|^2\frac{\diff{p}}{2\pi\hbar}\;.
\end{equation}
Inoltre, per le proprietà della trasformata di Fourier si ha:
\begin{equation}
\int |\psi(x)|^2\;\diff{x}=\int |\varphi(p)|^2\frac{\diff{p}}{2\pi\hbar}\;.
\end{equation}
Vediamo adesso cosa significa misurare il valor medio di $p$ su un certo stato. Innanzitutto dimostriamo che le espressioni:
\begin{equation}
\bar{p}=\int\frac{\diff{p}}{2\pi\hbar}p|\varphi(p)|^2\;, \label{ch2_p1}
\end{equation}
e:
\begin{equation}
\bar{p}=\int\diff{x}\,\psi^*(x)\frac{\hbar}{i}\frac{\partial}{\partial x}\psi(x)\;, \label{ch2_p2}
\end{equation}
sono equivalenti. Sostituendo nella \eqref{ch2_p2} la \eqref{ch2_psifourier} si ottiene:
\begin{align*}
\int \diff{x}\; \psi^*(x)\frac{\hbar}{i}\frac{\partial}{\partial x}\psi(x) &= \int \diff{x}\int \frac{\diff{p}}{2\pi\hbar}\int \frac{\diff{p'}}{2\pi\hbar}\;\varphi^*(p)e^{-ipx/\hbar}\frac{\hbar}{i}\frac{\partial}{\partial x}
e^{ip'x/\hbar}\varphi(p') \\
&= \int \diff{x}\int\frac{\diff{p}}{2\pi\hbar}\int\frac{\diff{p'}}{2\pi\hbar}\;\varphi^*(p)p'\varphi(p')e^{-i(p-p')x/\hbar}\;.
\end{align*}
Riconosciamo adesso che tutto ciò che dipende da $x$ è la trasformata di Fourier della delta di Dirac, così definita:
$$
\int \delta(x)f(x)\;\diff{x}=f(0)\;,
$$
con le seguenti proprietà:
\begin{align*}
\delta(x) &=\int\frac{\diff{k}}{2\pi}e^{ikx}\quad \Longleftrightarrow\quad \hat{\delta}(k)=\int\delta(x)e^{-ikx}\,\diff{x}=1\;, \\
\delta(cx) &= \frac{1}{|c|}\delta(x)\;,
\end{align*}
dunque:
$$
\int \diff{x}\; e^{-i(p-p')x/\hbar}=2\pi\delta\left(\frac{p-p'}{\hbar}\right)=2\pi\hbar\delta(p-p')\;.
$$
In conclusione, si ha:
\begin{align*}
\int \diff{x}\int\frac{\diff{p}}{2\pi\hbar}\int\frac{\diff{p'}}{2\pi\hbar}\;\varphi^*(p)p'\varphi(p')e^{-i(p-p')x/\hbar} &= \int \frac{\diff{p}}{2\pi\hbar}\frac{\diff{p'}}{2\pi\hbar}\varphi^*(p)\varphi(p')p'\delta(p-p')2\pi\hbar \\
&= \int \frac{\diff{p}}{2\pi\hbar}\varphi^*(p)\varphi(p)p=\int \frac{\diff{p}}{2\pi\hbar}\;p|\varphi(p)|^2\;.
\end{align*}
Quindi \eqref{ch2_p1}=\eqref{ch2_p2}. \\
\\
Le funzioni d'onda devono appartenere ad uno spazio vettoriale (perché vale il principio di sovrapposizione) su cui possiamo definire un prodotto scalare:
$$
(\psi_1,\psi_2)\equiv int \psi_1^*(x)\psi_2(x)\;\diff{x}\equiv \bra \psi_1|\psi_2\ket\;.
$$
Allora:
$$
||\psi||^2=\bra\psi|\psi\ket=\int |\psi|^2\;\diff{x} <\infty \qquad \mbox{(per la condizione di normalizzazione)}\;,
$$
da ciò deduciamo che lo spazio di Hilbert a cui appartengono le funzioni d'onda è $\mathbb{L}^2$. Alla luce di ciò, il valor medio di $x^n$ può essere scritto come:
\begin{equation}
\overline{x^n}=\int \diff{x}\; x^n|\psi(x)|^2=\bra\psi|x^n|\psi\ket\;.
\end{equation}
Stiamo cioè interpretando $x^n$ e $\frac{\hbar}{i}\frac{\partial}{\partial x}$ come operatori lineari definiti sullo spazio di Hilbert. In generale, dato un operatore $\mathcal{O}$ e un vettore $|\alpha\ket \in H$, si scrive:
$$
\mathcal{O}|\alpha\ket=|\beta\ket\;,
$$
dove $|\beta\ket$ è l'immagine di $|\alpha\ket$ rispetto all'operatore. Il prodotto scalare tra due vettori $|\alpha\ket,|\beta\ket\in H$ invece si indica con $\bra\alpha|\beta\ket$. Nel nostro caso specifico, $\mathcal{O}=x^n$, $|\alpha\ket=\psi$. Applichiamo l'operatore e facciamo il prodotto scalare:
$$
\bra\psi|x^n|\psi\ket=\int \diff{x}\;\psi^*x^n\psi=\int\diff{x}\; x^n|\psi|^2=\overline{x^n}\;.
$$
Stessa cosa per $\hat{p}=\frac{\hbar}{i}\frac{\partial}{\partial x}$:
$$
\bra\psi|\hat{p}|\psi\ket=\int\diff{x}\; \psi^*\frac{\hbar}{i}\frac{\partial}{\partial x}\psi=\bar{p}\;.
$$
Abbiamo perciò interpretato $\overline{x^n}$ e $\bar{p}$ come valor medi di operatori definiti sullo spazio di Hilbert $\mathbb{L}^2$. Possiamo generalizzare ad una certa funzione delle $q$ e delle $p$ scrivendo:
\begin{equation}
\overline{f(q,p)}=\int \psi^*(x)f\left(x,\frac{\hbar}{i}\frac{\partial}{\partial x}\right)\psi(x)\;\diff{x}\;.
\end{equation}
Notiamo subito che non possiamo prendere un operatore a caso, perché l'integrale deve essere un numero reale. Condizione necessaria e sufficiente affinché l'integrale restituisca un numero reale è che $f$ sia un operatore Hermitiano. \\
\\
Sia $A$ un operatore, sappiamo che $\bra\alpha|A|\beta\ket=(\alpha,A\beta)$. Definiamo l'operatore \textit{aggiunto} $A^{\dagger}$ come:
\begin{equation}
\bra\alpha|A^{\dagger}|\beta\ket \equiv (A\alpha,\beta)\;.
\end{equation}
Un operatore $A$ è Hermitiano se $A=A^{\dagger}$. Dimostriamo che l'hermitianità è condizione necessaria e sufficiente affinché i valori medi di un operatore siano reali. Sia $A$ hermitiano ($A=A^{\dagger}$), allora:
$$
\bar{A}=\bra\psi|A|\psi\ket=(\psi,A\psi)=(\psi,A^{\dagger}\psi)=(A\psi,\psi)=(\psi,A\psi)^*\;,
$$
e ciò dimostra la prima implicazione. Viceversa, supponiamo che $A$ sia un operatore avente valor medio reale su tutti gli stati, e scegliamo $|\psi\ket=|\alpha\ket+e^{i\phi}|\beta\ket$. Allora si ha:
$$
\bar{A}=\bra\psi|A|\psi\ket=\bra\alpha|A|\alpha\ket+\bra\beta|A|\beta\ket+e^{i\phi}\bra\alpha|A|\beta\ket+e^{-i\phi}\bra\beta|A|\alpha\ket\;.
$$
Il secondo membro per ipotesi deve essere reale; il primo e il secondo termine sono reali per ipotesi, deve quindi risultare:
$$
e^{i\phi}\bra\alpha|A|\beta\ket+e^{-i\phi}\bra\beta|A|\alpha\ket \in \mathbb{R}\;,
$$
poiché $e^{i\phi}=(e^{-i\phi})^*$, dovrà necessariamente essere:
$$
(\alpha,A\beta)=(\beta,A\alpha)^*\quad  \Longrightarrow\quad  A=A^{\dagger}\;,
$$
cioè l'operatore è hermitiano. Verifichiamo adesso se gli operatori $\hat{x},\hat{p}$ sono hermitiani. Per $\hat{x}$ si ha:
$$
(\alpha,A\beta)=\int \alpha^*(x)x\beta(x)\;\diff{x}=\int(x\alpha(x))^*\beta(x)\;\diff{x}=(A\alpha,x)\;,
$$
in quanto $x=x^*$ perché $x\in\mathbb{R}$; concludiamo che $\hat{x}$ è hermitiano. Per $\hat{p}$ si ha:
$$
\int \alpha^*(x)\frac{\hbar}{i}\frac{\partial}{\partial x}\beta(x)\;\diff{x}\stackrel{?}{=}\int \left(\frac{\hbar}{i}\frac{\partial}{\partial x}\alpha(x)\right)^*\beta(x)\;\diff{x}\;,
$$
integrando il secondo membro per parti si ha:
$$
\int \left(\frac{\hbar}{i}\frac{\partial}{\partial x}\alpha(x)\right)^*\beta(x)\;\diff{x} =-\frac{\hbar}{i}(\alpha\beta)+\int \alpha(x)\frac{\hbar}{i}\frac{\partial}{\partial x}\beta(x)\;\diff{x}\;,
$$
ed è uguale al primo membro se e solo se il primo termine è nullo, quindi l'hermitianità di $\hat{p}$ dipende dalle condizioni al contorno. Nel caso in cui $p$ è hermitiano, consideriamo gli operatori $xp$ e $px$:
\begin{align*}
(xp)f(x)&=x\frac{\hbar}{i}\pdev{f(x)}{x}=\frac{\hbar}{i}xf'\;, \\
(px)f(x)&= \frac{\hbar}{i}\frac{\partial}{\partial x}(xf)=\frac{\hbar}{i}f+\frac{\hbar}{i}xf'\;.
\end{align*}
Concludiamo che $xp$ e $px$ sono due operatori diversi, la cui differenza è:
\begin{equation}
(px-xp)f(x)=\frac{\hbar}{i}f(x)\quad \Longrightarrow \quad [p,x]f=\frac{\hbar}{i}f \Longrightarrow [p,x]=\frac{\hbar}{i}\;.
\end{equation}
Da ciò si evince che l'operatore $xp$ non è hermitiano, infatti:
$$
(xp)^{\dagger}=p^{\dagger}x^{\dagger}=px\ne xp\;.
$$
Risolviamo questo inconveniente simmetrizzando il $qp$ della meccanica classica:
$$
qp \longmapsto \frac{xp+px}{2}\;,
$$
che è hermitiano. Infine, introduciamo la \textit{regola di commutazione canonica}:
\begin{equation}
[p,x]=\frac{\hbar}{i}\;,
\end{equation}
in luogo della parentesi di Poisson canonica classica $\{p,q\}=-1$.
\subsection*{Propagazione di un pacchetto d'onda}
Prendiamo in esame un pacchetto d'onda:
$$
f(q)=Ce^{-q^2/2\sigma^2}\;,
$$
e scriviamo la funzione d'onda in termini di $k=p/\hbar$ e $\omega=\mathcal{E}/\hbar$:
\begin{equation}
\psi(x,t)=\int f(k-k_0)e^{ikx-i\omega(k)t}\frac{\diff{k}}{2\pi}\;.
\end{equation}
Scriviamo $k=k_0+q$, allora si ha:
$$
\omega(k)=\omega(k_0+q)=\omega(k_0)+q\left.\pdev{\omega}{k}\right|_{k=k_0}+\frac{1}{2}q^2\left.\pdev[2]{\omega}{k}\right|_{k=k_0}\equiv \omega_0+\omega_0'q+\frac{1}{2}\omega_0''q^2\;,
$$
dove $\omega(k)=\hbar k^2/2m$. La funzione d'onda diventa perciò:
\begin{align*}
\psi(x,t)&= \int f(q)e^{ik_0x+iqx}\frac{\diff{q}}{2\pi}e^{-i(\omega_0t+q\omega_0't+q^2\omega_0''t/2)} \\
&= e^{ik_0x-i\omega_0t}\int \exp\left[-\frac{q^2}{2\sigma^2}-i\frac{q^2\omega_0''t}{2}+iq(x-\omega_0't)\right]\frac{\diff{q}}{2\pi} \\
&= e^{ik_0x-i\omega_0t}\int \exp\left[-\frac{1}{2}q^2\left(\frac{1}{\sigma^2}+i\omega_0''t\right)+iq(x-\omega_0't)\right]\frac{\diff{q}}{2\pi}
\\
&=e^{ik_0x-i\omega_0t}C\exp\left[-\frac{1}{2}\Sigma^2(x-\omega_0't)^2\right]\;,
\end{align*}
dove abbiamo usato il fatto che la trasformata di una gaussiana è ancora una gaussiana e abbiamo posto:
$$
\frac{1}{\Sigma^2}=\frac{1}{\sigma^2}+i\omega_0''t\;.
$$
Il massimo della funzione d'onda è per $x=\omega_0't$. La velocità di gruppo è data da:
$$
v_g=\left.\pdev{\omega}{k}\right|_{k=k_0}=\frac{\hbar k_0}{m}\;.
$$
Osserviamo che a $t=0$ $\Delta x \sim 1/\sigma$ e $\Delta q \sim \sigma$, da cui $\Delta x\Delta q \sim 1$ e, moltiplicando per $\hbar$, ricaviamo il noto \textit{principio di indeterminazione di Heisenberg}:
\begin{equation}
\Delta x\Delta p \sim \hbar\;.
\end{equation}
Riscriviamo $\Sigma$:
$$
\mathrm{Re}(\Sigma^2)=\mathrm{Re}\left[\frac{\sigma^2(1-i\omega_0''t\sigma^2)}{1+(\omega_0''t\sigma^2)^2}\right]=\frac{\sigma^2}{1+(\omega_0''t\sigma^2)^2}\;.
$$
Per $t$ sufficientemente grande:
$$
\mathrm{Re}(\Sigma^2)\longrightarrow \frac{\sigma^2}{(\omega_0''t\sigma^2)^2}\;,
$$
quindi:
$$
\mathrm{Re}(\Sigma)\longrightarrow \frac{1}{\sigma}\frac{1}{\omega_0''t}\;,
$$
dall'espressione di $\omega$ ricaviamo $\omega_0''=\hbar/m$, quindi:
$$
\mathrm{Re}(\Sigma)\sim \frac{m}{\sigma\hbar t}\;.
$$
Allora, per $t$ abbastanza grande:
\begin{align*}
&\Delta x\sim \frac{1}{\Sigma}=\frac{\hbar}{m}\sigma t\quad \implies\quad \Delta x=\frac{\Delta p}{m}t\;, \\
&\Delta q\sim\sigma\;.
\end{align*}
\section{Autostati ed autovalori dell'equazione di Schrödinger}
Abbiamo visto che $\Delta x\Delta p\ge \hbar$, o in termini del numero d'onda $k$ $\Delta x\Delta k\ge 1$ e che i valori medi degli 
operatori $x$ e $p$ sono dati da:
\begin{align*}
&\bar{x}=\int\psi^* x\psi^*\,\diff{x}\;, \\
&\bar{p}=\int\psi^*\frac{\hbar}{i}\frac{\partial}{\partial x}\psi\,\diff{x}\;.
\end{align*}
Adesso vogliamo calcolare, dato un operatore $A$, il suo scarto quadratico medio, definito da:
$$
\Delta A^2=\overline{A^2}-\bar{A}^2\quad  \Longrightarrow\quad \Delta A=\sqrt{\overline{A^2}-\bar{A}^2}\;.
$$
In particolare, vogliamo calcolarlo per gli operatori $x$ e $p$. Possiamo sempre scegliere il sistema di riferimento in modo tale 
che $\bar{x}=\bar{p}=0$ (per facilitare i conti), quindi $\Delta x^2=\overline{x^2}$ e $\Delta p^2=\overline{p^2}$. Consideriamo 
l'integrale:
\begin{equation}
 \int \left|\alpha x\psi+\frac{\partial}{\partial x}\psi\right|^2\;\diff{x}\;,
\end{equation}
che deve essere necessariamente positivo. Allora, sviluppando il modulo quadro:
$$
 \int \left|\alpha x\psi+\frac{\partial}{\partial x}\psi\right|^2\;\diff{x} = \int \alpha^2 x^2 \psi^*\psi\;\diff{x}+\int \pdev{\psi^*}
 {x}\pdev{\psi}{x}\;\diff{x}+\alpha\int x\left(\psi^*\pdev{\psi}{x}+\psi\pdev{\psi^*}{x}\right)\diff{x}\;.
 $$
 Notiamo che:
 \begin{align}
 &\int\alpha^2x^2\psi^*\psi\,\diff{x}=\alpha^2\overline{x^2}=\alpha^2\Delta x^2\;, \\
 &\int \pdev{\psi^*}{x}\pdev{\psi}{x}\,\diff{x}=\frac{\overline{p^2}}{\hbar^2}=\frac{\Delta p^2}{\hbar^2}\;.
 \end{align}
Quindi:
$$
 \int \left|\alpha x\psi+\frac{\partial}{\partial x}\psi\right|^2\;\diff{x}=\alpha^2\Delta x^2+\frac{1}{\hbar^2}\Delta p^2+\alpha\int x
 \frac{\partial}{\partial x}(\psi^*\psi)\;\diff{x}
 $$
 integrando per parti l'ultimo termine si ottiene infine:
 \begin{equation}
  \alpha^2\Delta x^2+\frac{1}{\hbar^2}\Delta p^2-\alpha\ge 0\;,
 \end{equation}
 che è una disequazione di secondo grado in $\alpha$. Imponendo che il discriminante dell'equazione sia negativo, ci garantiamo la 
 positività del polinomio:
 \begin{equation}
  1-4\Delta x^2\frac{\Delta p^2}{\hbar^2} \le 0 \quad \Longrightarrow\quad  \Delta x\Delta p\ge \frac{\hbar}{2}\;,
 \end{equation}
 che ci restituisce ancora una volta il principio di indeterminazione di Heisenberg. Lo stato per cui si ha la minima indeterminazione è 
 quello per cui $\Delta x\Delta p=\hbar/2$, cioè $\Delta p=\hbar/2\Delta x$. L'equazione in $\alpha$ diventa così:
 $$
 \alpha^2\Delta x^2+\frac{1}{4\Delta x^2}-\alpha=0\;,
 $$
 da cui ricaviamo il valore di $\alpha$ per il quale l'indeterminazione è minima:
 $$
 \left(\alpha-\frac{1}{2\Delta x^2}\right)^2=0\quad \Longrightarrow\quad \alpha=\frac{1}{2\Delta x^2}\;.
 $$
 In questo caso l'integrale di partenza deve di conseguenza essere nullo, e ciò può avvenire se e solo se è nulla la funzione integranda. Otteniamo così l'equazione differenziale:
 \begin{equation}
  \pdev{\psi}{x}+\alpha x \psi=0\;,
 \end{equation}
 che ha come soluzione:
 $$
 \psi(x)=A\exp(-\alpha x^2/2)=A\exp(-x^2/4\Delta x^2)\;.
 $$
Quindi concludiamo che la funzione d'onda avente la minima indeterminazione è un pacchetto d'onda gaussiano. Generalizzando, la $\psi(x)$ appena trovata può essere scritta in un generico sistema di riferimento come:
$$
\psi(x)=A\exp\left[-\frac{(x-x_0)^2}{4\Delta x^2}+ip_0 x\right]\;.
$$
Adesso ci chiediamo come si debba preparare uno stato affinché un osservabile $A$ assuma certamente un certo valore $\lambda$. 
A tal scopo, deve innanzitutto valere:
\begin{equation}
 \bra \psi|(A-\lambda)^2|\psi\ket=0\;, \label{ch2_eigenvalue}
\end{equation}
in quanto $\Delta x^2=\overline{x^2}-\bar{x}^2=\overline{(x-\bar{x})^2}$ e $\lambda$ coincide con il valor medio dell'osservabile. 
Inoltre, poiché $A$ è hermitiano, $\lambda\in\mathbb{R}$ e dalla condizione $A=A^{\dagger}$ ricaviamo che:
$$
(A-\lambda)^2=(A^{\dagger}-\lambda)(A-\lambda)\;,
$$
quindi abbiamo:
\begin{equation}
 \bra \psi|(A^{\dagger}-\lambda)(A-\lambda)|\psi\ket=0\;,
\end{equation}
poiché $(A^{\dagger}-\lambda)=(A-\lambda)^{\dagger}$, quindi la \eqref{ch2_eigenvalue} rappresenta un modulo quadro nullo. L'unico vettore che ha modulo quadro nullo è il vettore nullo stesso, quindi otteniamo:
\begin{equation}
 (A-\lambda)|\psi\ket=0 \Longrightarrow A|\psi\ket=\lambda|\psi\ket\;,
\end{equation}
quindi troviamo che $\lambda$ non può assumere qualunque valore, ma è vincolato dalla condizione che debba essere un autovalore 
dell'operatore $A$ e $|\psi\ket$ debba essere un autovettore. \\
Supponiamo che $A$ abbia infiniti autovalori $a_1,\ldots,a_n,\ldots$ \textit{non degeneri} (cioè di molteplicità algebrica 1) a cui 
corrispondono infiniti autovettori $|e_1\ket,\ldots,|e_n\ket,\ldots$, cioè ad ogni autovalore corrisponde un solo autovettore. Dalla 
geometria, sappiamo che $\bra e_i|e_j\ket=0$ se $i\ne j$, infatti:
$$
\bra e_i|(A^{\dagger}-A)|e_j\ket=0 \qquad \mbox{perché }\; A=A^{\dagger}\;.
$$
Ma $A|e_i\ket=a_ie_i$, $A|e_j\ket=a_je_j$, quindi abbiamo:
$$
\bra e_i|(A^{\dagger}-A)|e_j\ket=(a_i-a_j)\bra e_i|e_j\ket=0\;,
$$
poiché per ipotesi abbiamo $a_i\ne a_j$, otteniamo appunto $\bra e_i|e_j\ket=0$. \\
In $\mathbb{R}^n$, data un matrice $M\in\mathcal{M}(n)$ hermitiana, cioè tale che $(M^*)_{ij}=M^*_{ji}=M_{ij}$, per il teorema spettrale, esiste una base di $\mathbb{R}^n$ $\{v_1,\ldots,v_n\}$ ortogonale costituita da autovettori di $M$. La stessa cosa vale negli spazi di Hilbert: gli autovettori di un operatore hermitiano formano un set completo dello spazio. Quindi dato un operatore $A$ hermitiano avente infiniti autovalori $a_1,\ldots,a_n,\ldots$ distinti e corrispettivi autovettori $|e_1\ket,\ldots,|e_n\ket,\ldots$ si ha che ogni $|\psi\ket$ appartenente allo spazio si può scrivere come combinazione lineare degli $|e_i\ket$:
$$
|\psi\ket=\sum_{n=1}^{\infty} c_i|e_i\ket\;.
$$
Calcoliamo adesso il valor medio dell'osservabile $A$ sullo stato $|\psi\ket$:
\begin{align*}
\bra\psi|A|\psi\ket &= \left(\sum_{i=1}^{\infty} c_i^* \bra e_i|\right)A\left(\sum_{j=1}^{\infty} c_j|e_j\ket\right)= \sum_{i=1}^{\infty} c_i^* \bra e_i|\sum_{j=1}^{\infty} a_jc_j|e_j\ket \\
&= \sum_{i=1}^{\infty} |c_i|^2a_i\;,
\end{align*}
con la condizione:
\begin{equation}
\sum_{i=1}^{\infty} |c_i|^2 =1\;.
\end{equation}
Abbiamo così ritrovato un'espressione che ci ricorda la formulazione della matematica statistica. \\
\\
\textbf{Esempio} \\
\\
Consideriamo il moto unidimensionale di una particella vincolata a muoversi lungo un segmento lungo $L$, cioè tra 0 e $L$. Prendiamo in esame l'operatore \textit{Hamiltoniano}:
$$
\hat{H} \equiv \frac{\hat{p}^2}{2m}\;.
$$
Si vede facilmente che $\ham$ è un operatore hermitiano. Vogliamo calcolarne gli autovalori e i rispettivi autovettori. L'equazione è:
\begin{equation}
\hat{H} \psi=\mathcal{E}\psi\quad \Longleftrightarrow \quad-\frac{\hbar^2}{2m}\dev[2]{\psi}{x}=\mathcal{E}\psi\;,
\end{equation}
dove abbiamo indicato con $\mathcal{E}$ gli autovalori (che rappresentano i possibili valori dell'energia). Poiché la particella non può trovarsi al di fuori dell'intervallo $[0,L]$ la funzione $\psi$ deve essere nulla al di fuori e, per continuità, otteniamo le condizioni al contorno $\psi(0)=\psi(L)=0$. Quindi il problema è il seguente:
\begin{equation}
\begin{cases}
\psi''+\dfrac{2m\mathcal{E}}{\hbar^2}\psi=0\;, \\
\\
\psi(0)=\psi(L)=0\;.
\end{cases}
\end{equation}
Una soluzione possibile dell'equazione è data da:
$$
\psi(x)=A\sin(kx)+B\cos(kx)\;,\qquad\qquad k=\sqrt{\frac{2m\mathcal{E}}{\hbar^2}}\;.
$$
Imponendo la condizione $\psi(0)=0$ troviamo subito $B=0$, quindi $\psi(x)=A\sin(kx)$. Imponendo la seconda condizione troviamo:
$$
A\sin(kL)=0\quad \Longrightarrow \quad kL=n\pi,\quad n=1,\ldots\;,
$$
cioè troviamo che i valori di $k$ sono discretizzati:
$$
k\equiv k_n=\frac{n\pi}{L}\;,
$$
poiché $k^2=2m\mathcal{E}/\hbar^2$, le energie possibili, cioè gli autovalori di $\hat{H}$, sono anch'esse discretizzate e date da:
\begin{equation}
\mathcal{E}_n=\frac{\hbar^2}{2m}\frac{n^2\pi^2}{L^2}\;.
\end{equation}
L'autostato $\psi_n$ relativo al valore dell'energia $\mathcal{E}_n$ sarà:
\begin{equation}
\psi_n(x)=A\sin\left(\frac{n\pi x}{L}\right)\;.
\end{equation}
La costante $A$ va determinata imponendo la condizione di normalizzazione:
$$
\int_0^L |\psi|^2\;\diff{x}=1\;,
$$
cioè:
$$
\int_0^L A^2 \sin^2\left(\frac{n\pi x}{L}\right)\;\diff{x}=A^2\frac{L}{2}\stackrel{!}{=}1 \Longrightarrow A=\sqrt{\frac{2}{L}}\;.
$$
Quindi in definitiva:
\begin{equation}
\psi_n(x)=\sqrt{\frac{2}{L}}\sin\left(\frac{n\pi x}{L}\right)\;.
\end{equation}
Il modulo quadro di $\psi_n$ vale:
$$
|\psi_n(x)|^2=\frac{2}{L}\sin^2\left(\frac{n\pi x}{L}\right)\;.
$$
Se considero un intervallo $\Delta x \gg \lambda$, non riusciamo a distinguere, per $n$ grande, le singole oscillazioni: quello che si osserva è il valor medio di $\sin^2$ che vale $1/2$:
$$
|\psi_n(x)|^2\Delta x \simeq \frac{\Delta x}{L}\;.
$$
In conclusione, per $n$ grande ottengo una distribuzione di probabilità uniforme. Infine, ogni $\psi$ potrà essere scritta in serie di Fourier:
\begin{equation}
\psi(x)=\sqrt{\frac{2}{L}}\sum_{n=1}^{\infty} c_n\sin\left(\frac{n\pi x}{L}\right)\;.
\end{equation}
In generale, dato un osservabile hermitiano $A$ avente autovalori $c_i$ e autovettori $|v_i\ket$, posso scrivere una qualunque funzione $\psi$ come combinazione lineare dei $|v_i\ket$:
$$
\psi(x)=\sum_{i=1}^{\infty} c_i|v_i\ket\;.
$$
Ricordando la funzione d'onda che avevamo scritto per descrivere l'elettrone, cioè la sovrapposizione di onde piane:
$$
\psi(x)=\int \frac{\diff{p}}{2\pi\hbar}e^{ipx/\hbar}\varphi(p)\;,
$$
notiamo che la formulazione integrale rappresenta una specie di limite del continuo della formulazione generale discreta:
\begin{align*}
&\sum_i \longmapsto\int\frac{\diff{p}}{2\pi\hbar}\;, \\
&|v_i\ket\longmapsto e^{ipx/\hbar}\;, \\
&\bra v_i|v_j\ket=\delta_{ij}\longmapsto \int\diff{p}e^{ipx/\hbar}e^{-ip'x/\hbar}=2\pi\hbar\delta(p-p')\;.
\end{align*}
Generalizzando ulteriormente, se ho un operatore $A$ hermitiano e impostiamo l'equazione $A\psi_{\alpha}=\alpha\psi_{\alpha}$ con la condizione di normalizzazione $\bra\alpha|\alpha'\ket=\delta(\alpha-\alpha')$, otteniamo nei due casi:
\begin{align*}
&|\psi\ket =\sum_i c_i|v_i\ket\;,\quad A|v_i\ket=\alpha_i|v_i\ket\;,\quad c_i=\bra v_i|\psi\ket\;,&\mbox{(discreto)}\;, \\
&|\psi\ket=\int\diff{\alpha}\,c_{\alpha}|\alpha\ket\;,\quad \bra\beta|\psi\ket=\int\diff{\alpha}\,c_{\alpha}\bra\beta|\alpha\ket=\int\diff{\alpha}\,c_{\alpha}\delta(\alpha-\beta)=c_{\beta}\;, &\mbox{(continuo)}\;.
\end{align*}
Nel primo caso, la probabilità di ottenere $\alpha_i$ nella misurazione di $A$ è data da $|c_i|^2$; nel secondo caso, la probabilità di avere un certo stato tra $\alpha$ e $\alpha+\diff{\alpha}$ è $\diff{P_{\alpha}}=|c_{\alpha}|^2\diff{\alpha}$. A questo punto, la definizione di valor medio di un operatore deve coincidere con quella statistica. È infatti cosi:
\begin{align*}
\bra\psi|A|\psi\ket &= \left(\int\diff{\alpha}\; \bra\alpha|c_{\alpha}^*\right)A\left(\int\diff{\beta}\;c_{\beta}|\beta\ket\right)=
\int\diff{\alpha}\int\diff{\beta}\;c_{\alpha}^* c_{\beta} \bra\alpha|A|\beta\ket \\
&= \int\diff{\alpha}\int\diff{\beta}\; c_{\alpha}^*c_{\beta}\beta \bra\alpha|\beta\ket=\int\diff{\alpha}\diff{\beta}\; c_{\alpha}^*c_{\beta}\beta\delta(\alpha-\beta) \\
&= \int \diff{\alpha}\;\alpha|c_{\alpha}|^2=\int \alpha\;\diff{P_{\alpha}}\;.
\end{align*}

\textbf{Esempio} \\
\\
Consideriamo una particella libera (inizialmente, tratto il caso unidimensionale): l'operatore hamiltoniano è:
$$
H=\frac{p^2}{2m}=-\frac{\hbar^2}{2m}\frac{\partial^2}{\partial x^2}\;.
$$
Impostiamo l'equazione agli autovalori $\ham \psi=\mathcal{E}\psi$ e ricaviamo i possibili valori dell'energia:
$$
\psi''+\frac{2m\mathcal{E}}{\hbar^2}\psi=0\;.
$$
Assumiamo come condizione che $\psi$ non diverga a $\pm\infty$. Le soluzioni dell'equazione sono (in notazione complessa):
\begin{equation}
\psi(x)=A\exp\left[i\sqrt{\frac{2m\mathcal{E}}{\hbar^2}}x\right]+B\exp\left[-i\sqrt{\frac{2m\mathcal{E}}{\hbar^2}}x\right]\;.
\end{equation}
Sappiamo già che, in quanto autovalore di un operatore hermitiano, $\mathcal{E}\in\mathbb{R}$. In più stavolta, deve essere $\mathcal{E}\ge 0$, perché altrimenti l'unica soluzione che non diverge a $\pm\infty$ è la soluzione nulla. Pertanto abbiamo due soluzioni indipendenti per lo stesso valore di $\mathcal{E}$, cioè gli autovalori hanno degenerazione 2. Fisicamente, ciò è dovuto al fatto che la particella può muoversi o avanti o indietro con lo stesso valore dell'energia (l'unicità è conseguenza delle condizioni iniziali). \\
In tre dimensioni l'equazione diventa:
$$
-\frac{\hbar^2}{2m}\nabla^2\psi=\mathcal{E}\psi\;,\qquad \mathcal{E}\ge 0\;.
$$
e la soluzione sarà:
$$
\psi(\mathbf{x})=A\exp\left[i\frac{\mathbf{p}\cdot \mathbf{x}}{\hbar}\right]\;, \qquad \mathcal{E}=\frac{\mathbf{p}^2}{2m}\;.
$$
In questo caso, fissata $\mathcal{E}$, abbiamo per gli autovalori una degenerazione infinita perché tutti i punti aventi $\mathbf{p}$ tale che $\mathbf{p}^2\le \sqrt{2m\mathcal{E}}$ sono buoni.
\subsection{Compatibilità di osservabili}
Presi due osservabili $A,B$ qualunque, è sempre possibile misurarli contemporaneamente con arbitraria precisione? Consideriamo il commutatore di $A,B$: $[A,B]\equiv AB-BA$. Abbiamo due casi:
\begin{itemize}
\item se $[A,B]=0$, le due osservabili si dicono \textit{compatibili} e possono essere misurate contemporaneamente;
\item se $[A,B]\ne0$, le due osservabili si dicono \textit{non compatibili} e non possono essere misurate contemporaneamente.
\end{itemize}
Perché la condizione $[A,B]=0$ mi garantisce questa cosa? Prendiamo due osservabili $A,B$ che commutano, $AB=BA$. Sia $|f_i\ket$ un autovettore per $B$ relativo all'autovalore $\lambda_i$: $B|f_i\ket=\lambda_i |f_i\ket$. Allora, anche $A|f_i\ket$ è autovettore per $B$ relativo allo stesso autovalore, infatti:
$$
BA|f_i\ket=AB|f_i\ket=A\lambda_i|f_i\ket=\lambda_iA|f_i\ket\;.
$$
Se possiamo diagonalizzare $B$, allora possiamo diagonalizzare anche $A$, cioè esiste una base comune di autovettori. In quella base, sono ben definiti $a_ip_i$ e $b_ip_i$, cioè i valori possibili delle due osservabili e le loro probabilità, quindi $A,B$ possono essere misurate contemporaneamente se $[A,B]=0$.
 \\
Le osservabili devono essere rappresentate da un operatore hermitiano: 
$$
A=A^{\dagger}\quad \Longleftrightarrow \quad A_{ji}^*=A_{ij}\;.
$$
Gli operatori hermitiani ammettono una base di autovettori dello spazio $\ham$ di Hilbert su cui sono definiti, in termini di stati:
$$
A\left(\frac{\mathrm{\partial}}{\partial x},x\right)\psi(x)=\lambda\psi(x)\;.
$$
Se gli autovalori sono discreti $A\psi_i=\lambda_i\psi_i$, allora la condizione di normalizzazione è:
\begin{equation}
\int |\psi(x)|^2\;\diff{x}=1\;.
\end{equation}
Se invece sono continui: $A\psi_{\alpha}(x)=\lambda_{\alpha}\psi_{\alpha}(x)$, allora la condizione di normalizzazione è:
\begin{equation}
\int\diff{\alpha}\;\psi_{\alpha}(x)\psi_{\beta}(x)=\delta(\alpha-\beta)\;.
\end{equation}
Se abbiamo un set completo di autovettori (discreti e continui), per ogni $\psi(x)$ si ha:
\begin{equation}
\psi(x)=\sum_i c_i f_i(x)+\int\diff{\alpha}\; c_{\alpha}f_{\alpha}(x)\;, \label{ch2_psisviluppo}
\end{equation}
moltiplico per $f_j^*(x)$ e integro su $x$:
\begin{align*}
\int f_j^*(x)\psi(x)\;\diff{x}&= \sum_i c_i\int f_j^*(x)f_i(x)\;\diff{x}+\int\diff{x}\int\diff{\alpha}f_j^*(x)
c_\alpha f_{\alpha}(x) \\
&= \sum_i c_i\delta_{ij}= c_j\;,
\end{align*}
mentre per quelli continui:
\begin{align*}
\int f_{\beta}^*(x)\psi(x)\;\diff{x} &= \sum_i c_i\int\diff{x}\;f_{\beta}^*(x)f_i(x)+\int\diff{\alpha}\;c_{\alpha}f_{\alpha}(x)f_{\beta}^*(x)= \\
&= \int\diff{\alpha}\;c_{\alpha}\delta(\alpha-\beta)=c_{\beta}\;.
\end{align*}
$|c_i|^2$ rappresenta la probabilità che facendo la misura sullo stato $\psi$ si ottenga l'autovalore $i$-esimo (nel caso discreto); $|c_{\alpha}|^2\diff{\alpha}$ rappresenta, nel caso continuo, la probabilità di misurare l'autovalore $\lambda_{\alpha}$ nell'intervallo $[\alpha,\alpha+\diff{\alpha}]$. Possiamo scrivere:
\begin{align*}
\psi(x)&= \sum_i f_i(x)\int\diff{y}\;f_i^*(y)\psi(y)+\int\diff{\alpha}\;f_{\alpha}(x)\int\diff{y}f_{\alpha}^*(y)\psi(y) \\
&= \int\diff{y}\;\psi(y)\sum_i f_i^*(y)f_i(x)+\int\diff{y}\;\psi(y)\int\diff{\alpha}\;f_{\alpha}^*(y)f_{\alpha}(x) \qquad\qquad \mbox{vale per ogni}\; \psi\;,
\end{align*}
troviamo dunque:
\begin{equation}
\psi(x)=\int\diff{y}\;\psi(y)K(x,y)\;,
\end{equation}
dove:
$$
K(x,y)=\sum_i f_i(x)f_i^*(y)+\int\diff{\alpha}\;f_{\alpha}(x)f_{\alpha}^*(y)\;.
$$
Affinché valga la \eqref{ch2_psisviluppo} deve necessariamente essere $K(x,y)=\delta(x-y)$, cioè:
\begin{equation}
\sum_i f_i(x)f_i^*(y)+\int\diff{\alpha}\;f_{\alpha}(x)f_{\alpha}^*(y)=\delta(x-y)\qquad\qquad\mbox{relazione di completezza}\;.
\end{equation}
Nel caso dell'impulso:
$$
p=\frac{\hbar}{i}\frac{\partial}{\partial x}\;, \qquad \frac{\hbar}{i}\frac{\partial}{\partial x}\psi(x)=p\psi(x)\;,
$$
si ha $\psi(x)=e^{ipx/\hbar}$, appartenente allo spettro continuo, dunque:
\begin{equation}
\int\frac{\diff{p}}{2\pi\hbar}e^{ipx/\hbar}e^{-ipx/\hbar}=\delta(x-y)\;.
\end{equation}

\section{Evoluzione della funzione d'onda}
\subsection{Evoluzione temporale}
Vogliamo sapere adesso come evolve nel tempo uno stato $|\psi\ket$. Supponiamo, dato un osservabile $A$, di conoscere per ogni stato $|\psi\ket$ il valor medio $\bra\psi|A|\psi\ket$. Allora l'operatore è completamente individuato; infatti se in generale $|\psi\ket=|\alpha\ket+|\beta\ket$:
\begin{equation}
\bra\psi|A|\psi\ket=\bra\alpha|A|\alpha\ket+\bra\beta|A|\beta\ket+\bra\beta|A|\alpha\ket+\bra\alpha|A|\beta\ket\;,\label{ch2_psi1}
\end{equation}
se $|\psi\ket=|\alpha\ket+i|\beta\ket$ invece:
\begin{equation}
\bra\psi|A|\psi\ket=\bra\alpha|A|\alpha\ket+\bra\beta|A|\beta\ket+i\bra\alpha|A|\beta\ket+i\bra\beta|A|\alpha\ket\;.\label{ch2_psi2}
\end{equation}
Dalla \eqref{ch2_psi1} ricaviamo il valore di $\bra\alpha|A|\beta\ket+\bra\beta|A|\alpha\ket$ (tutti gli altri sono noti perché medie su un certo stato, che per ipotesi conosciamo); dalla \eqref{ch2_p2} ricaviamo invece, per lo stesso motivo, il valore di $\bra\alpha|A|\beta\ket-\bra\beta|A|\alpha\ket$, quindi siamo in grado di calcolare il valore di $\bra\alpha|A|\beta\ket$ per ogni coppia di stati $|\alpha\ket,\;|\beta\ket$. \\
La condizione di normalizzazione a $t=0$ era:
$$
\int |\psi(x,0)|^2\;\diff{x}=1\;,
$$
ma, dato che gli elettroni non spariscono, la condizioni vale ad ogni istante:
\begin{equation}
\int |\psi(x,t)|^2\;\diff{x}=1\qquad \forall t\;,
\end{equation}
cioè, fisicamente, ad ogni istante l'elettrone deve stare da qualche parte. Adesso ci chiediamo cosa possiamo dire, se conosciamo $\psi(x,t)$ dopo un intervallo di tempo $\delta t$. Sappiamo che, al prim'ordine:
\begin{equation}
\psi(x,t+\delta t)=\psi(x,t)+\pdev{\psi}{t}\delta t\;.
\end{equation}
D'altronde, se vale il principio di sovrapposizione, $\psi(x,t+\delta t)$ può essere ottenuta unicamente mediante operatori lineari a partire da $\psi(x,t)$:
\begin{equation}
\psi(x,t+\delta t)=\psi(x,t)+iA\psi(x,t)\delta t\;,\qquad \mbox{A lineare}\;.
\end{equation}
$A$ inoltre deve soddisfare la condizione di normalizzazione. Se $\psi(t+\delta t)=\psi(t)+iA\psi\delta t$, $\psi^*(t+\delta t)=\psi^*(t)-i\psi^*A^{\dagger}\delta t$ (stiamo adesso trascurando la differenza spaziale perché irrilevante), allora:
$$
\int \psi^*\psi\;\diff{x}=1+i\left[\int\diff{x}(\psi^*A\psi-\psi^*A^{\dagger}\psi)\delta t\right]+\mathcal{O}(\delta t^2)\stackrel{!}{=}1\:,
$$
implica che:
$$
\int\diff{x}(\psi^*A\psi-\psi^*A^{\dagger}\psi)\delta t=0\;,
$$
da cui si deduce che $A=A^{\dagger}$, cioè $A$ è hermitiano. Quindi concludiamo che:
$$
\pdev{\psi}{t}=iA\psi\equiv -\frac{i}{\hbar}H\psi\;,
$$
dove $H$ è l'operatore hamiltoniano, definito da:
\begin{equation}
H\psi=i\hbar\pdev{\psi}{t}\;.
\end{equation}
Questa è l'equazione che descrive l'evoluzione temporale di un certo stato. \\
Nell'ipotesi di de Broglie, per esempio:
$$
\psi(x,t)=\int \frac{\diff{k}}{2\pi} e^{ikx}f(k)e^{-i\omega t}\;,
$$
dato che $\hbar\omega=\mathcal{E}$, $\hbar k=p$ e $\mathcal{E}=p^2/2m=(\hbar k)^2/2m$, si ottiene $\omega=(\hbar k^2)/2m$, quindi:
$$
\psi(x,t)=\int\frac{\diff{k}}{2\pi}e^{ikx}f(k)e^{-i\hbar k^2t/2m}\;,
$$
in questo caso $H=p^2/2m$ (in generale, con un potenziale esterno, $H=p^2/2m+V(q)$).
\subsection{Principio di Maupertuis e equazione di Schrödinger}
Se consideriamo un'onda avente velocità di fase $u=c/n$, con $n$ indice di rifrazione del mezzo, la traiettoria dell'onda era data in ottica geometrica dal \textit{principio di Fermat}:
\begin{equation}
\delta\int\frac{\diff{s}}{u}=0\;.
\end{equation}
In Meccanica Classica, l'analogo principio è il \textit{principio di Maupertuis}:
\begin{equation}
\delta\int\diff{s}\sqrt{\mathcal{E}-V}=0\;.
\end{equation}
Se vogliamo che i due principi siano in qualche modo equivalenti deve sussistere una relazione del tipo:
$$
\frac{1}{u}=f(\omega)\sqrt{\mathcal{E}-U}\;.
$$
Sappiamo che:
$$
\frac{1}{v_g}=\dev{k}{\omega}\;.
$$
La velocità di una particella è:
\begin{equation}
v_p=\frac{p}{m}=\frac{\sqrt{2m(\mathcal{E}-U)}}{m}=\sqrt{\frac{2}{m}}\sqrt{\mathcal{E}-U}\;.
\end{equation}
Imponiamo che $v_p=v_g$, cioè $1/v_p=1/v_g=\diff{k}/\diff{\omega}$, $k=\omega/u$:
\begin{equation}
\sqrt{\frac{m}{2}}\frac{1}{\sqrt{\mathcal{E}-U}}=\frac{\mathrm{d}}{\diff{\omega}}(\omega f(\omega)\sqrt{\mathcal{E}-U}=\frac{\mathrm{d}}{\diff{\omega}}(\omega f(\omega))\sqrt{\mathcal{E}-U}+\frac{\omega f}{2\sqrt{\mathcal{E}-U}}\dev{\mathcal{E}}{\omega}\;, \label{ch2_equation}
\end{equation}
Affinché il secondo membro abbia la stessa dipendenza spaziale del primo, impongo che $\diff{(\omega f)}/\diff{\omega}=0$, cioè $\omega f=$ cost. Inoltre, a primo membro non abbiamo dipendenza da $\omega$, quindi neanche il secondo membro deve dipendere da $\omega$. Abbiamo già imposto che $\omega f$ sia costante, perciò deve essere $\diff{\mathcal{E}}/\diff{\omega}=$ cost., in particolare $\mathcal{E}=\hbar\omega$. Quindi possiamo ricavare $f$ dalla \eqref{ch2_equation}, ottenendo:
\begin{equation}
f=\frac{\sqrt{2m}}{\hbar}\frac{1}{\omega}\;.
\end{equation}
Allora:
\begin{equation}
k=\frac{\omega}{u}=\omega f(\omega)\sqrt{\mathcal{E}-U}=\frac{p}{\hbar}\;.
\end{equation}
Descrivendo $\psi$ come onda:
$$
\nabla^2\psi+\frac{\omega^2}{u^2}\psi=0\;.
$$
Sostituisco quanto trovato:
$$
\nabla^2\psi+\omega^2\frac{2m}{\hbar^2}\frac{\mathcal{E}-U}{\omega^2}\psi=0\;.
$$
Otteniamo quindi l'equazione di Schrödinger come caso limite dell'ottica geometrica:
\begin{equation}
\frac{\hbar^2}{2m}\nabla^2\psi+(\mathcal{E}-U)\psi=0\;.
\end{equation}
\subsection{Evoluzione spaziale}
Dato uno stato $\psi(x)$, effettuando una traslazione di $a$ sappiamo che il nuovo stato $\psi_a$ è legato a $\psi$ dalla relazione:
$$
\psi_a(x)=\psi(x-a)\;.
$$
Vogliamo adesso cercare un operatore $T_a$ che descriva la traslazione, cioè $T_a\psi(x)=\psi(x-a)$. Sviluppo la funzione traslata in serie di Taylor:
\begin{align}
\psi(x-a)&=\sum_{n=0}^{\infty} \frac{(-a)^n}{n!}\dev[n]{\psi}{x}=\sum_{n=0}^{\infty}\frac{1}{n!}\left(\frac{-ia}{\hbar}\right)^np^n\psi \notag \\
&=\exp\left(-\frac{ia}{\hbar}p\right)\psi\;.
\end{align}
Quindi l'operatore di traslazione si scrive:
\begin{equation}
T_a\equiv e^{-iap/\hbar}\;.
\end{equation}
Notiamo che $T_a^{\dagger}=e^{iap/\hbar}=(T_a)^{-1}$, quindi $T_a$ è un operatore unitario. Se trasliamo di una quantità $a\ll 1$, sviluppando al prim'ordine:
\begin{equation}
T_a\simeq 1-i\frac{a}{\hbar}p+\mathcal{O}(a^2)\;.
\end{equation}
Da cui si evince che $p$ è il generatore infinitesimale delle traslazioni spaziali. \\
\\
Riprendendo il discorso sull'operatore Hamiltoniano:
$$
\pdev{\psi}{t}=-i\frac{H}{\hbar}\psi\quad \Longrightarrow \quad \psi(t)=e^{-iH t/\hbar}\simeq 1-\frac{i}{\hbar}H t\;,
$$
quindi $H$ è il generatore infinitesimale delle traslazioni temporali.
\section{Operatori e stati stazionari}
In generale, la forma dell'equazione di Schrödinger dipendente dal tempo è:
$$
i\hbar\frac{\partial}{\partial t}|\psi(t)\ket=H|\psi(t)\ket\;,
$$
che ha come soluzione:
$$
|\psi_i(t)\ket=e^{-i\mathcal{E}_it/\hbar}|\psi_i(0)\ket\;.
$$
Questi sono detti \textit{stati stazionari}. In particolare, si ha che:
\begin{equation}
\bra\psi_i(t)|A|\psi_(t)\ket=\bra\psi_i(0)|A|\psi_i(0)\ket\;,
\end{equation}
cioè il valor medio di un osservabile su uno stato stazionario non dipende dal tempo. Per uno stato non stazionario:
$$
\bra\alpha(0)|A|\beta(0)\ket \quad \longrightarrow\quad \bra\alpha(t)|A|\beta(t)\ket\;,
$$
con $|\alpha(t)\ket=\exp(-iH t/\hbar)|\alpha(0)\ket$ e $|\beta(t)\ket=\exp(-iH t/\hbar)|\beta(0)\ket$, quindi:
$$
\bra\alpha(t)|A|\beta(t)\ket\equiv \bra A\ket =\bra\alpha(0)|e^{iH t/\hbar}Ae^{-iH t/\hbar}|\beta(0)\ket\;.
$$
Derivando rispetto al tempo:
\begin{align*}
\frac{\mathrm{d}}{\diff{t}}\bra A\ket &= \frac{i}{\hbar}\bra \alpha_0|e^{iH t/\hbar}\ham Ae^{-iH t/\hbar}-e^{iH t/\hbar}AH e^{-iH t/\hbar}|\beta_0\ket \\
&= \frac{i}{\hbar}\bra\alpha(t)|H A-AH|\beta(t)\ket\;,
\end{align*}
quindi il valor medio dell'osservabile non dipende dal tempo se e solo se $[H,A]=0$, cioè $A$ commuta con l'operatore Hamiltoniano. Deduciamo pertanto che gli unici osservabili che sono costanti del moto sono quelli che commutano con l'Hamiltoniana. \\
Consideriamo adesso un pacchetto d'onda e calcoliamo le derivate dei valori medi di $x,p$:
\begin{align*}
\bra\psi(t)|x|\psi(t)\ket &\equiv \bra x\ket\;, \\
\frac{\mathrm{d}}{\mathrm{d}t}\bra x\ket&=\left\langle\frac{i}{\hbar}[H,x]\right\rangle\;.
\end{align*}
Se $H=p^2/2m+V(x)$,
$$
[H,x]=\frac{1}{2m}[p^2,x]+[V(x),x]=\frac{p}{m}[p,x]=\frac{\hbar}{im}p\;,
$$
quindi:
\begin{equation}
\frac{\mathrm{d}}{\diff{t}}\bra x \ket=\frac{\bra p\ket}{m}\;,
\end{equation}
che corrisponde alla prima equazione di Hamilton. Invece:
$$
\frac{\mathrm{d}}{\diff{t}}\bra p\ket=\bra\frac{i}{\hbar}[\ham,p]\ket=\bra \frac{i}{\hbar}[V(x),p]\ket=
-\bra\frac{i}{\hbar}[p,V(x)]\ket\;.
$$
In generale vale la relazione $[p,x^n]=n\hbar x^{n-1}/i=-i\hbar\partial_x x^n$, quindi:
$$
[p,V(x)]=\frac{\hbar}{i}\pdev{V}{x}\;,
$$
da cui segue:
\begin{equation}
\frac{\mathrm{d}}{\diff{t}}\bra p\ket=-\left\langle\pdev{V}{x}\right\rangle\;,
\end{equation}
che corrisponde con la seconda equazione di Hamilton. \\
\\
Adesso consideriamo una generica funzione $f(x,p)$ ed eseguiamo la trasformazione:
\begin{equation}
G(a)=e^{ipa/\hbar}f(x,p)e^{-ipa/\hbar}\;. \label{ch2_transformation}
\end{equation}
Si ha:
\begin{align*}
G(0) &=f(x,p)\;, \\
G'(0) &= \frac{i}{\hbar}\left.(pG-Gp)\right|_{a=0}=\frac{i}{\hbar}[p,f]=\pdev{f}{x}\;, \\
G''(0) &= \pdev[2]{f}{x}\;.
\end{align*}
Quindi, sviluppano $G$ in serie di Taylor:
$$
G(a)=\sum_{n=0}^{\infty}\frac{a^n}{n!}G^{(n)}(0)=\sum_{n=0}^{\infty} \frac{a^n}{n!}f^{(n)}(x)=f(x+a,p)\;,
$$
perciò abbiamo dimostrato che una trasformazione del tipo \eqref{ch2_transformation} coincide con una traslazione spaziale. Un modo alternativo per dimostrarlo è considerare $f(x,p)=x$, allora:
\begin{align*}
G(a) &= e^{ipa/\hbar}xe^{-ipa/\hbar}\;, \\
G(0) &= x\;, \\
G'(0)&=\frac{i}{\hbar}[p,x]=1\;.
\end{align*}
Da cui ricaviamo il problema di Cauchy:
\begin{equation}
\begin{cases}
G'(a)=1\;, \\
\\
G(0)=x\;,
\end{cases}\quad \Longrightarrow\quad G(a)=x+a\;.
\end{equation}
Ricordando che $U\equiv e^{ipa/\hbar}$ è un operatore unitario ($UU^{-1}=1$), possiamo scrivere:
$$
Ux^nU^{-1}=UxU^{-1}UxU^{-1}\cdots UxU^{-1}=(x+a)^n\;.
$$
\section{Equazione di continuità}
Vogliamo adesso scrivere un'equazione di continuità per la funzione d'onda. Sappiamo che $\forall t$:
\begin{align*}
\int |\psi(\mathbf{x},t|^2\,\diff^3{x} &= 1\;, \\
\rho\equiv |\psi(\mathbf{x},t)|^2=\psi^*\psi\;,
\end{align*}
dove $\rho$, in analogia con il caso elettromagnetico, rappresenta una densità (in questo caso di probabilità). \\
Inoltre, se l'Hamiltoniana del sistema è $H=\mathbf{p}^2/2m+V(\mathbf{x})$, abbiamo le equazioni:
\begin{align}
\pdev{\psi}{t}&=-\frac{i}{\hbar}H\psi\;, \\
\pdev{\psi^*}{t}&= \frac{i}{\hbar}H^*\psi^*\;.
\end{align}
Dunque (ricordando che $V$ è una funzione reale e quindi $V=V^*$):
\begin{align*}
\pdev{\rho}{t}&=\frac{i}{\hbar}[-\psi^*H\psi+(H^*\psi^*)\psi]=\frac{i}{\hbar}\left[\frac{\hbar^2}{2m} \psi^*
\nabla^2\psi-\psi\nabla^2 \psi^*\right] \\
&= \frac{i\hbar}{2m}[\psi^*\nabla^2\psi-\psi\nabla^2\psi^*]=\frac{i\hbar}{2m}\nabla\dot[\psi^*\nabla\psi-\psi\nabla\psi^*] \\
&=\nabla\cdot \boldsymbol{\mathcal{J}}\;,
\end{align*}
quindi l'equivalente della corrente in questo caso è:
\begin{equation}
\boldsymbol{\mathcal{J}}\equiv \frac{\hbar}{2mi}(\psi^*\nabla\psi-\psi\nabla\psi^*)\;.
\end{equation}
Per un'onda piana è $\psi=e^{i\mathbf{k}\cdot\mathbf{x}}$, quindi:
$$
\boldsymbol{\mathcal{J}}=\frac{h\mathbf{k}}{m}=\frac{\mathbf{p}}{m}=\mathbf{v}\;.
$$
\section{Teorema di Hellmann-Feynman}
\begin{thm}[Hellmann-Feynman] Prendiamo uno stato descritto dall'Hamiltoniana:
$$
H=\frac{\mathbf{p}^2}{2m}+V(\lambda,x)\;,
$$
dove $\lambda$ è un parametro, avente autovalori discreti $\mathcal{E}_n(\lambda)$ dipendenti da $\lambda$ e autostati $\psi_n(\lambda,x)$. Allora:
$$
\dev{\mathcal{E}_n}{\lambda}=\bra\psi_n|\pdev{V}{\lambda}|\psi_n\ket\;.
$$
\end{thm}
\proof
Sappiamo che
$$
\mathcal{E}_n(\lambda)=\int\diff{x}\;\psi_n^*H\psi_n\;.
$$
Allora:
\begin{align*}
\dev{\mathcal{E}_n}{\lambda}&= \int\diff{x}\;\psi^*\pdev{H}{\lambda}\psi_n+\int\diff{x}\left(\pdev{\psi_n^*}{\lambda}H\psi_n+\psi_n^*H\pdev{\psi_n}{\lambda}\right) \\
&= \int\diff{x}\,\psi_n^*\pdev{H}{\lambda}\psi_n+\mathcal{E}_n\int\diff{x}\left(\pdev{\psi_n^*}{\lambda}\psi_n+
\psi_n^*\pdev{\psi_n}{\lambda}\right) \\
&=\int\diff{x}\;\psi_n^*\pdev{\ham}{\lambda}\psi_n+\mathcal{E}_n\frac{\partial}{\partial\lambda}\int\diff{x}\;
|\psi|^2\;.
\end{align*}
Ma $\partial_{\lambda}\int\diff{x}\;|\psi|^2=\partial_{\lambda}(1)=0$, quindi otteniamo:
$$
\dev{\mathcal{E}_n}{\lambda}=\int\diff{x}\;\psi_n^*\pdev{H}{\lambda}\psi_n=\bra\psi_n|\pdev{H}{\lambda}|\psi_n\ket=\bra\psi|\pdev{V}{\lambda}|\psi\ket\;.
$$
\endproof
\section{Proiettori e matrici di Pauli}
Dato uno spazio di Hilbert $\ham$ con base ortonormale $\{|e_n\ket\}$, ogni vettore $|v\ket\in \ham$ può essere scritto in modo unico come:
$$
|v\ket=\sum_{n=1}^{\infty} |e_n\ket\bra e_n|v\ket\;,
$$
quindi, ogni singolo addendo $|e_k\ket\bra e_k|v\ket$ rappresenta una proiezione sul versore $|e_k\ket$. Di conseguenza l'operatore:
\begin{equation}
\Pi_k\equiv |e_k\ket\bra e_k|\;,
\end{equation}
è un proiettore. Vale la proprietà che la somma di tutti i proiettori di uno spazio è l'identità. Da questa proprietà discende la relazione di completezza, infatti:
$$
1=\sum_k \Pi_k=\sum_k |e_k\ket\bra e_k|\;.
$$
Sapevamo inoltre che il modulo quadro di $c_k=\bra e_k|v\ket$ è la probabilità di ottenere l'autostato $k$-esimo:
\begin{equation}
|c_k|^2=|\bra e_k|v\ket|^2=\bra v|e_k\ket\bra e_k|v\ket\equiv \bra v|\Pi_k|v\ket\;,
\end{equation}
cioè otteniamo che la probabilità può essere interpretata come il valor medio del proiettore sul relativo sottospazio. \\
Se $A$ è un osservabile con autovalori $\lambda_k$ e autovettori $|f_k\ket$ allora $A$ può essere scritto come somma di prioettori:
$$
A=\sum_k \lambda_k\Pi_k=\sum_k \lambda_k|f_k\ket\bra f_k|\;,
$$
infatti:
$$
A|f_j\ket=\sum_k\lambda_k|f_k\ket\bra f_k|f_j\ket=\sum_k \lambda_k|f_k\ket \delta_{kj}=\lambda_j|f_j\ket\;.
$$
\subsection*{Polarizzazione della luce}
Consideriamo un'onda piana monocromatica che si muove in direzione $\mathbf{\hat{z}}$. Il campo elettrico dell'onda sarà in generale:
\begin{align*}
\mathbf{E}_x &= |E_x|\cos(kz-\omega t+\phi_x)\mathbf{\hat{x}}\;, \\
\mathbf{E}_y &= |E_y|\cos(kz-\omega t+\phi_y)\mathbf{\hat{y}}\;,
\end{align*}
la polarizzazione dipenderà dallo sfasamento $\Delta\phi=\phi_x-\phi_y$:
\begin{itemize}
\item se $\Delta\phi=0$, la polarizzazione è lineare;
\item se $\Delta\phi=\pi/2$, la polarizzazione è circolare;
\item se $0<\Delta\phi<\pi/2$, la polarizzazione è ellittica.
\end{itemize}
Adesso facciamo incidere la luce su un cristallo di calcite. All'uscita avremo due raggi, uno polarizzato lungo $\mathbf{x}$ e l'altro lungo $\mathbf{y}$. Inseriamo quindi un assorbitore o sopra o sotto, che quindi farà passare un solo tipo di polarizzazione. Abbiamo dunque costruito un filtro che possiamo schematizzare nel seguente modo:
$$
\rightsquigarrow \left[
\begin{matrix}
\mathrm{O} \\
\mathrm{X}
\end{matrix}\right]\stackrel{x}{\rightsquigarrow}\;,
$$
se mettiamo l'assorbitore in modo tale da far passare solo la luce polarizzata lungo $\mathbf{x}$, altrimenti:
$$
\rightsquigarrow \left[
\begin{matrix}
\mathrm{O} \\
\mathrm{X}
\end{matrix}\right]\stackrel{y}{\rightsquigarrow}\;,
$$
se mettiamo l'assorbitore in modo tale da far passare solo la luce polarizzata lungo $\mathbf{y}$. Definiamo quindi a questo punto \textit{stato del fotone} l'uscita dal primo filtro. Possiamo realizzare anche i seguenti sistemi:
$$
\rightsquigarrow \left[
\begin{matrix}
\mathrm{O} \\
\mathrm{X}
\end{matrix}\right] \stackrel{x}{\rightsquigarrow}
\left[\begin{matrix}
\mathrm{O} \\
\mathrm{X}
\end{matrix}\right] \stackrel{x}{\rightsquigarrow}\;,
$$
$$
\rightsquigarrow \left[
\begin{matrix}
\mathrm{O} \\
\mathrm{X}
\end{matrix}\right]\stackrel{x}{\rightsquigarrow}
\left[\begin{matrix}
\mathrm{X} \\
\mathrm{O}
\end{matrix}\right] \stackrel{0}{\rightsquigarrow}\;,
$$
dove $0$ indica che non è passato nulla. Indichiamo adesso con $e_1,e_2$ rispettivamente lo stato con polarizzazione $\mathbf{x}$ e $\mathbf{y}$ e consideriamo il seguente schema:
$$
\rightsquigarrow \left[
\begin{matrix}
\mathrm{O} \\
\mathrm{X}
\end{matrix}\right] \stackrel{e_1}{\rightsquigarrow}
\left\{ \begin{matrix}
\mathrm{O} \\
\mathrm{X}
\end{matrix}\right\} \stackrel{f_1}{\rightsquigarrow}\;,
$$
dove il secondo filtro è simile al primo, cioè ha in uscita solo due stati possibili $f_1,f_2$, ma leggermente diverso da esso (i.e. ruotato di un certo angolo $\vartheta$). Definiamo adesso l'\textit{ampiezza di probabilità} (in analogia con l'esperimento di Young):
\begin{align}
P_i &\equiv |\bra f_i|e_1\ket|^2 \qquad\qquad \mbox{se il primo filtro lascia passare $e_1$}\;, \\
P_i &\equiv |\bra f_i|e_2\ket|^2 \qquad\qquad \mbox{se il primo filtro lascia passare $e_2$}\;.
\end{align}
Adesso considero:
$$
\left[\begin{matrix}
\mathrm{O} \\
\mathrm{X}
\end{matrix}\right] \stackrel{e_1}{\rightsquigarrow} \left\{
\begin{matrix}
\mathrm{O} \\
\mathrm{X}
\end{matrix}\right\} \stackrel{f_1}{\rightsquigarrow} \left[
\begin{matrix}
\mathrm{O} \\
\mathrm{X}
\end{matrix}\right] \stackrel{e_1}{\rightsquigarrow}\;.
$$
In termini di ampiezze, partiamo da $|e_1\ket$, arrivo in $\bra f_1|$ ($\bra f_1|e_1\ket$), parto da $|f_1\ket$ ($|f_1\ket\bra f_1|e_1\ket$) e arrivo in $\bra e_1|$ ($\bra e_1|f_1\ket\bra f_1|e_1\ket$), quindi ho $A_1=\bra e_1|f_1\ket\bra f_1|e_1\ket$. Se adesso inseriamo un polarimetro senza filtro in mezzo:
$$
\left[\begin{matrix}
\mathrm{O} \\
\mathrm{X}
\end{matrix}\right] \stackrel{e_1}{\rightsquigarrow}
\left\{\begin{matrix}
\mathrm{O} \\
\mathrm{O}
\end{matrix}\right\} \stackrel{f_1,f_2}{\rightsquigarrow}
\left[\begin{matrix}
\mathrm{O} \\
\mathrm{X}
\end{matrix}\right] \stackrel{e_1}{\rightsquigarrow}\;,
$$
l'ampiezza totale sarà la somma delle ampiezze: $A=\bra e_1|f_1\ket\bra f_1|e_1\ket+\bra e_1|f_2\ket\bra f_2|e_1\ket$. Osserviamo però che il risultato dell'inserimento del polarimetro senza filtro è lo stesso di non avere nulla tra i due filtri esterni, quindi deve essere:
$$
\bra e_1|f_1\ket\bra f_1|e_1\ket+\bra e_1|f_2\ket\bra f_2|e_1\ket=\bra e_1|e_1\ket\;,
$$
che è la relazione di completezza per questo sistema. \\
\\
In termini di vettori e matrici, siano:
$$
|e_1\ket=\left(
\begin{matrix}
1 \\
0
\end{matrix}\right)\;, \qquad
|e_2\ket=\left(
\begin{matrix}
0 \\
1
\end{matrix}\right)\;.
$$
Questi due vettori rappresentano come sappiamo la polarizzazione rispettivamente lungo $\mathbf{x}$ e $\mathbf{y}$. Possiamo rappresentare anche le polarizzazioni circolari destra e sinistra come:
$$
|e_L\ket=\frac{1}{\sqrt{2}}\left(
\begin{matrix}
1 \\
i
\end{matrix}\right)\;,\qquad
|e_R\ket=\frac{1}{\sqrt{2}}\left(
\begin{matrix}
1 \\
-i
\end{matrix}\right)\;.
$$
Allora i filtri possono essere rappresentati con delle matrici. Per esempio, il filtro che lascia passare $\mathbf{x}$ può essere rappresentato da una matrice $M_x$ tale che:
$$
M_x|e_1\ket=|e_1\ket\;,\quad M_x|e_2\ket=0 \quad \Longrightarrow\quad
M_x=\left(
\begin{matrix}
1 & 0 \\
0 & 0
\end{matrix}\right)\;.
$$
Analogamente, per $M_y$ ricaviamo l'espressione:
$$
M_y=\left(
\begin{matrix}
0 & 0 \\
0 & 1
\end{matrix}\right)\;.
$$
Si vede che $M_x.M_y$ sono due proiettori. Adesso occupiamoci del filtro ruotato. Scriviamo:
$$
|f_1\ket=\left(
\begin{matrix}
\cos\vartheta \\
\sin\vartheta
\end{matrix}\right)\;, \qquad
|f_2\ket=\left(
\begin{matrix}
\sin\vartheta \\
\cos\vartheta
\end{matrix}\right)\;.
$$
La prima matrice $M_{\vartheta_1}$ deve essere tale che $M_{\vartheta_1}|f_1\ket=|f_1\ket$ e $M_{\vartheta_1}|f_2\ket=0$. Possiamo scegliere la base in modo tale da ricondurci al caso precedente, cioè in cui $|f_1\ket$ ha componenti $(1,0)$. La matrice che descrive il cambio di base è la matrice di rotazione:
$$
R_{\vartheta_1}=\left(
\begin{matrix}
\cos\vartheta & \sin\vartheta \\
-\sin\vartheta & \cos\vartheta
\end{matrix}\right)\;.
$$
Poiché stiamo operando un cambiamento di base con matrice $R_{\vartheta}$, le matrici $M_x$ e $M_{\vartheta_1}$ saranno legate dalla relazione di similitudine:
$$
M_{\vartheta_1}=R_{\vartheta_1}M_xR_{\vartheta_1}^{-1}\;,
$$
da cui si ottiene ($R_{\vartheta_1}^{-1}={}^tR_{\vartheta_1}$):
$$
M_{\vartheta_1}=\left(
\begin{matrix}
\cos^2\vartheta & \sin\vartheta\cos\vartheta \\
\sin\vartheta\cos\vartheta & \sin^2\vartheta
\end{matrix}\right)\;.
$$
Consideriamo una \textit{lamina a un quarto d'onda}, cioè una lamina tale che:
$$
\left(\begin{matrix}
1 \\
0
\end{matrix}\right) \longmapsto \left(
\begin{matrix}
1 \\
0
\end{matrix}\right)\;, \qquad
\left(\begin{matrix}
0 \\
1
\end{matrix}\right) \longmapsto \left(
\begin{matrix}
0 \\
i
\end{matrix}\right)\;,
$$
rappresentata quindi dalla matrice:
$$
M_{1/4}=\left(
\begin{matrix}
1 & 0 \\
0 & i
\end{matrix}\right)\;.
$$
Se facciamo incidere sulla lamina della luce polarizzata a $45$ gradi, cioè:
$$
e_{45}=\frac{1}{\sqrt{2}}\left(
\begin{matrix}
1 \\
1
\end{matrix}\right)\;,
$$
allora in uscita avremo (svolgendo i calcoli):
$$
M_{1/4}e_{45}=\frac{1}{\sqrt{2}}\left(
\begin{matrix}
1	\\
i
\end{matrix}\right)\;,
$$
cioè della luce a polarizzazione circolare sinistra.
\subsection{Matrici di Pauli}
In due dimensioni, una generica osservabile hermitiana è rappresentata dalla matrice:
$$
\left(\begin{matrix}
a & c+id \\
c-id & b
\end{matrix}\right)\;.
$$
Abbiamo quindi che le matrici hermitiane formano uno spazio vettoriale di dimensione quattro. La prima è la matrice identica:
$$
\mathbb{I}=\left(
\begin{matrix}
1 & 0 \\
0 & 1
\end{matrix}\right)\;,
$$
le altre tre prendono il nome di \textit{matrici di Pauli}:
\begin{equation}
\sigma_1=\sigma_x\equiv \left(
\begin{matrix}
0 & 1 \\
1 & 0
\end{matrix}\right)\;,\quad
\sigma_2=\sigma_y\equiv \left(
\begin{matrix}
0 & -i \\
i & 0
\end{matrix}\right)\;,\quad
\sigma_3=\sigma_z\equiv\left(
\begin{matrix}
1 & 0 \\
0 & -1
\end{matrix}\right)\;.
\end{equation}
Allora, preso una qualunque osservabile $A$, che sappiamo deve essere necessariamente hermitiana, essa può essere scritta (nella rappresentazione matriciale) come combinazione lineari delle quattro matrici sopra descritte:
$$
A=a_0 \mathbb{I}+a_1 \sigma_1+a_2\sigma_2+a_3 \sigma_3\;.
$$
\textbf{Proprietà delle matrici di Pauli} \\
\\
Le matrici di Pauli verificano la seguente relazione:
\begin{equation}
\sigma_i\sigma_j=\delta_{ij}+i\varepsilon_{ijk}\sigma_k\;.
\end{equation}
Inoltre:
\begin{equation}
[\sigma_i,\sigma_j]=2i\varepsilon_{ijk}\sigma_k\;.
\end{equation}
\textbf{Esempio} \\
\\
Consideriamo un sistema a due stati degeneri, descritto nella base degli autostati dall'Hamiltoniana:
$$
H=\left(
\begin{matrix}
\mathcal{E}_0 & 0 \\
0 & \mathcal{E}_0
\end{matrix}\right)\;, \qquad |e_1\ket=\left(
\begin{matrix}
1 \\
0
\end{matrix}\right)\;,\quad |e_2\ket=\left(
\begin{matrix}
0 \\
1
\end{matrix}\right)\;.
$$
In realtà, non possiamo ottenere stati effettivamente degeneri, ma solamente approssimazioni del tipo:
$$
H=\left(
\begin{matrix}
\mathcal{E}_0 & -\varepsilon \\
-\varepsilon & \mathcal{E}_0
\end{matrix}\right)\;.
$$
Gli autovalori adesso sono $\mathcal{E}_1=\mathcal{E}_0-\varepsilon$ e $\mathcal{E}_2=\mathcal{E}_0+\varepsilon$, con autostati rispettivamente:
\begin{align*}
|f\ket&=\frac{1}{\sqrt{2}}\left(
\begin{matrix}
1 \\
1
\end{matrix}\right) \qquad \mbox{fondamentale}\;, \\
|e\ket&=\frac{1}{\sqrt{2}}\left(
\begin{matrix}
1 \\
-1
\end{matrix}\right) \qquad \mbox{eccitato}\;.
\end{align*}
Se per esempio prendiamo come osservabile un dipolo:
$$
D=\left(
\begin{matrix}
d & 0 \\
0 & -d
\end{matrix}\right)\;,
$$
abbiamo che $\bra e_1|D|e_1\ket=d$, cioè come prevede l'elettromagnetismo classico. Ma ciò è valido se l'Hamiltoniana fosse degenere. In realtà devo considerare $|f\ket$ come stato fondamentale, quindi adesso $\bra f|D|f\ket=0$, quindi otteniamo il risultato che in Meccanica Quantistica non esistono dipoli elettrici. Introduciamo l'operatore di parità $\pi$:
\begin{equation}
\pi=\left(
\begin{matrix}
0 & 1 \\
1 & 0
\end{matrix}\right)\;.
\end{equation}
Allora, in termini di matrici di Pauli, abbiamo $H=\mathcal{E}_0-\varepsilon\sigma_1$, $\pi=\sigma_1$, $D=d\sigma_3$. Per le proprietà delle matrici di Pauli si ha $[\pi,D]\ne 0$, quindi le due osservabili non sono compatibili.
\section{Equazione di Schrödinger per la particella legata}
L'equazione di Schrödinger in presenza di un potenziale $V$ prende, in una dimensione, la forma:
\begin{equation}
-\frac{\hbar^2}{2m}\dev[2]{\psi}{x}+V(x)\psi=\mathcal{E}\psi\;.
\end{equation}
Un autostato $\psi\in\mathbb{L}^2$ rappresenta uno stato legato della particella. Riscriviamo l'equazione in termini dell'impulso:
$$
\frac{p^2}{2m}\psi+V(x)\psi=\mathcal{E}\psi\;.
$$
Le ipotesi che facciamo sul potenziale sono che $V(x\to\pm\infty)=+\infty$ oppure costante (escludiamo cioè i casi oscillanti). L'insieme dei valori di $\mathcal{E}$ per cui l'equazione di Schrödinger ha soluzione prende il nome di \textit{spettro dell'Hamiltoniana}. Lasciando solamente il termine con l'impulso a primo membro, moltiplicando a sinistra per $\psi^*$ e infine integrando si ottiene:
\begin{equation}
\int \psi^*\frac{p^2}{2m}\psi\;\diff{x}=\int (\mathcal{E}-V)\psi^*\psi\;\diff{x}\;.
\end{equation}
Il primo integrale è positivo perché $p^2$ è definito positivo, quindi deve essere $\mathcal{E}-V>0$, cioè l'energia cinetica deve essere positiva. Adesso cerchiamo le condizioni per cui sia possibile trovare stati legati. Riscriviamo ancora una volta l'equazione nella forma più comoda:
\begin{equation}
\psi''=\frac{2m}{\hbar^2}(V-\mathcal{E})\psi\;. \label{ch2_schroddy}
\end{equation}
Devo verificare che $\psi$ sia a quadrato integrabile. A $x\to -\infty$, nella regione in cui $V>\mathcal{E}$, si ha dall'equazione $\psi''>0$, supponendo che anche $\psi>0$ (non è restrittivo). La concavità deve quindi invertirsi una volta affinché la funzione non diverga. Precisamente, l'inversione si ha nel punto in cui $\mathcal{E}=V$. Inoltre la concavità deve invertirsi una seconda volta al fine di non divergere a $+\infty$, ma l'inversione non deve avvenire troppo presto rispetto alla prima, altrimenti si ha divergenza. \\
Sappiamo che l'equazione \eqref{ch2_schroddy} ammette due soluzioni linearmente indipendenti:
$$
\psi(x)=c_1\psi_1(x)+c_2\psi_2(x)\;.
$$
Nel limite $V\gg \mathcal{E}$, 
\begin{equation}
\psi(x)=\pm\exp\left[\int_0^x V(x)\;\diff{x}\right]\;.
\end{equation}
In questo caso imporre che $\psi(x\to-\infty)=0$ implica fissare una determinata dipendenza dall'energia: $\psi_a(x)=c_1(\mathcal{E})\psi_1+c_2\mathcal{E}\psi_2$, ma ciò non ci garantisce che valga la stessa cosa per $x\to +\infty$, quindi in generale se imponiamo la convergenza da una parte, quasi automaticamente avremo divergenza dall'altra.
\chapter{Soluzione dell'equazione di Schrödinger}
\section{Sistemi unidimensionali}
Sappiamo che nel caso di sistemi unidimensionali l'operatore Hamiltoniano è della forma:
\begin{equation}
H=-\frac{\hbar^2}{2m}\frac{\mathrm{d}^2}{\diff^2{x}}+V(x)\;.
\end{equation}
Vogliamo studiare l'equazione e capire se esistano stati $\psi\in\mathbb{L}^2$ che soddisfano l'equazione $H\psi=\mathcal{E}\psi$. È interessante studiare questi sistemi perché partendo da essi possiamo studiare anche sistemi in tre dimensioni semplici, come nel caso di Hamiltoniana separabile, cioè per esempio:
\begin{equation}
H=H_x+H_y+H_z=-\frac{\hbar^2}{2m}\left(\frac{\partial^2}{\partial x^2}+\frac{\partial^2}{\partial y^2}+\frac{\partial^2}{\partial z^2}\right)+V_x(x)+V_y(y)+V_z(z)\;.
\end{equation}
Cercando una soluzione del tipo $\psi(x,y,z)=a(x)b(y)c(z)$, sostituendo nell'equazione $H\psi=\mathcal{E}\psi$ si trova:
$$
b(y)c(z)H_x a(x)+a(x)c(z)H_y b(y)+a(x)b(y)H_z c(z)=\mathcal{E}a(x)b(y)c(z)\;,
$$
dividendo questa relazione per $abc$ si ottiene l'espressione:
\begin{equation}
\frac{H_x a(x)}{a(x)}+\frac{H_y b(y)}{b(y)}+\frac{H_z c(z)}{c(z)}=\mathcal{E}\;,
\end{equation}
da cui deduciamo che gli addendi sono singolarmente delle costanti, cioè:
\begin{align*}
\frac{1}{a(x)}H_xa(x) &=\mathcal{E}_1\;, \\
\frac{1}{b(y)}H_yb(y) &=\mathcal{E}_2\;, \\
\frac{1}{c(z)}H_zc(z) &= \mathcal{E}_3\;,
\end{align*}
con $\mathcal{E}=\mathcal{E}_1+\mathcal{E}_2+\mathcal{E}_3$. \\
\\
Ritornando al nostro sistema unidimensionale, possiamo avere due casi principali: $x\in\;]-\infty,+\infty[$, oppure $x\in\;[0,+\infty[$. Nel primo caso, come condizione al contorno, imponiamo la condizione di normalizzazione:
$$
\int_{-\infty}^{+\infty} |\psi|^2\;\diff{x}=1\;.
$$
Nel secondo caso, oltre alla normalizzazione, imponiamo per continuità $\psi(0)=0$. Sia $f(x)=V(x)-\mathcal{E}$, l'equazione diventa:
\begin{equation}
\psi''(x)=\frac{2m}{\hbar^2}f(x)\psi(x)\;. \label{ch3_psiddot}
\end{equation}
Supponiamo inizialmente che $V(x\to\pm\infty)\to +\infty$ ed eseguiamo uno sviluppo asintotico all'infinito. Per $x$ molto grande, $f(x)\simeq V(x)$. La soluzione generale dell'equazione \eqref{ch3_psiddot} sarà:
\begin{equation}
\psi(x)\simeq A\exp\left[\pm\int_{0}^{x}\sqrt{f(x)}\;\diff{x}\right]\;.
\end{equation}
Infatti, sostituendo:
$$
\psi''\simeq Af(x)\exp\left[\pm\int_{0}^{x} \sqrt{f(x)}\;\diff{x}\right]+ A\exp\left[\pm\int_{0}^{x} \sqrt{f(x)}\;\diff{x}\right]\left(\frac{\mathrm{d}}{\diff{x}}\sqrt{f(x)}\right)\;,
$$
il secondo termine è trascurabile rispetto al primo per $x$ abbastanza grande (infatti figura una radice di $f$). Otteniamo quindi che per $x\to -\infty$, $\psi(x)=c_1(\mathcal{E})\exp\left(\int_0^x \sqrt{f(x)}\;\diff{x}\right)$, per $x\to +\infty$, $\psi(x)=c_2(\mathcal{E})\exp\left(\int_0^x \sqrt{f(x)}\;\diff{x}\right)$. Imponendo che $c_1(\mathcal{E})=0$, trovo lo spettro dell'Hamiltoniana. \\
\\
Se invece $V(x\to\pm\infty)=0$, per $x$ molto grande si ha $f(x)\simeq \mathcal{E}$ e l'equazione diventa:
$$
\psi''\simeq -\frac{2m}{\hbar^2}\psi\;,
$$
$\mathcal{E}$ deve essere non positivo, altrimenti non troviamo soluzioni $\mathbb{L}^2$. In tal caso, le soluzioni generali dell'equazione saranno:
\begin{equation}
\psi=c_1(\mathcal{E})\exp\left(\sqrt{\frac{2m|\mathcal{E}|}{\hbar^2}}\cdot x\right)+c_2(\mathcal{E})\exp\left(\sqrt{\frac{2m|\mathcal{E}|}{\hbar^2}}\cdot x\right)\;.
\end{equation}
Nel caso di $\mathcal{E}>0>V$, otteniamo uno spettro continuo con autovalori doppiamente degeneri. \\
\\
Dimostriamo adesso che le soluzioni dell'equazione di Schrödinger unidimensionale nello spettro discreto sono non degeneri. Sia $a_L$ il punto iniziale, in cui vale la condizione $\psi(a_L)=0$. L'equazione è:
$$
\psi''=\frac{2m}{\hbar^2}(V(x)-\mathcal{E})\psi\;.
$$
Prendiamo due soluzioni nello spettro discreto $y_1,y_2$, che soddisfano singolarmente alle equazioni:
\begin{align*}
y_1'' &= \frac{2m}{\hbar^2}(V(x)-\mathcal{E}_1)y_1\;, \\
y_2'' &= \frac{2m}{\hbar^2}(V(x)-\mathcal{E}_2)y_2\;.
\end{align*}
Moltiplichiamo la prima equazione per $y_2$, la seconda per $y_1$ ed eseguiamo la differenza:
\begin{equation}
y_2y_1''-y_1y_2''=\frac{2m}{\hbar^2}(\mathcal{E}_2-\mathcal{E}_1)y_1y_2\;. \label{ch3_differenza}
\end{equation}
Adesso supponiamo che $\mathcal{E}_1=\mathcal{E}_2$, cioè che l'autovalore sia degenere e ammetti come autostati $y_1,y_2$ distinti. Quindi la \eqref{ch3_differenza} diventa:
\begin{equation}
y_2y_1''-y_1y_2''=\frac{\mathrm{d}}{\diff{x}}(y_2y_1'-y_1y_2')=0\;,
\end{equation}
cioè la quantità $W(x)\equiv y_2y_1'-y_1y_2'$ (detta \textit{Wronskiano}) è costante. In particolare sarà costante in $x=a_L$, dove $\psi$ è nulla, quindi:
$$
y_2y_1'-y_1y_2'=0\quad \Longleftrightarrow \quad y_2y_1'=y_1y_2'\;,
$$
dividiamo per $y_1y_2$:
$$
\frac{y_1'}{y_1}=\frac{y_2'}{y_2}\;,
$$
da cui si ottiene che $y_2=\alpha y_1$, quindi se due autostati ammettono lo stesso autovalore, allora saranno necessariamente l'uno multiplo dell'altro. Un'altra proprietà già nota che discende dalle proprietà del Wronskiano è l'ortogonalità degli autostati appartenenti ad autovalori diversi. Sia:
$$
\dev{W}{x}=\frac{2m}{\hbar^2}(\mathcal{E}_2-\mathcal{E}_1)y_1y_2,\qquad \mathcal{E}_1\ne\mathcal{E}_2\;.
$$
Integrando:
\begin{equation}
\int_{a_L}^{+\infty}\dev{W}{x}\;\diff{x}=\frac{2m}{\hbar^2}(\mathcal{E}_2-\mathcal{E}_1)\int_{a_L}^{+\infty} y_1y_2\;\diff{x}\;.
\end{equation}
Il primo integrale vale $W(+\infty)-W(a_L)$, ma per le condizioni al contorno, i due addendi sono entrambi nulli. Quindi, poiché $\mathcal{E}_1\ne\mathcal{E}_2$, deve necessariamente essere:
\begin{equation}
\int_{a_L}^{+\infty} y_1y_2\;\diff{x}=\bra y_1|y_2\ket=0\;,
\end{equation}
che è proprio la tesi. \\
\\
Un ulteriore teorema molto significativo è il \textit{teorema dei nodi}, che afferma che l'$n$-esimo autostato ha $n-1$ zeri (detti \textit{nodi}) nel dominio dello spettro discreto. \\
In generale, gli stati così ottenuti sono tali che $\psi,\psi'$ siano continui, anche nel caso in cui il potenziale risulti discontinuo in un punto $x_0$, infatti, integrando l'equazione in un intorno di $x_0$, si ha:
\begin{align}
\int_{x_0-\varepsilon}^{x_0+\varepsilon} \psi''\;\diff{x} &= \psi'(x_0+\varepsilon)-\psi'(x_0-\varepsilon) \notag \\
&= \int_{x_0-\varepsilon}^{x_0+\varepsilon} \frac{2m}{\hbar^2}(V-\mathcal{E})\psi\;\diff{x}=0\;,
\end{align}
quindi si ottiene che $\psi'$ è continua. \\
Infine, un altro fatto importante è che se $V(x)$ è una funzione pari, sostituendo $x\to -x$ nell'equazione di Schrödinger si ottiene:
$$
-\frac{\hbar^2}{2m}\frac{\mathrm{d}^2}{\diff{x}^2}\psi(-x)+V(-x)\psi(-x)=\frac{\hbar^2}{2m}\frac{\mathrm{d}^2}{\diff{x}^2}\psi(-x)+V(x)\psi(-x)=\mathcal{E}\psi(-x)\;,
$$
cioè otteniamo che $\psi(x),\psi(-x)$ soddisfano l'equazione $H\psi=\mathcal{E}\psi$. Ma, essendo gli autovalori non degeneri, per quanto appena visto, deve essere $\psi(-x)=\eta\psi(x)$. In più $\psi(x)=\psi(-(-x))=\eta\psi(-x)=\eta^2\psi(x)$. Dal fatto che possiamo prendere $\psi\in\mathbb{R}$, segue che $\eta=\pm 1$. Concludiamo che, se il potenziale è una funzione pari, allora gli stati sono pari o dispari.
\section{Buca di potenziale}
Consideriamo una buca di potenziale, cioè un potenziale che vale $-V_0$ (costante) in una regione di spazio lunga $2a$ e zero altrove. Scegliamo gli assi in modo tale che gli estremi della buca si trovino a $\pm a$. Con questa scelta degli assi, $V$ è una funzione pari, quindi, tra $-a$ e $a$ possiamo cercare separatamente soluzioni pari e dispari. Notiamo inoltre:
\begin{itemize}
\item per $x\in\;[-a,a]$, $V$ è costante, quindi ci aspettiamo che le soluzioni siano seni e coseni;
\item nella zona classicamente proibita ci aspettiamo esponenziali decrescenti.
\end{itemize}
Dunque, se cerchiamo soluzioni pari in $[-a,a]$ (zona 1) ed esponenziali nella zona proibita (zona 2), avremo:
\begin{align*}
\psi_1(x) &= c_1\cos(qx)\;, \\
\psi_2(x) &= c_2 e^{-kx}\;.
\end{align*}
Se invece cerchiamo soluzioni dispari in $[-a,a]$, avremo:
\begin{align*}
\psi_1(x) &= c_1\sin(qx)\;, \\
\psi_2(x) &= c_2 e^{-kx}\;.
\end{align*}
Incominciamo dalle soluzioni pari. Sostituendo nell'equazione, troviamo:
\begin{align}
&\left(\frac{\hbar^2}{2m}q^2-V_0\right)\cos(qx) =\mathcal{E}\cos(qx)\;, \label{ch3_sol1} \\
&-\frac{\hbar^2}{2m}k^2e^{-kx}=\mathcal{E}e^{-kx}\;, \label{ch3_sol2}
\end{align}
da cui otteniamo le condizioni:
\begin{equation}
\begin{cases}
\dfrac{\hbar^2q^2}{2m}-V_0=-\dfrac{\hbar^2k^2}{2m}\;, \\
\\
\mathcal{E}=-\dfrac{\hbar^2k^2}{2m}\;.
\end{cases}
\end{equation}
In unità naturali, $V_0=\frac{\hbar^2}{2m}\beta^2$, quindi la prima condizione diventa $q^2+k^2=\beta^2$. Imponiamo adesso la continuità di $\psi$ e $\psi'$ in $a$ (dato che $\psi$ è pari o dispari, è sufficiente studiare solo $x>0$):
\begin{equation}
\begin{cases}
\psi_1(a)=\psi_2(a)\;, \\
\\
\psi_1'(a)=\psi_2'(a)\;. \\
\end{cases}
\end{equation}
Queste condizioni, insieme alla condizione di normalizzazione sono sufficienti per determinare le costanti $q,c_1,c_2$. Tuttavia, deve ancora venir fuori la condizione di quantizzazione. Allora scriviamo la condizione di raccordo come:
\begin{equation}
\left.\frac{\psi'_1}{\psi_1}\right|_a=\left.\frac{\psi_2'}{\psi_2}\right|_a\;,
\end{equation}
cioè nel caso pari $q\tan qa=k$. Adesso abbiamo:
\begin{equation}
\begin{cases}
q^2+k^2=\beta^2\;, \\
\\
q\tan(qa)=k\;,
\end{cases} \Longrightarrow
\begin{cases}
k=\sqrt{\beta^2-q^2}\;, \\
\\
q\tan(qa)=\sqrt{\beta^2-q^2}\;.
\end{cases}
\end{equation}
Mentre per le dispari otteniamo:
\begin{equation}
\begin{cases}
k=\sqrt{\beta^2-q^2}\;, \\
\\
q \cot(qa) =-\sqrt{\beta^2-q^2}\;.
\end{cases}
\end{equation}
Notiamo innanzitutto via grafica che abbiamo sempre almeno una soluzione al variare di $\beta$, che rappresenta lo stato fondamentale. Aumentando l'energia, si creano i successivi stati eccitati. \\
\\
Riprendiamo adesso l'equazione:
\begin{equation}
y''=\frac{2m}{\hbar^2}(V-E)y\;, \qquad\qquad \mathcal{E}\equiv \frac{2m}{\hbar^2}E\;.
\end{equation}
Siano $y_1,y_2$ due soluzioni indipendenti dell'equazione, relativi ai valori $E_1$ ed $E_2$ dell'energia, supponiamo $E_2>E_1$. Sappiamo che in queste condizioni, il Wronskiano $W=y_1'y_2-y_1y_2'$ soddisfa la relazione:
\begin{equation}
\dev{W}{x}=(\mathcal{E}_2-\mathcal{E}_1)y_1y_2\;. \label{ch3_dxwronsk}
\end{equation}
Siano $a,b$ due zeri di $y_1$; allora, integrando la \eqref{ch3_dxwronsk} da $a$ a $b$:
\begin{equation}
\int_a^b\dev{W}{x}\; \diff{x}=y_1'(b)y_2(b)-y_1'(a)y_2(a)=(\mathcal{E}_2-\mathcal{E}_1)\int_a^b y_1y_2\;\diff{x}\;.
\end{equation}
\textbf{Affermazione}: tra due zeri di $y_1$ esiste uno zero di $y_2$. \\
\\
Infatti, supponiamo che sia $y_1>0$ in $]a,b[$ e che $y_1'(a)>0$, $y_1'(b)<0$. Se $y_2$ non avesse zeri nell'intervallo, per esempio $y_2>0$ in $[a,b]$, allora:
$$
y_1'(b)y_2(b)-y_1'(a)y_2(a)<0\;,
$$
mentre:
$$
(\mathcal{E}_2-\mathcal{E}_1)\int_a^b y_1y_2\;\diff{x}>0\;,
$$
che contraddice la \eqref{ch3_dxwronsk}, quindi $y_2$ non può essere positiva in $[a,b]$. Analogamente se $y_2<0$ in $[a,b]$, allora:
$$
y_1'(b)y_2(b)-y_1'(a)y_2(a)>0\;,
$$
mentre:
$$
(\mathcal{E}_2-\mathcal{E}_1)\int_a^b y_1y_2\;\diff{x}<0\;,
$$
quindi troviamo di nuovo una contraddizione. Concludiamo che $y_2$ è positiva e negativa nell'intervallo $[a,b]$ ed essendo continua deduciamo che esiste almeno un punto in cui si annulla.
\section{Soluzione tramite problema di Cauchy}
Risolviamo l'equazione di Schrödinger come problema di Cauchy:
\begin{equation}
\begin{cases}
y''=\dfrac{2m}{\hbar^2}(V-E)y\;, \\
\\
y(a_L)=0\;, \\
\\
y'(a_L)=1\;.
\end{cases}
\end{equation}
Sappiamo che la soluzione di un problema di Cauchy è unica e dipende con continuità dai dati iniziali. Integriamo innanzitutto la \eqref{ch3_dxwronsk} tra $a_L$ e $x$:
$$
\int_{a_L}^x \dev{W}{x}\;\diff{x}=
y_1'(x)y_2(x)-y_2'(x)y_1(x)=(\mathcal{E}_2-\mathcal{E}_1)\int_{a_L}^x y_1y_2\;\diff{x}\;.
$$
Scrivamo a questo punt $\mathcal{E}_2=\mathcal{E}_1+\delta\mathcal{E}$, quindi:
$$
y_2=y_2(x,\mathcal{E})=y_1+\delta y\;,
$$
per la dipendenza continua, quindi:
$$
y_1'(x)y_2(x)-y_2'(x)y_1(x)=\delta\mathcal{E}\int_{a_L}^x y_1^2\;\diff{x}\;.
$$
Fissiamo come estremo superiore di integrazione un punto $\xi$ tale che $y_1(\xi)=0$, allora:
\begin{equation}
y_1'(\xi)y_2(\xi)=\delta\mathcal{E}\int_{a_L}^{\xi}y_1^2\;\diff{x}\;.
\end{equation}
Osserviamo quindi che, dato che $\delta\mathcal{E}$ è positivo, il secondo membro è sempre positivo. Questo ci dice che se $y_1'(\xi)>0$, allora deve necessariamente essere $y_2(\xi)<0$, da cui si vede che lo zero di $y_2$ si trova a sinistra di $\xi$, che è lo zero di $y_1$, in quanto $y_1,y_2$ sono parallele. Viceversa, se $y_1'(\xi)<0$, allora $y_2(\xi)>0$, ed essendo $y_1,y_2$ parallele, ritroviamo che lo zero di $y_2$ è a sinistra di quello di $y_1$. \\
\\
\textbf{Osservazione}: dato un qualunque potenziale $V$, il numero degli stati legati è uguale al numero degli zeri della soluzione dell'equazione di Schrödinger con $E=0$, cioè:
\begin{equation}
\psi''=\frac{2m}{\hbar^2}\psi\;.
\end{equation}
\section{Metodo variazionale}
L'equazione di Schrödinger è un'equazione agli autovalori, che assume più in astratto la forma:
\begin{equation}
H_{ij}v_j=Ev_i\;. \label{ch3_autovalori}
\end{equation}
Essendo $H$ un operatore hermitiano, esso induce una forma quadratica:
\begin{equation}
Q=\frac{1}{2}H_{ij}v_iv_j\;.
\end{equation}
\textbf{Affermazione}: trovare gli autovalori $E_i$ dell'equazione \eqref{ch3_autovalori} equivale a cercare il minimo della forma quadratica $Q$ con il vincolo $|v|=1$. Infatti, per trovare i minimi vincolati si usa il metodo dei moltiplicatori di Lagrange:
$$
\frac{\partial}{\partial v_i}\left[Q-\frac{\lambda}{2}(v_i^2-1)\right]=0\;,
$$
da cui, esplicitando la derivata, si ricava proprio l'equazione $H_{ij}v_j=\lambda v_i$. \\
\\
Nel nostro caso, la forma quadratica indotta dall'Hamiltoniana è:
\begin{equation}
\mathcal{Q}=\int \frac{\hbar^2}{2m}(\nabla\psi)^*(\nabla\psi)\;\diff{x}+\int V(x)\psi^*\psi\;\diff{x}\;.
\end{equation}
Dobbiamo estremizzare $\mathcal{Q}$ con il vincolo $||\psi||^2=1$, cioè:
$$
\frac{\delta}{\delta\psi^*}\left[\mathcal{Q}-\lambda\left(\int\psi^*\psi\;\diff{x}-1\right)\right]=0\;.
$$
Per linearità:
$$
\frac{\delta\mathcal{Q}}{\delta\psi^*}=\lambda\frac{\delta}{\delta\psi^*}\left[\int\psi^*\psi\;\diff{x}-1\right]\;.
$$
Ma dalla definizione di $\mathcal{Q}$ si ha:
\begin{equation}
\frac{\delta\mathcal{Q}}{\delta\psi^*}=-\frac{\hbar^2}{2m}\nabla^2\psi+V(x)\psi\;.
\end{equation}
Inoltre:
\begin{equation}
\frac{\delta}{\delta\psi^*}\left[\int\psi^*\psi\;\diff{x}-1\right]=\psi(x)\;.
\end{equation}
Sostituendo troviamo:
\begin{equation}
-\frac{\hbar^2}{2m}\nabla^2\psi(x)+V(x)\psi(x)=\lambda\psi(x)\;,
\end{equation}
che è proprio l'equazione di Schrödinger. \\
\\
Consideriamo adesso un potenziale $V$ che tende a zero per $x\to\pm\infty$. Sappiamo che per valori dell'energia $E$ positivi, abbiamo uno spettro di autovalori puramente continuo, mentre se $E<0$ possono esistere stati legati. \\
\textbf{Affermazione}. Consideriamo un sistema descritto dall'Hamiltoniana $H$ avente almeno un autovalore negativo. Condizione sufficiente affinché esista almeno uno stato legato è che esista $\varphi$ tale che $\bra\varphi|H|\varphi\ket<0$. \\
\proof
Se così non fosse, gli autovalori $E_{\alpha}$ di $H$ sarebbero tutti positivi. Preso un set completo ortonormale di autovettori $f_{\alpha}$, possiamo scrivere:
$$
|\varphi\ket=\sum_{\alpha} c_{\alpha}|f_{\alpha}\ket,\qquad H|f_{\alpha}\ket=E_{\alpha}|f_{\alpha}\ket\;.
$$
Quindi:
$$
\bra\varphi|H|\varphi\ket=\sum_{\alpha} |c_{\alpha}|^2 E_{\alpha}>0\;,
$$
che contraddice l'ipotesi.
\endproof
Sull'esistenza degli stati legati è importante anche il seguente \\
\\
\textbf{Teorema}. Siano $V_1,V_2$ due potenziali che tendono a zero per $x\to\pm\infty$, con $V_1<V_2$. Le corrispondenti Hamiltoniane saranno $H_1=K_1+V_1, H_2=K_2+V_2$, dove $K_1,K_2$ sono le energie cinetiche. Allora:
\begin{enumerate}
\item se $H_2$ ha uno stato legato, allora $H_1$ ha almeno uno stato legato;
\item se $H_2$ ha due stati legati, allora $H_1$ ha almeno due stati legati.
\end{enumerate}
\proof
1. Se così non fosse, per un autostato $\varphi$ di $H_2$ si avrebbe $H_2|\varphi\ket=E_2|\varphi\ket$, $E_2<0$ e $\bra\varphi|H|\varphi\ket\ge 0$. Ma allora $\bra\varphi|H_1|\varphi\ket\le\bra\varphi|H_2|\varphi\ket<0$, che è assurdo.\\
\\
2. Se così non fosse, allora $H_1$ avrebbe, per il punto precedente, un solo stato legato $|f_1\ket$, con $H_1|f_1\ket=E_1|f_1\ket$, $E_1<0$. Quindi, per ogni $\psi\perp f_1$ deve essere $\bra\psi|H|\psi\ket\ge 0 \quad (*)$ \\
Siano $\varphi_1,\varphi_2$ gli stati legati di $H_2$:
$$
H_2|\varphi_1\ket=E_1^{(2)}|\varphi_2\ket,\qquad H_2|\varphi\ket=E_2^{(2)}|\varphi\ket,\qquad E_1^{(2)},E_2^{(2)}<0\;.
$$
Possiamo proiettare $f_1$ sul sottospazio generato da $\varphi_1,\varphi_2$:
$$
\pi|f_1\ket=c_1|\varphi_1\ket+c_2|\varphi_2\ket\;.
$$
In questo sottospazio esisterà un vettore $|\alpha\ket$ ortogonale a $\pi|f_1\ket$, della forma $|\alpha\ket=-c_2|\varphi_1\ket+c_1|\varphi_2\ket$ che sarà ortogonale anche a $|f_1\ket$. Allora si avrà:
$$
\bra \alpha|H_1|\alpha\ket\le \bra\alpha|H_2|\alpha\ket\le 0\;,
$$
che contraddice (*).
\endproof
In generale, se $H_2$ ha $n$ stati legati, allora $H_1$ avrà almeno $n$ stati legati.
\section{Metodo spettrale}
Dato un generico spazio di Hilbert $\ham$ con Hamiltoniana $H$ e base ortonormale completa $|f_i(x)\ket$, soddisfacenti cioè:
$$
\int f_i^*f_j\;\diff{x}=\delta_{ij}\;,
$$
prendiamo una combinazione lineare finita dei vettori di base:
$$
\psi(x)=\sum_{i=1}^N c_if_i(x)\;.
$$
Scriviamo adesso il principio variazionale per le funzioni del tipo di $\psi$:
$$
\int\diff{x}\;\bra\psi|H|\psi\ket=\int\diff{x}\left[\frac{\hbar^2}{2m}(\nabla\psi^*)(\nabla\psi)+\psi^*V\psi\right]\;,
$$
con il vincolo:
$$
\int\diff{x}\;|\psi|^2=1\;,
$$
dove $\bra\psi|H|\psi\ket$ è la forma quadratica indotta dall'Hamiltoniana. Il minimo vincolato della forma quadratica costituisce un'approssimazione dello stato fondamentale del sistema:
\begin{align*}
c_i^*c_j\bra f_i|H|f_j\ket -\lambda\left(c_i^*c_j\bra f_i|f_j\ket-1\right) &=
c_i^*c_j H_{ij}-\lambda(c_i^*c_j\delta_{ij}-1) \\
&= c_i^*c_jH_{ij}-\lambda(c_i^*c_i-1)\;,
\end{align*}
derivo rispetto a $c_i^*$ l'ultima espressione (devo trovare comunque zero):
\begin{equation}
H_{ij}c_j-\lambda c_i=0\;. \label{ch3_stima}
\end{equation}
Risolvendo questa equazione ($H$ è una matrice $n\times n$), ottengo una stima degli autovalori dell'Hamiltoniana complessiva; in particolare, l'autovalore più basso dà una stima dell'energia dello stato fondamentale. \\
Se scegliamo i vettori di base dipendenti da un parametro, $f_i\equiv f_i(x,\alpha)$ e facciamo di nuovo il conto, troviamo come soluzione di \eqref{ch3_stima} dei valori a loro volta dipendenti da $\alpha$, $E_i=E_i(\alpha)$. Imponendo:
$$
\pdev{E_i}{\alpha}=0\;,
$$
si ottiene un'approssimazione migliore degli autovalori dell'Hamiltoniana.
\section{Potenziale a delta}
Consideriamo un potenziale della forma $V(x)=-g\delta(x)$. L'equazione di \Sch\; è:
\begin{equation}
-\frac{\hbar^2}{2m}\psi''(x)-g\delta(x)\psi(x)=E\psi(x)\;,
\end{equation}
cioè
$$
\psi''(x)=\frac{2m}{\hbar^2}(-g\delta(x)-E)\psi(x)\;.
$$
Osserviamo che, a differenza della buca di potenziale, adesso la derivata prima di $\psi$ è discontinua in zero, infatti, integrando la precedente espressione tra $-\varepsilon$ e $\varepsilon$ si ha:
\begin{equation}
\psi'(\varepsilon)-\psi'(-\varepsilon)=-\frac{2mg}{\hbar^2}\psi(0)\;, \label{ch3_deltacondition}
\end{equation}
Quindi, nel caso di potenziale a delta, bisogna accompagnare l'equazione con la condizione \eqref{ch3_deltacondition} insieme alla continuità di $\psi$. \\
\textbf{Analisi dimensionale}. Scriviamo l'equazione di \Sch\; nel seguente modo:
\begin{equation}
-\frac{1}{2}\psi''(x)-\frac{mg}{\hbar^2}\delta(x)\psi(x)=\frac{mE}{\hbar^2}\psi\;.
\end{equation}
Tutti i termini hanno a numeratore le dimensioni di $\psi$. Il primo termine va come $[\psi]/x^2$, quindi anche tutti gli altri devono andare allo stesso modo; nel secondo termine figura $\delta(x)$, che ha le dimensioni di $1/x$, quindi per rispettare l'andamento, dovrà essere:
\begin{equation}
\frac{mg}{\hbar^2}=\beta, \qquad \qquad [\beta]=\frac{1}{x}\;.
\end{equation}
Per quanto riguarda l'ultimo termine, il coefficiente di $\psi$ deve andare come $1/x^2$, cioè come $\beta^2$, quindi:
\begin{equation}
\frac{mE}{\hbar^2}=c\beta^2\quad  \Longrightarrow\quad  E=c\frac{\hbar^2}{m}\beta^2\;.
\end{equation}
Per $x\ne 0$ l'equazione diventa:
$$
\psi''=-\frac{2mE}{\hbar^2}\psi\;,\qquad\qquad E<0\;,
$$
che ha come soluzioni esponenziali reali:
$$
\psi(x)=C\exp\left(\pm\sqrt{\frac{2m|E|}{\hbar^2}} x\right)\;.
$$
In unità naturali, $E=\alpha^2(-\hbar^2/2m)$, quindi si ottiene $\psi=C\exp(-\alpha|x|)$. Imponiamo adesso la condizione \eqref{ch3_deltacondition}:
\begin{align*}
\psi' &=-\alpha C\mathrm{sgn}(x)e^{-\alpha|x|}\;, \\
\psi'(0^+) &= -\alpha C\;, \\
\psi'(0^-) &= \alpha C\;.
\end{align*}
Quindi:
$$
\psi'(0^+)-\psi'(0^-)=-2\alpha C\stackrel{!}{=}-\frac{2mg}{\hbar^2}C=-2C\beta\;.
$$
Dove abbiamo usato i fatti che $\psi(0)=C$. Troviamo infine il valore della costante $C$ normalizzando la $\psi$:
\begin{equation}
1=\int_{-\infty}^{+\infty}|\psi|^2\;\diff{x}=2C^2\int_0^{+\infty}e^{-2\beta x}\;\diff{x}=2C^2\frac{1}{2\beta}\;,
\end{equation}
cioè $C=\sqrt{\beta}$. Quindi le soluzioni dell'equazione di \Sch\; per un potenziale a delta sono:
\begin{equation}
\psi(x)=\sqrt{\beta}e^{-\beta|x|},\qquad\qquad E=-\frac{\hbar^2}{2m}\beta^2\;.
\end{equation}
\chapter{Oscillatore armonico}
L'Hamiltoniana standard di un'oscillatore armonico è:
\begin{equation}
H=\frac{p^2}{2m}+\frac{1}{2}m\omega^2q^2\;, \label{ch4_harmonicham}
\end{equation}
dove $\omega^2=k/m$, con $k$ costante elastica. Per come è fatto il potenziale dell'oscillatore armonico, non troveremo in nessun caso autostati del continuo. \\
\textbf{Analisi dimensionale}. L'equazione agli autovalori per l'oscillatore armonico è:
\begin{equation}
-\frac{\hbar^2}{2m}\psi''+\frac{1}{2}m\omega^2q^2\psi=E\psi\;,
\end{equation}
cioè:
$$
-\frac{1}{2}\psi''+\frac{1}{2}\frac{m^2\omega^2}{\hbar^2}q^2\psi=\frac{Em}{\hbar^2}\psi\;.
$$
Dato che $[\psi'']=[\psi]/[q]^2$, tutti i coefficienti dei termini in $\psi$ devono avere le dimensioni di $1/[q]^2$, in particolare ricaviamo che:
\begin{equation}
\left[\frac{m^2\omega^2}{\hbar^2}\right]=\frac{1}{[q]^4}\quad \Longrightarrow\quad \frac{m^2\omega^2}{\hbar^2}=\frac{1}{\ell^4}
\Longrightarrow \ell=\sqrt{\frac{\hbar}{m\omega}}\;,
\end{equation}
e inoltre:
\begin{equation}
\left[\frac{Em}{\hbar^2}\right]=\frac{1}{[q]^2}\quad \Longrightarrow\quad E=\frac{\hbar^2}{\ell m}=\frac{\hbar^2}{m}\frac{m\omega}{\hbar}=\hbar\omega\;.
\end{equation}
\\
Per l'oscillatore armonico esistono vari metodi di risoluzione.

\section{Metodo astratto}
Poiché l'Hamiltoniana \eqref{ch4_harmonicham} è quadratica, possiamo provare a scriverla in termini di variabili complesse. Definiamo a tal scopo gli operatori:
\begin{equation}
\begin{cases}
a=\dfrac{1}{\sqrt{2}}\left(\dfrac{q}{\ell}+i\dfrac{p}{m\omega\ell}\right)\;, \\
\\
\adj{a}=\dfrac{1}{\sqrt{2}}\left(\dfrac{q}{\ell}-i\dfrac{p}{m\omega\ell}\right)\;.
\end{cases}
\end{equation}
Invertendo queste relazioni, troviamo $p,q$ in funzione di $a,\adj{a}$:
\begin{equation}
\begin{cases}
q=\dfrac{\ell}{\sqrt{2}}\left(a+\adj{a}\right)\;, \\
\\
p=\dfrac{m\ell\omega}{\sqrt{2}}\left(a-\adj{a}\right)\;.
\end{cases}
\end{equation}
Sostituendo queste espressioni nell'Hamiltoniana troviamo:
$$
H=\frac{1}{2}m\omega^2\left[\frac{\ell^2}{2}\left(a^2+a^{\dagger^2}+a\adj{a}+\adj{a}a\right)\right]-\frac{1}{2}\frac{1}{m}\frac{1}{2}m^2\ell^2\omega^2\left(a^2+a^{\dagger^2}-a\adj{a}-\adj{a}a\right)\;,
$$
perché $a$ e $\adj{a}$ non commutano. Adesso notiamo che:
$$
\ell^2m\omega^2=\frac{\hbar}{m\omega}m\omega^2=\hbar\omega\;,
$$
quindi:
\begin{align}
H &= \frac{\hbar\omega}{4}\left(a^2+a^{\dagger^2}+a\adj{a}+\adj{a}a\right)-\frac{\hbar\omega}{4}\left(a^2+a^{\dagger^2}-a\adj{a}-\adj{a}a\right) \notag \\
&= \frac{1}{2}\hbar\omega\left(a\adj{a}+\adj{a}a\right)\;.
\end{align}
Vogliamo adesso scrivere l'Hamiltoniana solamente come funzione di $\adj{a}a$. Per far ciò, calcoliamo il commutatore $[a,\adj{a}]$, ricordando che $[q,p]=i\hbar$:
\begin{equation}
[a,\adj{a}]=\frac{1}{2}\frac{1}{m\ell\omega}\left(-i[q,p]+i[p,q]\right)=\frac{1}{2\hbar}(\hbar+\hbar)=1\;.
\end{equation}
Quindi $1=[a,\adj{a}]=a\adj{a}-\adj{a}a$ implica $a\adj{a}=1-\adj{a}a$, che sostituito ci dà la forma definitiva dell'Hamiltoniana per l'oscillatore armonico:
\begin{equation}
H=\hbar\omega\left(\adj{a}a+\frac{1}{2}\right)\;.
\end{equation}
In pratica, notiamo che diagonalizzare $H$ significa diagonalizzare l'operatore $\adj{a}a$. Gli autovalori di $\adj{a}a$ sono sicuramente positivi. Calcoliamo adesso i commutatori:
\begin{align}
[a,\adj{a}a] &= [a,\adj{a}]a+\adj{a}[a,a]=a\;, \notag \\
[\adj{a},\adj{a}a] &= [\adj{a},\adj{a}]a+\adj{a}[\adj{a},a]=-\adj{a}\;.
\end{align}
Sia $|\varepsilon\ket$ un autostato dell'Hamiltoniana, $H|\varepsilon\ket=E|\varepsilon\ket$. Allora:
$$
Ha|\varepsilon\ket=(aH-\hbar\omega a)|\varepsilon\ket=aE|\varepsilon\ket-\hbar\omega a|\varepsilon\ket=(E-\hbar\omega)a|\varepsilon\ket\;.
$$
Quindi se $|\varepsilon\ket$ è un autostato di $H$, anche $a|\varepsilon\ket$ lo è. Inoltre, l'autovalore di $a|\varepsilon\ket$ è minore di quello di $|\varepsilon\ket$. Per questo, l'operatore $a$ prende il nome di \textit{operatore di discesa}. Allo stesso modo:
$$
H\adj{a}|\varepsilon\ket=(\adj{a}H+\hbar\omega\adj{a})|\varepsilon\ket=(E+\hbar\omega)\adj{a}|\varepsilon\ket\;.
$$
Quindi anche $\adj{a}|\varepsilon\ket$ è autostato di $H$, con autovalore maggiore di quello di $|\varepsilon\ket$. Per questo, $\adj{a}$ è detto \textit{operatore di salita}. \\
Per interrompere la catena di discesa (si avrebbero altrimenti autovalori negativi), deve esistere un autostato di $H$ $|0\ket$ tale che $a|0\ket=0$. Riassumendo:
\begin{table}[h]
\centering
\begin{tabular}{l l l}
\multicolumn{1}{c}{ } &
\multicolumn{1}{c}{$\adj{a}a$} &
\multicolumn{1}{c}{$H$} \\
$|0\ket$ & $0$ & $\frac{1}{2}\hbar\omega$ \\
$|1\ket=\adj{a}|0\ket$ & $1$ & $\frac{1}{2}\hbar\omega+\hbar\omega$ \\ 
$|2\ket=a^{\dagger^2}|0\ket$ & $2$ & $\frac{1}{2}\hbar\omega+2\hbar\omega$ \\
\end{tabular}
\end{table}
e così via. Quindi, lo stato $n$-esimo si può ottenere dallo stato fondamentale:
\begin{equation}
|n\ket=c_n(\adj{a})^n|0\ket\;.
\end{equation}
Questi stati costituiscono un set ortonormale completo. Definiamo a questo punto lo spazio di Hilbert $\ham$ su cui è definita l'Hamiltoniana come:
\begin{equation}
\ham:=\left\{\psi=\sum_n \alpha_n|n\ket\; |\;\{\alpha_n\}\in \ell_2\right\}\;.
\end{equation}
Determiniamo adesso le costanti di normalizzazione $c_n$ degli autostati. Partiamo dal fatto che:
\begin{equation}
[a,(\adj{a})^n]=[a,\adj{a}](\adj{a})^{n-1}+\adj{a}[a,\adj{a}](\adj{a})^{n-2}+\cdots+(\adj{a})^{n-1}[a,\adj{a}]=n(\adj{a})^{n-1}\;. \label{ch4_commutator}
\end{equation}
In quanto $[a,\adj{a}]=1$. Allora, assumendo che $\bra 0|0\ket=1$ (cioè che lo stato fondamentale sia normalizzato) si ha:
$$
|c_n|^2\equiv \bra 0|a^n(\adj{a})^n|0\ket=\bra 0|a^{n-1}a(\adj{a})^n|0\ket\;.
$$
Dalla \eqref{ch4_commutator} otteniamo che $a(\adj{a})^n-(\adj{a})^na=n(\adj{a})^{n-1}$, cioè $a(\adj{a})^n=(\adj{a})^na+n(\adj{a})^{n-1}$. Quindi:
\begin{align}
|c_n|^2&=\bra 0|a^{n-1}((\adj{a})^na+n(\adj{a})^{n-1})|0\ket \notag \\
&= n\bra 0|a^{n-1}(\adj{a})^{n-1}|0\ket=n|c_{n-1}|^2\;.
\end{align}
Per ricorrenza otteniamo che $|c_n|^2=n!$, quindi gli autostati normalizzati saranno:
\begin{equation}
|n\ket=\frac{1}{\sqrt{n!}}(\adj{a})^n|0\ket\;.
\end{equation}
Verifichiamo che gli autostati di indice diverso sono ortogonali. Sia $k<n$, allora:
\begin{align*}
\bra k|n\ket &= \bra 0|a^k(\adj{a})^n|0\ket=\bra 0|a^{k-1}n(\adj{a})^{n-1}|0\ket  \\
&=\binom{n}{k}\bra 0|(\adj{a})^{n-k}|0\ket=0\;.
\end{align*}
Perché $a^n|0\ket=0$ per ogni $n$ implica $\bra 0|(\adj{a})^n=0$ per ogni $n$. \\
Vogliamo adesso calcolare gli elementi di matrice di $\adj{a}$. In quanto operatore hermitiano, avrà gli elementi sulla diagonale principale nulli. Notiamo poi che:
$$
\adj{a}|n\ket=\adj{a}\frac{(\adj{a})^n}{\sqrt{n!}}|0\ket=\frac{\sqrt{n+1}}{\sqrt{n+1}}\frac{1}{\sqrt{n!}}(\adj{a})^{n+1}|0\ket=\sqrt{n+1}|n+1\ket\;.
$$
Ciò implica che:
$$
(\adj{a})_{kn}\equiv\bra k|\adj{a}|n\ket=\sqrt{n+1}\bra k|n+1\ket=\sqrt{n+1}\delta_{k,n+1}\;.
$$
Quindi troviamo che gli unici elementi di matrice di $\adj{a}$ non nulli sono $(\adj{a})_{n+1,n}$, $n=0,1,2,\ldots$ e valgono $\sqrt{n+1}$. \\
Per quanto riguarda $a$, notiamo invece che:
$$
a|n\ket=\frac{a(\adj{a})^n}{\sqrt{n!}}|0\ket=n\frac{(\adj{a})^{n-1}}{\sqrt{n!}}=\sqrt{n}|n-1\ket\;.
$$
Con lo stesso ragionamento, otteniamo che gli unici elementi di $a$ non nulli sono quelli di posto $(a)_{n-1,n}$, $n=1,2,\ldots$ e valgono $\sqrt{n}$. In sintesi:
\begin{equation}
\begin{cases}
\adj{a}|n\ket=\sqrt{n+1}|n+1\ket\;, \\
\\
a|n\ket=\sqrt{n}|n-1\ket\;.
\end{cases}
\end{equation}
Poiché valgono queste relazioni, gli operatori $\adj{a}$ e $a$ prendono rispettivamente i nomi di \textit{operatore di creazione} e \textit{operatore di distruzione}. \\
Adesso possiamo calcolare esplicitamente gli elementi di matrice di $q,p$:
\begin{align}
(q)_{ij}&=\frac{\ell}{\sqrt{2}}(a+\adj{a})_{ij}\;, \notag \\
(p)_{ij} &= i\frac{m\omega\ell}{\sqrt{2}}(a-\adj{a})_{ij}\;.
\end{align}
$(q)_{n,n}=0$ per ogni $n$ in quanto, in un sistema unidimensionale con autostati non degeneri è sempre possibile scegliere una base in modo che gli autostati siano anche autostati della parità.
\section{Rappresentazione di \Sch}
Passiamo adesso alla rappresentazione di \Sch\; mediante le sostituzioni:
\begin{align*}
q &\longrightarrow x \;,\\
p &\longrightarrow \frac{\hbar}{i}\frac{\partial}{\partial x}\;.
\end{align*}
In unità adimensionali:
\begin{align*}
x&=\ell\xi\;, \\
\frac{p}{m\omega\ell}&= \frac{\partial}{\partial\xi}\;.
\end{align*}
Allora gli operatori di discesa e di salita saranno dati da:
\begin{align}
a&=\frac{1}{\sqrt{2}}\left(\xi+\frac{\partial}{\partial\xi}\right)\;, \notag \\
\adj{a}&=\frac{1}{\sqrt{2}}\left(\xi-\frac{\partial}{\partial\xi}\right)\;.
\end{align}
L'Hamiltoniana diventa di conseguenza:
\begin{equation}
H=\frac{\hbar\omega}{2}\left[\left(\xi-\frac{\partial}{\partial\xi}\right)\left(\xi+\frac{\partial}{\partial\xi}\right)+1\right]\;.
\end{equation}
Scriviamo adesso lo stato fondamentale $\psi_0(\xi)=|0\ket$ ricordando che deve verificare $a|0\ket=0$:
\begin{equation}
\frac{1}{\sqrt{2}}\left(\xi+\frac{\partial}{\partial\xi}\right)\psi_0(\xi)=0\quad  \Longrightarrow \quad \psi_0(\xi)=Ce^{-\xi^2/2}\;.
\end{equation}
La costante di normalizzazione $c$ è data da:
$$
1=\int_{-\infty}^{+\infty}C^2e^{-\xi^2}\;\diff{\xi}=C^2\sqrt{\pi}\quad \Longrightarrow \quad C=\pi^{1/4}\;.
$$
Lo stato fondamentale è quindi:
\begin{equation}
\psi_0(\xi)=\frac{1}{\pi^{1/4}}e^{-\xi^2/2}\;.
\end{equation}
In termini di $x$:
\begin{equation}
\psi_0(x)=\frac{1}{\sqrt{\ell}}\psi_0\left(\frac{x}{\ell}\right)=\frac{1}{\sqrt{\pi^{1/2}\ell}}e^{-x^2/2\ell^2}\;,
\end{equation}
con autovalore (energia) $\mathcal{E}_0=\hbar\omega/2$. Gli stati eccitati sono dati da:
\begin{equation}
|n\ket=\frac{(\adj{a})^n}{\sqrt{n!}}|0\ket=\frac{1}{\sqrt{n!}}\frac{1}{\sqrt{2^n}}\left(\xi-\frac{\partial}{\partial\xi}\right)^n\psi_0(\xi)=\psi_n(\xi)\;,
\end{equation}
che possiamo riscrivere come:
\begin{equation}
\psi_n(\xi)=\frac{1}{\sqrt{2^n n!}}\frac{e^{-\xi^2/2}}{\sqrt[4]{\pi}}H_n(\xi)\;,
\end{equation}
dove $H_n(\xi)$ è un polinomio di grado al più $n$ detto \textit{polinomio n-esimo di Hermite}. I polinomi di Hermite sono ortogonali rispetto alla misura $\mu(x)=e^{-x^2}$. I primi due sono $H_0(x)=1$ e $H_1(x)=x$. Inoltre i polinomi di Hermite di indice pari sono polinomi pari, mentre quelli di indice dispari sono polinomi dispari.
\subsection{Relazione di ricorrenza per i polinomi di Hermite}
Esplicitando l'uguaglianza $a|n\ket=\sqrt{n}|n-1\ket$ troviamo:
\begin{align*}
\frac{1}{\sqrt{2}}\left(\xi+\frac{\partial}{\partial\xi}\right)\frac{1}{\sqrt{2^n n!}}H_n(\xi)\frac{e^{-\xi^2/2}}{\sqrt[4]{\pi}}&=\sqrt{n}\frac{1}{\sqrt{2^{n-1}(n-1)!}}H_{n-1}(\xi)\frac{e^{-\xi^2/2}}{\sqrt[4]{\pi}} \\
\left(\xi+\frac{\partial}{\partial\xi}\right)H_n(\xi)e^{-\xi^2/2}&=2nH_{n-1}(\xi)e^{-\xi^2} \\
\xi H_n(\xi)e^{-\xi^2/2}+H_n'(\xi)e^{-\xi^2/2}-\xi H_n(\xi)e^{-\xi^2/2}&=2nH_n(\xi)e^{-\xi^2/2}\;.
\end{align*}
Semplificando, troviamo l'equazione differenziale:
\begin{equation}
H_n'(\xi)=2n H_{n-1}(\xi)\;,
\end{equation}
Se invece esplicitiamo l'uguaglianza $\adj{a}|n\ket=\sqrt{n+1}|n+1\ket$ troviamo l'equazione differenziale:
\begin{equation}
H_n'(\xi)=2\xi H_n(\xi)-H_{n+1}(\xi)\;.
\end{equation}
Uguagliando le due equazioni troviamo la relazione di ricorrenza:
\begin{equation}
H_{n+1}(\xi)=2\xi H_n(\xi)-2n H_{n-1}(\xi)\;.
\end{equation}
Inoltre, dopo alcuni passaggi, troviamo l'\textit{equazione differenziale di Hermite}:
\begin{equation}
H''_n(\xi)-2\xi H'_n(\xi)+2n H_n(\xi)=0\;.
\end{equation}
Data una generica successione di polinomi $\{P_n(x)\}$, si definisce la \textit{funzione generatrice} della successione:
\begin{equation}
g(s,x)=\sum_{n=0}^{\infty} \frac{s^n}{n!}P_n(x)\;,\qquad\qquad P_n(x)=\left.\pdev[n]{g}{s}\right|_{(0,x)}\;.
\end{equation}
Scriviamo adesso la funzione generatrice dei polinomi di Hermite. Partiamo a tal scopo dall'identità:
\begin{equation}
\left(\frac{\partial}{\partial\xi}-\xi\right)^nf(\xi)=e^{\xi^2/2}\frac{\partial^n}{\partial\xi^n}(e^{-\xi^2/2}f(\xi))\;.
\end{equation}
Possiamo riscrivere gli stati eccitati come:
\begin{align*}
\psi_n(\xi) &= \frac{1}{\sqrt{2^n n!}}(-1)^n\left(\frac{\partial}{\partial\xi}\right)^n\psi_0(\xi) \\
&= \frac{(-1)^n}{\sqrt{2^n n!}}e^{\xi^2/2}\frac{\partial^n}{\partial\xi^n}\left(e^{-\xi^2/2}\frac{e^{-\xi^2/2}}{\sqrt[4]{\pi}}\right) \\
&= \frac{(-1)^n}{\sqrt[4]{\pi}\sqrt{2^n n!}}e^{-\xi^2/2}\frac{\partial^n}{\partial\xi^n}(e^{-\xi^2/2} \\
&\stackrel{!}{=} \frac{1}{\sqrt[4]{\pi}\sqrt{2^n n!}}H_n(\xi)e^{-\xi^2/2}\;,
\end{align*}
da cui ottieniamo la \textit{formula di Rodriguez}:
\begin{equation}
H_n(\xi)=(-1)^n e^{\xi^2}\frac{\diff^n}{\diff{\xi}^n}e^{-\xi^2}\;.
\end{equation}
La funzione generatrice dei polinomi di Hermite è quindi data da:
\begin{align}
g(s,x)&=\sum_{n=0}^{\infty}\frac{(-s)^n}{n!}e^{\xi^2}\frac{\diff^n}{\diff{\xi}^n}e^{-\xi^2} \notag \\
&= e^{\xi^2}e^{-(\xi-s)^2}=e^{\xi^2-\xi^2+2\xi s-s^2}\;, \notag \\
g(s,x) &= e^{-s^2+2\xi s}\;.
\end{align}
\section{Metodo differenziale}
Il terzo metodo di risoluzione consiste nel risolvere direttamente l'equazione di \Sch:
\begin{equation}
-\frac{\hbar^2}{2m}\psi''+\frac{1}{2}m\omega^2x^2\psi=E\psi\;.
\end{equation}
In unità adimensionali, $x=\ell\xi$:
\begin{align*}
-\frac{\hbar^2}{2m}\frac{1}{\ell^2}\pdev[2]{\psi}{\xi}+\frac{1}{2}m\omega^2\ell^2\xi^2\psi&=E\psi \\
-\frac{1}{2}\pdev[2]{\psi}{\xi}+\frac{1}{2}\frac{m^2\omega^2}{\hbar^2}\ell^4\xi^2\psi&=\frac{Em\ell^2}{\hbar^2}\psi\;,
\end{align*}
cioè:
\begin{equation}
-\psi''(\xi)+\xi^2\psi(\xi)=\mathcal{E}\psi,\qquad \qquad \mathcal{E}=\frac{2E}{\hbar\omega}\;. \label{ch4_metododiff}
\end{equation}
Avevamo visto precedentemente che $E=(n+1/2)\hbar\omega$. Ciò implica che $\mathcal{E}=2n+1$, cioè l'equazione \eqref{ch4_metododiff} ha soluzione se e solo se $\mathcal{E}$ è un intero dispari. I coefficienti delle $\psi$ non presentano singolarità e quindi dall'analisi complessa sappiamo che le soluzioni, se esistono, sono funzioni intere, cioè analitiche su tutto il piano complesso. \\
In unità adimensionali, l'equazione diventa:
$$
-\frac{1}{2}y''+\frac{1}{2}\xi^2y=Ey\;.
$$
Prendiamo $y=f(\xi)e^{-\xi^2/2}$. Sostituendo, ottengo per $f$ l'equazione:
\begin{equation}
f''-2\xi f'+(\mathcal{E}-1)f=0,\qquad\qquad \mathcal{E}=2E\;.
\end{equation}
Il potenziale è pari, dunque sappiamo che la soluzione è pari o dispari. Prendiamo $f$ pari che risolve il problema di Cauchy:
\begin{equation}
\begin{cases}
f''-2\xi f'+(\mathcal{E}-1)f=0\;, \\
\\
f(0)=1\;, \\
\\
f'(0)=0\;,
\end{cases}
\end{equation}
e cerchiamo $f$ in forma di serie, cioè $f=\sum_{k=0}^{\infty} c_k\xi^{2k}$. Sostituendo si trova:
$$
\sum_{k=1}^{\infty} 2k(2k-1)c_k\xi^{2k-2}-2\xi\sum_{k=0}^{\infty}c_k 2k\xi^{2k-1}+(\mathcal{E}-1)\sum_{k=0}^{\infty} c_k \xi^{2k}=0\;.
$$
Shiftiamo gli indici delle prime due sommatorie in modo tale che tutto parta da $k=0$:
$$
\sum_{k=0}^{\infty} (2k+2)(2k+1)c_{k+1}\xi^{2k}-\sum_{k=0}^{\infty}c_k 4k\xi^{2k}+(\mathcal{E}-1)\sum_{k=0}^{\infty} c_k\xi^{2k}=0\;.
$$
Pertanto otteniamo una relazione ricorsiva per i coefficienti:
\begin{equation}
\begin{cases}
c_0=1\;, \\
\\
c_{k+1}=\dfrac{4k-(\mathcal{E}-1)}{(2k+2)(2k+1)}c_k\;.
\end{cases} \label{ch4_coefficienti}
\end{equation}
Per $k$ grande, $c_{k+1}\simeq c_k/(k+1)$, cioè $c_k=c_0/k!$. Allora:
$$
f\simeq \sum_k \frac{c_0}{k!}\xi^{2k}=c_0e^{\xi^2}\;.
$$
Ma questa soluzione da problemi, in quanto $y=e^{-\xi^2/2}f(\xi)\not\in\mathbb{L}^2$. Se però esiste un $c_k=0$, allora tutti i successivi coefficienti sono nulli, e la serie diventa una somma finita. Ciò avviene per $k^*$ tale che il numeratore di \eqref{ch4_coefficienti} si annulli, cioè $\mathcal{E}-1=4k^*=2(2k^*)=2n$, da cui $2E=2n+1$ e quindi $E=n+1/2$. In conclusione, se $E=n+1/2$, $f$ non è più una serie ma una somma finita che non converge più a $e^{\xi^2}$, quindi la soluzione $y$ è in $\mathbb{L}^2$. \\
\\
Riprendiamo la soluzione in rappresentazione di \Sch:
\begin{equation}
\psi_n(x)=\frac{1}{\pi^{1/4}}\frac{1}{\sqrt{2^n n!}}H_n(\xi)e^{-\xi^2/2}\;.
\end{equation}
L'$n+1$-esimo autostato è proporzionale a $H_n(\xi)$, $n$-esimo polinomio di Hermite. Ci domandiamo se $H_n$ rappresenta unicamente l'$n+1$-esimo stato, oppure può rappresentarne altri. Innanzitutto, notiamo che $H_n$ ha al più $n$ zeri, quindi per il teorema dei nodi non può rappresentare uno stato superiore all'$n+1$-esimo. Inoltre, poiché $H_n$ è ortogonale ai precedenti polinomi $H_0,\ldots,H_{n-1}$ che fra loro sono indipendenti, allora $H_n$ non può rappresentare meno dell'$n+1$-esimo stato. Quindi concludiamo che $H_n$ rappresenta unicamente l'$n+1$-esimo autostato. \\
Le $\psi_n$ così trovate costituiscono un set completo? Se lo fossero, ogni $\psi\in\mathbb{L}^2$ può essere scritta come:
$$
\psi(\xi)=\sum c_n\psi_n(\xi), \qquad\qquad c_n=\int_{-\infty}^{+\infty}\psi_n(\xi)\psi(\xi)\;\diff{\xi}\;.
$$
Se invece non lo fossero, si avrebbe:
\begin{equation}
f(\xi)=\psi(\xi)-\sum_k c_k\psi_k(\xi)\ne 0,\qquad\qquad f\perp\psi_k\quad\forall k\;.
\end{equation}
Fra tutte le funzioni ortogonali alle $\psi_k$, scegliamo quella che minimizza l'energia con i vincoli:
$$
\int f^2\;\diff{\xi}=1 \qquad\qquad \int f\psi_k\;\diff{\xi}=0\;.
$$
Usiamo il metodo dei moltiplicatori di Lagrange:
\begin{equation}
\int (f,Hf)\;\diff{\xi}-E\left(\int f^2\;\diff{\xi} -1\right)-2\lambda_k\sum_k\int f\psi_k\;\diff{\xi}\;.
\end{equation}
Derivando rispetto a $f$ si ottiene:
\begin{equation}
Hf-Ef-\sum_k\lambda_k\psi_k=0\;.
\end{equation}
Moltiplico scalarmente per $\psi_n$:
\begin{align*}
\bra\psi_n|Hf\ket-E\bra\psi_n|f\ket-\lambda_n &= 0\;, \\
\bra H\psi_n|f\ket-E\bra\psi_n|f\ket &=\lambda_n\;, \\
E_n\bra\psi_n|f\ket-E\bra\psi_n|f\ket &= \lambda_n\;, \\
(E_n-E)\bra\psi_n|f\ket &=\lambda_n \Longrightarrow \lambda_n=0\;.
\end{align*}
In quanto per ipotesi $\psi_n\perp f$. Allora l'equazione per $f$ è $Hf=Ef$, ma questo implica che $f$ sia un autostato e $E$ un autovalore dell'equazione di \Sch, ma per ipotesi non ci sono altri autostati oltre a $\{\psi_k\}$. Quindi anche $E=0$. Risulta perciò $f\equiv 0$. Si conclude che $\{\psi_k\}$ è un set completo.
\section{Interpretazione della funzione d'onda nel metodo astratto}
Lo spazio di Hilbert che avevamo definito tramite il metodo astratto era :
\begin{equation}
\ham =\left\{\left.|\psi\ket=\sum c_n|n\ket\;\right|\; \sum |c_n|^2<\infty\right\}\;.
\end{equation}
La probabilità di trovare un certo autostato, come sappiamo è $|c_n|^2$ e l'ampiezza è $\bra n|\psi\ket$, il cui valore, in quanto prodotto scalare, non dipende dalla particolare scelta della base. Quindi diagonalizziamo l'operatore $q$:
\begin{equation}
q|\bar{x}\ket=\bar{x}|\bar{x}\ket\;.
\end{equation}
La soluzione del problema agli autovalori è $|\bar{x}\ket=\delta(x-\bar{x})$. Allora:
$$
\bra\bar{x}|\psi\ket=\int\diff{x}\; \delta(x-\bar{x})\psi(x)=\psi(\bar{x})\;.
$$
Concludiamo che la funzione d'onda è il coefficiente dello sviluppo in serie:
\begin{equation}
|\psi\ket=\sum_x |x\ket\bra x|\psi\ket\;.
\end{equation}
Per l'oscillatore armonico (in unità naturali):
$$
q=\frac{1}{\sqrt{2}}(a+\adj{a})\;.
$$
Vogliamo risolvere l'equazione $q|\xi\ket=\xi|\xi\ket$, con $|\xi\ket$ dato da:
\begin{equation}
|\xi\ket=\sum_{n=0}^{\infty} \frac{1}{\sqrt{2^n n!}}c_n|n\ket\;.
\end{equation}
Sostituendo troviamo la relazione:
\begin{equation}
c_{n+1}=2\xi c_n-2nc_{n-1}\;,
\end{equation}
che è proprio la relazione che determina i polinomi di Hermite, quindi $c_n=F(\xi)H_n(\xi)$. Determiniamo $F(\xi)$ dalla condizione di completezza $\bra\xi|\xi'\ket=\delta(\xi-\xi')$, ottenendo $F(\xi)=\pi^{-1/4}e^{-\xi^2/2}$. Quindi:
\begin{equation}
|\xi\ket=\sum_n \psi^*_n(\xi)|n\ket=\sum_n |n\ket\bra n|\xi\ket\;.
\end{equation}
\section{Funzione d'onda nelle p}
L'Hamiltoniana dell'oscillatore armonico era:
\begin{equation}
H=\frac{p^2}{2m}+\frac{1}{2}m\omega^2q^2\;,
\end{equation}
che, nella rappresentazione delle $q$, dava luogo all'operatore:
$$
H=-\frac{\hbar^2}{2m}\frac{\partial^2}{\partial x^2}+\frac{1}{2}m\omega x^2\;.
$$
Possiamo anche usare una rappresentazione nelle $p$, interpretando, al contrario dei casi precedenti, l'operatore $\hat{p}$ come una moltiplicazione per $p$ e l'operatore $\hat{q}$ come una derivazione rispetto a $p$. In questa rappresentazione, l'operatore Hamiltoniano diventa:
\begin{equation}
H=\frac{p^2}{2m}-\frac{\hbar^2}{2}m\omega^2\frac{\partial^2}{\partial p^2}\;.
\end{equation}
La funzione d'onda nelle $p$ sarà allora:
\begin{equation}
\varphi(p)=c_nH_n(p)e^{-p^2/2}\;.
\end{equation}
\section{Stati coerenti}
Gli stati coerenti di un sistema sono quelli che assomigliano di più alla descrizione classica del sistema. Considerando gli operatori di distruzione e creazione,
\begin{align*}
a|n\ket &=\sqrt{n}|n-1\ket\;, \\
\adj{a}|n\ket=\sqrt{n+1}|n+1\ket\;.
\end{align*}
Gli stati coerenti sono definiti come gli autostati dell'operatore di distruzione $a$. Innanzitutto, notiamo che non esistono autostati dell'operatore di creazione perché fa salire la scala. Tuttavia possono esistere stati $|\beta\ket$ che soddisfano:
$$
a|\beta\ket=\beta|\beta\ket,\qquad \beta\in\mathbb{C},\qquad |\beta\ket=\sum c_n|n\ket\;.
$$
Risolviamo pertanto l'equazione:
\begin{equation}
a\left(\sum c_n|n\ket\right)= \sum_0^{\infty} c_n\sqrt{n}|n-1\ket=\beta\sum_0^{\infty} c_n|n\ket\;.
\end{equation}
Il termine con $n=0$ della prima serie è nullo, quindi lo eliminiamo:
$$
\sum_1^{\infty} c_n\sqrt{n}|n-1\ket=\beta\sum_0^{\infty} c_n|n\ket\;.
$$
Shiftiamo adesso la prima serie di 1 tramite la posizione $n=k+1=n+1$:
$$
\sum_0^{\infty} c_{n+1}\sqrt{n+1}|n\ket=\beta\sum_0^{\infty} c_n|n\ket\;,
$$
da cui si ottiene la relazione di ricorrenza:
\begin{equation}
c_{n+1}\sqrt{n+1}=\beta c_n\;,
\end{equation}
che implica:
\begin{equation}
c_{n+1}=\frac{\beta^{n+1}}{\sqrt{(n+1)!}}c_0\quad \Longrightarrow\quad c_n=\frac{\beta^n}{\sqrt{n!}}c_0\;.
\end{equation}
Pertanto gli stati coerenti sono dati da:
\begin{equation}
|\beta\ket=\sum_{n=0}^{\infty}\frac{\beta^n}{\sqrt{n!}}|n\ket\;.
\end{equation}
$c_0$ è la costante di normalizzazione:
\begin{align*}
1=\bra\beta|\beta\ket &= |c_0|^2\left(\sum_n \frac{\beta^{*n}}{\sqrt{n!}}\bra n|\right)\left(\sum_s \frac{\beta^s}{\sqrt{s!}}|s\ket\right) \\
&= |c_0|^2\sum_n \frac{1}{n!}(|\beta|^2)^n= |c_0|^2 e^{|\beta|^2}\;.
\end{align*}
quindi $c_0=e^{-|\beta|^2/2}$. Gli stati coerenti sono:
\begin{equation}
|\beta\ket=e^{-|\beta|^2/2}\sum_{n=0}^{\infty}\frac{\beta^n}{\sqrt{n!}}|n\ket\;.
\end{equation}
Ma, poiché valeva:
$$
|n\ket=\frac{(\adj{a})^n}{\sqrt{n}!}|0\ket\;,
$$
si ha:
\begin{equation}
|\beta\ket=e^{-|\beta|^2/2}\sum_n \frac{\beta^n}{n!}(\adj{a})^n|0\ket=e^{-|\beta|^2/2}e^{\beta\adj{a}}|0\ket\;. \label{ch4_staticoerenti}
\end{equation}
Il valor medio di $q$ su uno stato coerente è dato da:
\begin{equation}
\bra\beta|q|\beta\ket=\frac{1}{\sqrt{2}}\bra\beta|a+\adj{a}|\beta\ket=\frac{1}{\sqrt{2}}(\beta+\beta^*)=\sqrt{2}\mathrm{Re}(\beta)\;.
\end{equation}
Studiamo l'evoluzione temporale di uno stato coerente:
\begin{align*}
|\beta(t)\ket &= e^{-iHt/\hbar}|\beta\ket=e^{-iHt/\hbar}\left(\sum_n e^{-|\beta|^2/2}\frac{\beta^n}{\sqrt{n!}}|n\ket\right) \\
&= \sum_n e^{-|\beta|^2/2}\frac{\beta^n}{\sqrt{n!}}e^{-i\omega(n+1/2)t}|n\ket= e^{-i\omega t/2}\sum_n e^{-|\beta|^2/2}\frac{1}{\sqrt{n!}}(\beta e^{i\omega t})^n|n\ket \\
&= e^{-i\omega t/2}|\beta e^{-i\omega t}\ket\;.
\end{align*}
Quindi uno stato coerente rimane nel tempo uno stato coerente a meno di una fase $\omega t$. Adesso, preso $\beta=|\beta|e^{i\phi}$, calcoliamo:
$$
\bra \beta(t)|q|\beta(t)\ket=\bra\beta e^{-i\omega t}|q|\beta e^{-i\omega t}\ket=\sqrt{2}\Re(\beta e^{-i\omega t}=\sqrt{2}|\beta|\cos(\omega t-\phi)\;,
$$
che è appunto il moto classico di un oscillatore armonico.
\section{Stati coerenti in rappresentazione di \Sch}
Abbiamo visto che $\bar{q}=\sqrt{2}\mathrm{Re}(\beta)$. Scriviamo adesso gli scarti quadratici di $q$ e $p$:
\begin{align*}
\overline{\Delta q^2} &=\overline{q^2}-\overline{q}^2\;, \\
\overline{\Delta p^2} &= \overline{p^2}-\overline{p}^2\;.
\end{align*}
Sfruttando il fatto che $[a,\adj{a}]=1$, possiamo scrivere:
$$
q^2=\frac{1}{2}(a+\adj{a})^2=\frac{1}{2}\left[a^2+(\adj{a})^2+a\adj{a}+\adj{a}a\right]=\frac{1}{2}\left[a^2+(\adj{a})^2+2\adj{a}a+1\right]\;.
$$
Quindi:
\begin{equation}
\bra\beta|q^2|\beta\ket=\frac{1}{2}\left[\beta^2+\beta^{*2}+2\beta\beta^*+1\right]=\frac{1}{2}\left[(\beta+\beta^*)^2+1\right]=2\mathrm{Re}(\beta)^2+\frac{1}{2}\;.
\end{equation}
Da cui:
\begin{equation}
\overline{\Delta q^2}=2\mathrm{Re}(\beta)^2+\frac{1}{2}-2\Re(\beta)^2=\frac{1}{2}\;.
\end{equation}
Facendo lo stesso tipo di conto, si trova che anche $\overline{\Delta p^2}=1/2$, da cui:
$$
\Delta q\Delta p=\frac{1}{2}\;.
$$
Cioè gli stati coerenti sono caratterizzati dalla minima indeterminazione. Risolviamo adesso l'equazione degli stati coerenti in rappresentazione di \Sch:
\begin{equation}
\frac{1}{\sqrt{2}}\left(\xi+\frac{\partial}{\partial\xi}\right)\psi_{\beta}(\xi)=\beta\psi_{\beta}(\xi)\;,
\end{equation}
cioè:
$$
\pdev{\psi_{\beta}}{\xi}=-(\xi-\sqrt{2}\beta)\psi_{\beta}\;,
$$
da cui:
\begin{equation}
\psi_{\beta}(\xi)=Ce^{-(\xi-\sqrt{2}\beta)^2/2}\;.
\end{equation}
Gli stati coerenti sono perciò gli autostati normali shiftati di $\sqrt{2}\beta$. \\
\\
\textbf{Esempio}. Particella carica $q$ in campo esterno costante $\mathbf{E}$. \\
\\
L'Hamiltoniana della particella sarà data da:
\begin{equation}
H=\frac{p^2}{2m}+\frac{1}{2}m\omega^2 x^2-qxE\;.
\end{equation}
Possiamo riscrivere i termini dipendenti da $x$ come:
$$
\frac{1}{2}m\omega^2 x^2-qxE=\frac{1}{2}m\omega^2\left(x^2-\frac{2qE}{m\omega^2}x\right)=\frac{1}{2}\left(x-\frac{qE}{m\omega^2}\right)^2-\frac{1}{2}m\omega^2\left(\frac{qE}{m\omega^2}\right)^2\;,
$$
quindi:
\begin{equation}
H=\frac{p^2}{2m}+\frac{1}{2}m\omega^2\left(x-\frac{qE}{m\omega^2}\right)^2-\frac{1}{2}m\omega^2\left(\frac{qE}{m\omega^2}\right)^2\;.
\end{equation}
Risolvendo rispetto alle variabili:
$$
z=x-\frac{qE}{m\omega^2},\qquad\qquad p=\frac{\hbar}{i}\frac{\partial}{\partial z}\;.
$$
Otteniamo la nuova espressione per i livelli energetici:
\begin{equation}
\mathcal{E}_n'=\hbar\omega\left(n+\frac{1}{2}\right)-\frac{1}{2}\frac{q^2E^2}{m\omega^2}\;. \label{ch4_energetic}
\end{equation}
Il valor medio del dipolo in questa situazione è dato da:
\begin{equation}
\bra 0'|d|0'\ket=q\bra 0'|z+\frac{qE}{m\omega^2}|0'\ket=\frac{q^2E}{m\omega^2}\;,
\end{equation}
dove $q^2/m\omega^2\equiv \alpha$ è il coefficiente di polarizzabilità. In caso di dipolo indotto, avevamo che $U=-\alpha E^2/2$, risultato che ritroviamo nella \eqref{ch4_energetic}. \\
\\
Dimostriamo adesso che gli stati coerenti possono essere ricavati a partire dallo stato fondamentale mediante un operatore. Sia:
\begin{equation}
U(\beta)\equiv e^{\beta\adj{a}-\beta^*a}\;.
\end{equation}
L'operatore $B\equiv \beta\adj{a}-\beta^*a$ è tale che $\adj{B}=\beta^*a-\beta\adj{a}=-B$, quindi:
$$
\adj{U}=e^{\adj{B}}=e^{-B}=U^{-1}\;,
$$
da cui segue che $U$ è un operatore unitario. Allora lo stato $|\beta\ket\equiv U(\beta)|0\ket$ è un autostato di $a$. Innanzitutto notiamo che $\bra\beta|\beta\ket=\bra 0|\adj{U}U|0\ket=1$:
$$
a|\beta\ket=aU(\beta)|0\ket=ae^B|0\ket\;.
$$
Valgono le relazioni:
\begin{align}
[a,B]&=\left[a,\beta\adj{a}-\beta^*a\right]=\beta\;, \notag \\
e^{-B}ae^B&=a+[a,B]\;,
\end{align}
quindi:
$$
e^{-B}ae^B=a+\beta \qquad \Longrightarrow \qquad ae^B=e^Ba+e^B\beta\;.
$$
Di conseguenza:
\begin{equation}
ae^B|0\ket=(e^Ba+e^B\beta)|0\ket=\beta e^B|0\ket\;,
\end{equation}
è la definizione di stato coerente. Dimostriamo adesso che questa definizione coincide con la \eqref{ch4_staticoerenti}. Innanzitutto dimostriamo il seguente:
\begin{thm}[Formula di Campbell-Hausdorff]
Siano $A,B$ due operatori tali che $[A,B]=c$, $c$ costante. Allora si ha:
\begin{equation}
e^Ae^Be^{-\frac{1}{2}[A,B]}=e^{A+B}\;.
\end{equation}
\end{thm}
\proof
Definiamo le funzioni:
\begin{align}
G(t) &= e^{tA}e^{tB}e^{-\frac{1}{2}t^2[A,B]}\;, \notag \\
F(t) &= e^{t(A+B)}\;.
\end{align}
Si ha $G(0)=F(0)=1$. Le derivate prime saranno invece:
\begin{align*}
F'(t)&=e^{t(A+B)}(A+B)=F(t)(A+B)\;, \\
G'(t)&= e^{tA}Ae^{tB}e^{-\frac{1}{2}t^2[A,B]}+e^{tA}e^{tB}Be^{-\frac{1}{2}t^2[A,B]}+e^{tA}e^{tB}e^{-\frac{1}{2}t^2[A,B]}(-t[A,B]) \\
&= e^{tA}e^{tB}(A+t[A,B])e^{-\frac{1}{2}t^2[A,B]}+e^{tA}e^{tB}Be^{-\frac{1}{2}t^2[A,B]}-te^{tA}e^{tB}e^{-\frac{1}{2}t^2[A,B]}[A,B] \\
&= e^{tA}e^{tB}e^{-\frac{1}{2}t^2[A,B]}(A+B)=G(t)(A+B)\;.
\end{align*}
Allora $F$ e $G$ risolvono lo stesso problema di Cauchy:
$$
\begin{cases}
F'(t)=F(t)(A+B)\;, \\
\\
F(0)=1\;,
\end{cases} \qquad\qquad
\begin{cases}
G'(t)=G(t)(A+B)\;, \\
\\
G(0)=1\;,
\end{cases}
$$
quindi per il teorema di esistenza ed unicità, $F(t)\equiv G(t)$, in particolare, per $t=1$ otteniamo la tesi.
\endproof
Allora possiamo scrivere, alla luce di questa formula:
\begin{equation}
U(\beta)=e^{\beta\adj{a}-\beta^*a}=e^{\beta\adj{a}}e^{\beta^*a}e^{-|\beta|^2/2}\;.
\end{equation}
Quindi:
\begin{equation}
U(\beta)|0\ket=e^{-|\beta|^2/2}e^{\beta\adj{a}}e^{-\beta^*a}|0\ket=e^{-|\beta|^2/2}e^{\beta\adj{a}}|0\ket\;,
\end{equation}
che coincide con la \eqref{ch4_staticoerenti}.
\chapter{Potenziali a caso}
\section{Soluzioni asintotiche}
Consideriamo un sistema con un potenziale $V(x)>0$ a supporto compatto. Il sistema non ammette stati legati. L'equazione di \Sch\; è la solita. In questo caso, stiamo descrivendo una situazione tipica di scattering. Vogliamo descriverne le soluzioni. Nelle zone in cui $V=0$, avremo soluzioni del tipo onda piana $e^{\pm ikx}, k=p/\hbar$ con frequenza $\omega=E/\hbar$, e quindi energia $E=\hbar^2k^2/2m$. Nella realtà avremo una sovrapposizione di onde piane, cioè un pacchetto d'onda. Indichiamo con $I$ la zona a sinistra del dominio del potenziale e con $II$ quella a destra. In zona $I$ avremo l'onda incidente più un'onda riflessa, mentre in zona $II$ avremo solo l'onda trasmessa:
\begin{equation*}
\begin{cases}
\psi_I(x)= ae^{ikx}+be^{-ikx}\;, \\
\\
\psi_{II}(x)=ce^{ikx}\;.
\end{cases}
\end{equation*}
Con le dovute normalizzazioni, ci riconduciamo alla forma:
\begin{equation}
\psi(x)=\begin{cases}
e^{ikx}+Re^{-ikx} \qquad I\;, \\
\\
Te^{ikx} \qquad II\;.
\end{cases}
\end{equation}
$T$ rappresenta l'ampiezza di trasmissione e $|T|^2$ è il \textit{coefficiente di trasmissione}, cioè la probabilità che l'onda passi la barriera. $R$ è l'ampiezza di riflessione e $|R|^2$ è il \textit{coefficiente di riflessione}, cioè la probabilità che l'onda venga riflessa. In termini di probabilità, è naturale che debba essere $|R|^2+|T|^2=1$. Questa identità può essere ricavata direttamente dall'equazione di \Sch:
$$
-\frac{\hbar^2}{2m}\psi''+V(x)\psi=E\psi\;.
$$
Dato che il problema è stazionario si conserva la corrente:
$$
j(x)=\frac{\hbar}{2im}(\psi^*\partial_x\psi-\psi\partial_x\psi^*)\;.
$$
Dato che $\partial_xj(x)=0$, la corrente sarà la stessa sia in zona $I$ che in zona $II$. Se $\psi(x)=ae^{ikx}+be^{-ikx}$, allora $j=\hbar k(|a|^2-|b|^2)/m$, quindi si ottiene:
$$
j_I=\frac{\hbar^2k}{m}(1-|R|^2)=\frac{\hbar^2 k}{m}|T|^2=j_{II} \quad \Longrightarrow \quad |R|^2+|T|^2=1\;.
$$
Prendiamo adesso un potenziale che è nullo in zona $I$ ed è costante $V_0$ in zona $II$. Adesso le soluzioni nelle due zone sono date da:
\begin{equation}
\begin{cases}
\psi_I(x)=e^{ikx}+Re^{-ikx}\;, \\
\\
\psi_{II}(x)=Te^{iqx}\;,
\end{cases}
\end{equation}
con $k,q$ tali che:
\begin{equation}
E=\frac{\hbar^2 k^2}{2m}\;,\qquad\qquad \frac{\hbar^2 q^2}{2m}=E-V_0\;.
\end{equation}
Anche in questo caso si conserva la corrente, data nelle due zone da:
\begin{align*}
j_I &=\frac{\hbar k}{m}(1-|R|^2)\;, \\
j_{II} &=\frac{\hbar q}{m}|T|^2\;,
\end{align*}
quindi possiamo definire:
$$
\frac{\mbox{num. di particelle che passano}}{\mbox{num. di particelle incidenti}}=\frac{q|T|^2}{k}\;, \qquad \qquad
\frac{\mbox{num. di particelle riflesse}}{\mbox{num. di particelle incidenti}}=|R|^2\;.
$$
\section{Gradino di potenziale}
Consideriamo un gradino di potenziale:
\begin{equation}
V(x)=\begin{cases}
0 \qquad x<0\;, \\
\\
V_0 \qquad x>0\;.
\end{cases}
\end{equation}
Identifichiamo $x<0$ con la zona $I$ e $x>0$ con la zona $II$. Se l'energia $E$ è minore di $V_0$, le soluzioni saranno date da:
\begin{equation}
\begin{cases}
\psi_I=e^{ikx}+Re^{-ikx}\;, \\
\\
\psi_{II}=Ae^{-\alpha x}\;.
\end{cases}
\end{equation}
Determiniamo la costante $\alpha$ dall'equazione di \Sch:
$$
-\frac{\hbar^2}{2m}\alpha A+AV_0=EA \qquad \Longrightarrow \qquad \alpha=\sqrt{\frac{2m(V_0-E)}{\hbar^2}}\;.
$$
Troviamo $A$ e $R$ imponendo la continuità di $\psi$ e $\psi'$ in $x=0$:
\begin{equation}
\begin{cases}
1+R=A\;, \\
\\
ik(1-R)=-\alpha A\;,
\end{cases} \qquad \Longrightarrow \qquad
\begin{cases}
R=\dfrac{\alpha+ik}{ik-\alpha}\;, \\
\\
A=\dfrac{2ik}{ik-\alpha}\;.
\end{cases}
\end{equation}
Se invece $E>V_0$ abbiamo:
\begin{equation}
\begin{cases}
\psi_I=e^{ikx}+Re^{-ikx}\;, \\
\\
\psi_{II}=Te^{iqx}\;,
\end{cases} \qquad\qquad \frac{\hbar^2 q^2}{2m}=E-V_0\;.
\end{equation}
Imponendo le condizioni:
\begin{equation}
\begin{cases}
1+R=T\;, \\
\\
k(1-R)=qT\;,
\end{cases}\qquad \Longrightarrow\qquad 
\begin{cases}
R=\dfrac{k-q}{k+q}\;, \\
\\
T=\dfrac{2k}{k+q}\;.
\end{cases}
\end{equation}
In generele, in zona $I$ si ha $\psi_I(x)=ae^{ikx}+be^{-ikx}$, e in zona $II$ $\psi_{II}(x)=ce^{ikx}+de^{-ikx}$. I coefficienti indipendenti sono $a,b$, e i coefficienti $c,d$ dipendono da essi linearmente:
\begin{equation*}
\left(\begin{matrix}
c \\
d
\end{matrix}\right)=\Omega\left(
\begin{matrix}
a \\
b
\end{matrix}\right)\;,
\end{equation*}
dove $\Omega$ è la \textit{matrice di transfer}, data da (in termini di $R$ e $T$):
\begin{equation}
\Omega=\left(
\begin{matrix}
1/T^* & -R^*/T^* \\
-R/T & 1/T
\end{matrix}\right)\;.
\end{equation}
In particolare si ha:
$$
\Omega\left(
\begin{matrix}
1 \\
R
\end{matrix}\right)=\left(
\begin{matrix}
T \\
0
\end{matrix}\right)\;.
$$
Poiché l'equazione è reale, se $\psi$ è soluzione, lo è anche $\psi^*$:
\begin{align*}
\psi_I=e^{ikx}+Re^{-ikx}\qquad &\Longrightarrow \qquad \psi_I^*=e^{-ikx}+R^*e^{ikx}\;, \\
\psi_{II}=Te^{ikx} \qquad &\Longrightarrow \qquad \psi_{II}^*=T^*e^{-ikx}\;,
\end{align*}
da cui:
$$
\Omega\left(
\begin{matrix}
R^* \\
1
\end{matrix}\right)=\left(
\begin{matrix}
0 \\
T^*
\end{matrix}\right)\;.
$$
Dal fatto che $|R|^2+|T|^2=1$ segue che $\det\Omega=1$, quindi $\Omega$ è unimodulare. \\
Se adesso mandiamo un fascio incidente da destra verso sinistra avremo:
$$
\left(\begin{matrix}
a \\
1
\end{matrix}\right)=\Omega\left(
\begin{matrix}
0 \\
b
\end{matrix}\right)\;,
$$
cioè:
\begin{equation}
\begin{cases}
a=-\dfrac{R^*}{T^*}b\;, \\
\\
1=\dfrac{b}{T}\;,
\end{cases}\qquad \Longrightarrow\qquad
\begin{cases}
a=-\dfrac{R^*}{T^*}T\;, \\
\\
b=T\;.
\end{cases}
\end{equation}
Quindi la probabilità di passare da destra verso sinistra è $|b|^2=|T|^2$, che è la stessa di passare da sinistra a destra. In generale si usa la seguente nomenclatura:
\begin{align}
\psi_R &=\left\{e^{ikx}+Re^{-ikx}\; ;\; Te^{ikx}\right\} \qquad \mbox{right-mover} \\
\psi_L &=\left\{-\frac{R^*}{T^*}Te^{-ikx}\; ;\; e^{-ikx}+Te^{ikx}\right\}\qquad \mbox{left-mover}
\end{align}
$\psi_R$ e $\psi_L$ sono due soluzioni linearmente indipendenti e devono soddisfare la relazione di ortogonalità:
\begin{equation}
\int\diff{x}\;\psi_R^*(k,x)\psi_L(k',x)=0 \quad \forall k,k'\;.
\end{equation}
La soluzione esatta del problema del potenziale dipende in generale dal tempo: $\psi^{(+)}(t)$. Per $t\to-\infty$, coincide con l'onda piana libera. Si impone allora, per $t\to-\infty$:
\begin{equation}
||\psi^{(+)}(t)-\psi_0(t)||\to 0\;.
\end{equation}
\section{Barriere di potenziale in sequenza}
Supponiamo di aver risolto il problema per un potenziale $V(x)>0$ centrato nell'origine (conosciamo cioè la matrice di transfer $\Omega_1$). Se trasliamo tutto a destra ($V\equiv V(x-d)$), l'equazione diventa:
\begin{equation}
-\frac{\hbar^2}{2m}\psi''+V(x-d)\psi=E\psi\;,
\end{equation}
con la posizione $z=x-d$ otteniamo la stessa equazione che avevamo risolto:
$$
-\frac{\hbar^2}{2m}\dev[2]{\psi}{z}+V(z)\psi=E\psi\;,
$$
per cui $\psi=\{e^{ikz}+Re^{-ikx}\; ;\; Te^{ikz}\}$. In termini di matrici:
$$
\left(\begin{matrix}
\alpha \\
\beta
\end{matrix}\right)=\Omega_1\left(
\begin{matrix}
a \\
b
\end{matrix}\right)\;,
$$
poiché:
$$
\alpha e^{ikz}+\beta e^{-ikz}=\alpha e^{ik(x-d)}+\beta e^{-ik(x-d)}\;,
$$
segue che le ampiezze acquistano una fase. Possiamo dunque scrivere:
$$
\left(\begin{matrix}
a \\
b
\end{matrix}\right)=\left(
\begin{matrix}
\alpha e^{-ikd} \\
\beta e^{ikd}
\end{matrix}\right)\qquad \Longleftrightarrow \qquad \left(
\begin{matrix}
\alpha \\
\beta
\end{matrix}\right)=\left(
\begin{matrix}
a e^{ikd} \\
b e^{-ikd}
\end{matrix}\right)=T(d)\left(
\begin{matrix}
a \\
b
\end{matrix}\right)\;,
$$
dove:
\begin{equation}
T(d)=\left(
\begin{matrix}
e^{ikd} & 0 \\
0 & e^{-ikd}
\end{matrix}\right)\;,
\end{equation}
è la matrice di traslazione. Si ottiene quindi:
\begin{equation}
T(d)\left(\begin{matrix}
a' \\
b'
\end{matrix}\right)=\Omega_1 T(d)\left(
\begin{matrix}
a \\
b
\end{matrix}\right) \qquad \Longrightarrow \qquad \left(
\begin{matrix}
a' \\
b'
\end{matrix}\right)=T^{-1}(d)\Omega_1 T(d)\left(
\begin{matrix}
a \\
b
\end{matrix}\right)\;,
\end{equation}
che equivale a un cambiamento di base (relazione di similitudine tra $\Omega_1'$ e $\Omega$). Allora:
$$
\varphi(x)=\left(
\begin{matrix}
ae^{ikx} \\
be^{-ikx}
\end{matrix}\right)=T(x)\left(
\begin{matrix}
a \\
b
\end{matrix}\right), \qquad \qquad
\left(\begin{matrix}
a' \\
b'
\end{matrix}\right)=\Omega_1\left(
\begin{matrix}
a \\
b
\end{matrix}\right)\;.
$$
Concludiamo che ($x_0$ e $x_1$ sono dei punti in zona asintotica rispettivamente a sinistra e a destra del dominio del potenziale):
\begin{equation}
T^{-1}(x_1)\varphi(x_1)=\Omega_1 T^{-1}(x_0)\varphi(x_0)\;,
\end{equation}
da cui:
\begin{equation}
\varphi(x_1)=T(x_1)\Omega_1 T^{-1}(x_0)\varphi(x_0)\;.
\end{equation}
Questa relazione lega la soluzione asintotica in zona $I$ a quella in zona $II$. \\
Supponiamo adesso di avere due potenziali $V_1$ e $V_2$ e di averli risolti separatamente, cioè supponiamo di conoscere le matrici di transfer $\Omega_1$ e $\Omega_2$ relative al problema singolo. Siano $\varphi(x_0)$ la soluzione asintotica a $x=-\infty$, $\varphi(x_1)$ la soluzione nella zona intermedia tra i due potenziali e $\varphi(x_2)$ la soluzione asintotica a $x=+\infty$. Allora si ha:
\begin{align}
\varphi(x_2) &= T(x_2)\Omega_2 T^{-1}(x_1)\varphi(x_1)\;, \notag \\
\varphi(x_1) &= T(x_1)\Omega_1 T^{-1}(x_0)\varphi(x_0)\;,
\end{align}
che rappresentano le soluzioni dei singoli problemi separati. Sostituendo troviamo:
\begin{equation}
\varphi(x_2)=T(x_2)\Omega_1\Omega_2 T^{-1}(x_0)\varphi(x_0)\;.
\end{equation}
Quindi la matrice di transfer totale è il prodotto delle singole matrici. Se ci mettiamo nell'ipotesi $\Omega_1=\Omega_2=\Omega$, allora:
$$
\Omega_{\mathrm{TOT}}=T^{-1}(d)\Omega T(d)\Omega\;.
$$
Per $N$ barriere identiche si ha:
\begin{equation}
\Omega_{\mathrm{TOT}}=(T(d))^{-N}(T(d)\Omega)^N\;.
\end{equation}
\textbf{Esempio: potenziale a delta.} \\
Risolviamo il problema di una buca di potenziale a delta con il formalismo matriciale. Sia $V(x)=-g\delta(x)$, $g=\hbar^2 \beta/m$. Sappiamo che esiste uno stato legato:
\begin{equation}
\psi_0(x)=\sqrt{\frac{\beta}{2}}e^{-\beta x}\;.
\end{equation}
Calcoliamo la matrice di transfer:
\begin{equation}
\psi(x)=\begin{cases}
e^{ikx}+Re^{-ikx}, \qquad x<0\;, \\
\\
Te^{ikx} \qquad x>0\;,
\end{cases}
\end{equation}
con la condizione:
\begin{equation}
\frac{\hbar^2}{2m}(\psi'(0^+)-\psi'(0^-))=-g\psi(0)\;.
\end{equation}
Imponendo la continuità di $\psi$ in $x=0$ troviamo la condizione $1+R=T$, mentre esplicitando l'equazione precedente:
\begin{equation}
ik(T-1+R)=2ik(T-1) \qquad \Longrightarrow \qquad 2ik(T-1)\frac{\hbar^2}{2m}=-\frac{\hbar^2}{m}\beta T\;.
\end{equation}
Otteniamo quindi il sistema:
\begin{equation}
\begin{cases}
1+R=T\;, \\
\\
2ik(T-1)=\beta T\;,
\end{cases} \qquad \Longrightarrow \qquad 
\begin{cases}
R=-\dfrac{\beta}{ik+\beta}\;, \\
\\
T=\dfrac{ik}{ik+\beta}\;.
\end{cases}
\end{equation}
Notiamo che $R,T$ hanno una singolarità per $k=i\beta$, che corrisponde al $k$ dello stato legato. In generale, $T$ ha poli del prim'ordine in $k$ sull'asse immaginario positivo in corrispondenza delle energie degli stati legati. \\
\\
\textbf{Esempio: buca di potenziale.} \\
Trattiamo adesso il problema della buca di potenziale col formalismo matriciale. Consideriamo una buca di potenziale centrata nell'origine estesa da $-a/2$ ad $a/2$ e di profondità $V_0<0$. La funzione d'onda sarà:
\begin{equation}
\begin{cases}
\psi_1(x)=e^{ikx}+Re^{-ikx}, \quad x<-a/2\;, \\
\\
\varphi(x)=Ae^{iqx}+Be^{-iqx} \quad -a/2<x<a/2\;, \\
\\
\psi_2(x)=Te^{ikx} \quad x>a/2\;.
\end{cases}
\end{equation}
Con le condizioni:
\begin{equation}
E=\frac{\hbar^2 k^2}{2m} \qquad \qquad \frac{\hbar^2 q^2}{2m}=E+V_0\;.
\end{equation}
Imponendo la continuità della funzione d'onda e della sua derivata in $x=\pm a/2$ troviamo quattro equazioni:
$$
\begin{cases}
\psi_1(-a/2)=\varphi(-a/2)\;, \\
\\
\psi'_1(-a/2)=\varphi'(-a/2)\;, \\
\\
\psi_2(a/2)=\varphi(a/2)\;, \\
\\
\psi'_2(a/2)=\varphi'(a/2)\;,
\end{cases}
$$
da cui ricaviamo i valori di $R$ e $T$:
\begin{equation}
\begin{cases}
R=e^{-iak}\dfrac{(k^2-q^2)\sin(aq)}{2ikq\cos(aq)+(k^2+q^2)\sin(aq)}\;, \\
\\
T=e^{-iak}\dfrac{2ikq}{2ikq\cos(aq)+(k^2+q^2)\sin(aq)}\;.
\end{cases}
\end{equation}
\section{Relazione di completezza}
Vogliamo adesso verificare per le soluzioni che abbiamo trovato nei vari casi la relazione di completezza:
\begin{equation}
\int\diff{x}\; \psi_{k'}^*(x)\psi_k(x)=2\pi\delta(k-k')\;.
\end{equation}
Innanzitutto siamo sicuri che ci sia la delta, in quanto gli autostati con $k$ diverso sono ortogonali, possiamo avere al più una cosa del tipo $2\pi M_k\delta(k-k')$. Dobbiamo determinare $M_k$. Consideriamo un intervallo finito $[-L/2,L/2]$. Allora, a meno di costanti,
\begin{equation}
\int_{-L/2}^{L/2} e^{-ik'x}e^{ikx}=
\begin{cases}
0\qquad \mbox{se}\; k'\ne k\;, \\
\\
\propto L\qquad \mbox{se}\; k'=k\;.
\end{cases} \label{ch5_integrale}
\end{equation}
$M_k$ è il coefficiente di $L$ nel risultato dell'integrale \eqref{ch5_integrale} nel caso $k=k'$. Nel caso di un potenziale qualunque:
\begin{align*}
\psi_R(x)&=\left\{ e^{ikx}+Re^{-ikx}\; ;\; Te^{ikx}\right\}\;, \\
\psi^*_R(x) &= \left\{ e^{-ikx}+R^*e^{ikx}\; ; \; T^*e^{-ikx}\right\}\;, \\
\psi_L(x) &= \left\{ Te^{-ikx} \; ; \; e^{-ikx}-\frac{R^*}{T^*}T e^{ikx}\right\}\;.
\end{align*}
L'integrale allora viene:
\begin{align*}
\int_{-L/2}^{L/2} \psi^*_R(x)\psi_R(x)\;\diff{x}&=\int_{-L/2}^0 (e^{-ikx}+R^*e^{ikx})(e^{ikx}+Re^{-ikx})\;\diff{x}+
\int_0^{L/2} T^*e^{-ikx}Te^{ikx} \\
&= (1+|R|^2)\frac{L}{2}+|T|^2\frac{L}{2}=(1+|R|^2+|T|^2)\frac{L}{2}=L\;.
\end{align*}
Quindi $M_k=1$, cioè gli stati sono correttamente normalizzati. Si ha inoltre:
\begin{equation}
\int\diff{x}\,\psi_R^*\psi_L= \frac{L}{2}R^*T-\frac{L}{2}\left(T^*\frac{R^*}{T^*}T\right)=0\;.
\end{equation}
quindi gli autostati sono effettivamente ortogonali. Dobbiamo in più controllare che $\psi_R,\psi_L$ siano ortogonali agli stati legati. \\
Siano $\varphi_n(x)$ le soluzioni dello spettro discreto e $f_{\alpha}(k,x)$ quelle dello spettro continuo. Allora la relazione di completezza che dobbiamo verificare sarà:
\begin{equation}
\sum_n \varphi_n(x)\varphi^*_n(x')+\sum_{\alpha}\int_0^{\infty} \frac{\diff{k}}{2\pi}f_{\alpha}(k,x)f^*_{\alpha}(k,x')=\delta(x-x')\;.
\end{equation}
Per $x,x'$ abbastanza grandi (cioè in zona asintotica), con $x,x'>0$, la parte continua viene:
\begin{align*}
&\int_0^{\infty}\frac{\diff{k}}{2\pi}|T|^2e^{ik(x-x')}+\int_0^{\infty}\frac{\diff{k}}{2\pi}\left[e^{-ikx}-\frac{R^*}{T^*}Te^{ikx}\right]\left[e^{ikx'}-\frac{R}{T}T^*e^{-ikx'}\right] \;, \\
&=\int_0^{\infty}\frac{\diff{k}}{2\pi}|T|^2e^{ik(x-x')}+\int_0^{\infty}\frac{\diff{k}}{2\pi}\left[e^{-ik(x-x')}+|R|^2e^{ikx(x-x')}\right]+\;\mbox{pezzi misti} \\
&=\int_0^{\infty}\frac{\diff{k}}{2\pi}(|T|^2+|R|^2)e^{ik(x-x')}+\int_{-\infty}^0\frac{\diff{k}}{2\pi}e^{ik(x-x')}+\;\mbox{pezzi misti} \\
&=\int_{-\infty}^{+\infty}\frac{\diff{k}}{2\pi}e^{ik(x-x')}+\;\mbox{pezzi misti}=\delta(x-x')+\;\mbox{pezzi misti}\;.
\end{align*}
Mentre:
$$
\mbox{pezzi misti} = \int_0^{\infty}\left[e^{-ik(x+x')}\frac{RT^*}{T}+\frac{R^*T}{T^*}e^{ik(x+x')}\right]\frac{\diff{k}}{2\pi}=-\int_{-\infty}^{+\infty}\frac{\diff{k}}{2\pi}\frac{R^* T}{T^*}e^{ik(x+x')}\;.
$$
Il termine del continuo viene quindi in conclusione:
\begin{equation}
\sum_{\alpha}\int_0^{\infty}\frac{\diff{k}}{2\pi}f_{\alpha}(k,x)f_{\alpha}^*(k,x')=\delta(x-x')-\int_{-\infty}^{+\infty} \frac{R^*}{T^*}Te^{ik(x+x')}\frac{\diff{k}}{2\pi}\;.
\end{equation}
Per calcolare l'ultimo integrale, integro sul piano complesso da $-R$ a $R$ sull'asse reale e chiudendo il cammino con una semicirconferenza di raggio $R$ nel semipiano $\mathrm{Im}(z)>0$ e uso il lemma di Jordan. Se $T$ non ha poli nel semipiano $\mathrm{Im}(z)>0$, allora il sistema non ha stati legati (i.e. il termine discreto della relazione di completezza è nullo). Ma allora la funzione integranda risulterebbe analitica su una curva chiusa e nei punti interni. Quindi per il primo teorema di Cauchy si ha:
$$
I=\int_{-\infty}^{+\infty} \frac{R^*}{T^*}Te^{ik(x+x')}\frac{\diff{k}}{2\pi}=0\;,
$$
che dimostra la relazione di completezza. Se invece $T$ ha dei poli in $\mathrm{Im}(z)>0$ (i.e. vi sono stati legati), allora $I\ne 0$, ma il suo contributo viene annullato dal termine discreto della relazione, quindi anche in questo caso la relazione di completezza è dimostrata. \\
\\
Studiamo adesso $T,R$ in funzione di $\mathcal{E}=2mE/\hbar^2\equiv k^2$. La funzione $k=\sqrt{\mathcal{E}}$ è a un sol valore su una superficie di Riemann a due fogli:
\begin{align*}
&\mathrm{Im}(k)>0: \qquad 0<\arg\mathcal{E}<2\pi \qquad \Longrightarrow \qquad \mbox{foglio 1 o foglio fisico}\;, \\
&\mathrm{Im}(k)<0: \qquad 2\pi<\arg\mathcal{E}<4\pi \qquad \Longrightarrow \qquad \mbox{foglio 2}\;.
\end{align*}
Quindi $T(\mathcal{E}),R(\mathcal{E})$ sono analitiche sul foglio fisico, tranne al più sul taglio. Siamo certi che $T$ abbia un taglio, infatti se scriviamo $T=1+if$, dalla relazione di unitarietà:
\begin{equation}
|T|^2+|R|^2=1+i(f-f^*)+|f|^2+|R|^2=1 \qquad \Longrightarrow \qquad 2\mathrm{Im}(f)=|R|^2+|f|^2\;,
\end{equation}
quindi $f$ ha una parte immaginaria sempre diversa da zero. Considero adesso un cammino chiuso $\gamma$ che non attraversi il taglio (pacman). $T$ è analitica su $\gamma$ e dentro; allora, per il secondo teorema di Cauchy:
\begin{equation}
T(\mathcal{E})=\oint_{\gamma} \frac{f(z)}{z-\mathcal{E}}\;\diff{z}\;.
\end{equation}
Questa può essere scritta come una relazione di dispersione (???). Nel caso in cui $k$ sia puramente immaginario, $k=i\alpha$, con $\alpha\in\mathbb{R}$:
\begin{align*}
e^{ikx}\quad &\longrightarrow \quad e^{-\alpha x}\;, \\
e^{-ikx}\quad &\longrightarrow \quad e^{\alpha x}\;.
\end{align*}
Per $x<0$, la soluzione accettabile è $e^{\alpha x}$, quindi:
$$
\left(\begin{matrix}
0 \\
1
\end{matrix}\right) \longrightarrow \left(
\begin{matrix}
a' \\
b'
\end{matrix}\right)=\Omega\left(\begin{matrix}
0 \\
1
\end{matrix}\right)=\left(\begin{matrix}
-R^*/T^* \\
1/T
\end{matrix}\right)\;,
$$
poiché a $x>0$ la soluzione accettabile è $e^{-\alpha x}$, dovrà essere $1/T=0$. In effetti, se $T$ ha un polo in $k=i\alpha$, allora $1/T$ ha uno zero in $k=i\alpha$. In più:
$$
\frac{R^*(i\alpha)}{T^*(i\alpha)}=-1\;,
$$
quindi:
$$
\left(\begin{matrix}
0 \\
1
\end{matrix}\right)\longrightarrow \Omega\left(
\begin{matrix}
0 \\
1
\end{matrix}\right)=\left(\begin{matrix}
1 \\
0
\end{matrix}\right)\;,
$$
che è esattamente il risultato che ci aspettavamo. \\
\\
Riprendendo in esame il caso di $N$ buche identiche di potenziale poste a distanza $d$ l'una dall'altra, avevamo trovato che la matrice di transfer totale era legata a quella di singolo potenziale dalla relazione:
$$
\Omega_N=[U(-d)]^N[U(d)\Omega]^N\;,
$$
dove:
\begin{equation}
U(d)=\left(\begin{matrix}
e^{ikd} & 0 \\
0 & e^{-ikd}
\end{matrix}\right)\;,
\end{equation}
è una traslazione e $\Omega$ era data da:
\begin{equation}
\Omega=\left(
\begin{matrix}
1/T^* & -R^*/T^* \\
-R/T & 1/T
\end{matrix}\right)\;.
\end{equation}
Sia $M=U(d)\Omega$ e $\mathcal{M}=M^N$. Si ha che:
\begin{equation}
\det[U(d)\Omega]=\det U(d)\cdot\det\Omega=1\;,
\end{equation}
in quanto $U$ è unitaria. Allora $M$ può essere diagonalizzata, cioè esisterà una matrice invertibile $S$ tale che:
\begin{equation}
S^{-1}U(d)\Omega S=\left(\begin{matrix}
\lambda_1 & 0 \\
0 & \lambda_2
\end{matrix}\right) \qquad\Longleftrightarrow\qquad M=U(d)\Omega=S\left(\begin{matrix}
\lambda_1 & 0 \\
0 & \lambda_2
\end{matrix}\right)S^{-1}\;.
\end{equation}
Si ha che gli elementi di $M$ sono lineari in $\lambda_1,\lambda_2$, in particolare, $[M]_{11}=c_1\lambda_1+c_2\lambda_2$. Inoltre $\mathcal{M}=M^N$ è diagonalizzabile tramite la stessa matrice $S$, e i suoi autovalori saranno $\lambda_1^N,\lambda_2^N$, dunque:
\begin{equation}
S^{-1}\mathcal{M}S=\left(\begin{matrix}
\lambda_1^N & 0 \\
0 & \lambda_2^N
\end{matrix}\right)\;.
\end{equation}
Anche in questo caso, gli elementi di matrice saranno lineari negli autovalori, dunque $[\mathcal{M}]_{11}=c_1\lambda_1^N+c_2\lambda_2^N$ ($c_1,c_2$ sono gli stessi coefficienti di prima). Dato che $\det\mathcal{M}=1$, allora dovrà essere $\lambda_1\lambda_2=1$. Se $|\lambda_1|>|\lambda_2|$, allora mandando $N\to\infty$ si ottiene:
\begin{equation}
[\mathcal{M}]_{11}=\frac{1}{T^*}=c_1\lambda_1^N+c_2\lambda_2^N\to\infty\;,
\end{equation}
da cui segue $T=0$. Se invece $|\lambda_1|=|\lambda_2|=1$ non abbiamo divergenze, e calcoliamo $\lambda_1$ dall'equazione:
\begin{equation}
\det\left[U(d)\Omega-e^{i\varphi}\right]=0\;. \label{ch5_lambda}
\end{equation}
Se scriviamo $T=|T|e^{i\delta}$, le soluzioni $\varphi$ della \eqref{ch5_lambda} dovranno soddisfare la relazione:
\begin{equation}
\left|\frac{\cos(kd+\delta)}{T}\right|=|\cos\varphi|\;,
\end{equation}
essendo tuttavia $|\cos\varphi|\le 1$ e $T\equiv T(k)$, segue che non tutti i valori di $k$ soddisfano questa relazione. Quindi, esistendo energie non ammissibili, per continuità esisteranno zone in cui non vi saranno soluzioni, cioè avremo dei \textit{gap di energia}. \\
L'Hamiltoniana di questo sistema sarà:
\begin{equation}
H=\frac{p^2}{2m}+V(x)\;,
\end{equation}
con $V(x+a)=V(x)$. Considero una funzione $U$ tale che $U(a)\psi(x)=\psi(x+a)\equiv\psi_a(x)$. \\
\\
\textbf{Osservazione}. Se $A$ è un operatore hermitiano, allora $e^{iA}$ è unitario. Infatti $\adj{U}=\adj{(e^{iA})}=e^{-i\adj{A}}=e^{-iA}=U^{-1}$. \\
\\
Se $U$ unitario commuta con l'Hamiltoniana, allora posso diagonalizzare $U$ e $H$ simultaneamente. In tal caso, $U$ rappresenterà una fase:
\begin{equation}
U(a)=e^{i\varphi}=e^{2\pi in/N},\qquad n=0,1,\ldots,N-1\;.
\end{equation}
Posto $q=2\pi n/Na$, possiamo scrivere $U(a)=e^{iqa}$. Allora $\psi$ è autostato di $U(a)$ se:
\begin{align*}
U(a)\psi(x)&=e^{iqa}\psi(x)\;, \\
U(a)\psi(x)&=\psi(x+a)\;.
\end{align*}
Presa:
\begin{equation}
\psi(x)=\left(
\begin{matrix}
ae^{ikx} \\
be^{-ikx}
\end{matrix}\right)\;,
\end{equation}
otteniamo:
\begin{equation*}
\left(\begin{matrix}
a'e^{ik(x+d)} \\
b'e^{-ik(x+d)}
\end{matrix}\right)=\left(\begin{matrix}
e^{ikd} & 0 \\
0 & e^{-ikd}
\end{matrix}\right)\left(\begin{matrix}
a'e^{ikx} \\
b'e^{-ikx}
\end{matrix}\right)=U(d)\Omega\left(
\begin{matrix}
a \\
b
\end{matrix}\right)\stackrel{!}{=}e^{iqd}\left(
\begin{matrix}
a \\
b
\end{matrix}\right)\;,
\end{equation*}
cioè dobbiamo risolvere il sistema lineare omogeneo:
\begin{equation}
U(d)\Omega\left(\begin{matrix}
a \\
b
\end{matrix}\right)=e^{iqd}\left(\begin{matrix}
a \\
b
\end{matrix}\right)\;.
\end{equation}
Questo sistema ammette soluzioni non banali se e solo se:
\begin{equation}
\det\left[U(d)\Omega-e^{iqd}\right]=0\;.
\end{equation}
\section{Approssimazione dei livelli energetici}
Consideriamo una successione di buche molto profonde equidistanti. Ogni singola buca (presa singolarmente) avrà uno stato legato. Poiché le buche sono identiche, le funzioni d'onda degli stati legati saranno le stesse, ma shiftate del passo delle buche, cioè la funzione d'onda dello stato legato dell'$n$-sima buca sarà funzione di $x$ e di $n$: $\varphi(x,n)$. Tuttavia, per effetto tunnel, esiste una probabilità che la particella descritta passi nelle buche successive o precedenti. Vogliamo quindi realizzare un modello per descrivere il sistema tramite le $\varphi(x,n)$. L'Hamiltoniana sarà pertanto:
\begin{equation}
H\varphi(x,n)=E_0\varphi(x,n)+\sum_{s}c_s\varphi(x,s)\;.
\end{equation}
Questa forma è dovuta al fatto che $\varphi$ non è autostato di tutta l'Hamiltoniana (solo della parte discreta). I termini aggiuntivi $c_s\varphi(x,s)$ rappresentano le probabilità di passare da una buca all'altra. Poiché le buche sono molto profonde, i coefficienti $c_s$ saranno sempre più piccoli se consideriamo buche sempre più lontane; questo ci permette di considerare solo le buche adiacenti e scrivere l'Hamiltoniana nella seguente forma:
\begin{equation}
H\varphi(x,n)=E_0\varphi(x,n)-\epsilon[\varphi(x,n+1)+\varphi(x,n-1)]\;. \label{ch5_nextneigh}
\end{equation}
In questa forma, la matrice dell'Hamiltoniana conterrà $E_0$ sulla diagonale principale e $-\epsilon$ sulle diagonali immediatamente superiore ed inferiore. Per risolvere l'equazione \eqref{ch5_nextneigh} prendiamo come ansatz:
\begin{equation}
\psi_k(x)=\sum_{n=-\infty}^{+\infty} e^{ikan}\varphi(x,n)\;.
\end{equation}
Sostituendo nell'equazione, troviamo:
\begin{align}
H\psi_k(x) &= \sum_{n=-\infty}^{+\infty} E_0e^{ikan}\varphi(x,n)-\epsilon\left[\sum_{n=-\infty}^{+\infty}e^{ikna}\varphi(x,n+1)+\sum_{n=-\infty}^{+\infty}e^{ikna}\varphi(x,n-1)\right] \notag \\
&= E_0\sum_{n=-\infty}^{+\infty}e^{ikna}\varphi(x,n)-\epsilon\left[e^{-ika}\sum_{n=-\infty}^{+\infty} e^{ik(n+1)a}\varphi(x,n+1)+e^{ika}\sum_{n=-\infty}^{+\infty}e^{ik(n-1)a}\varphi(x,n-1)\right] \notag \\
&= E_0\psi_k(x)-\epsilon[e^{-ika}+e^{ika}]\psi_k(x) = E_0\psi_k(x)-2\epsilon\cos(ka)\psi_k(x)  \notag \\
&= [E_0-2\epsilon\cos(ka)]\psi_k(x)\;.
\end{align}
Quindi le $\psi_k(x)$ così definite sono autofunzioni dell'Hamiltoniana troncata. Dato che $0\le ka\le 2\pi$, si ha $-1\le \cos(ka)\le 1$, quindi otteniamo uno spettro continuo di valori dell'energia compresi tra $E_0-2\epsilon$ e $E_0+2\epsilon$, cioè una banda di valori permessi dell'energia. Adesso sviluppiamo per $ka\ll 1$:
\begin{equation}
E(k)=E_0-\epsilon\cos(ka)\simeq E_0-\epsilon+\frac{1}{2}\epsilon k^2a^2=\frac{p^2}{2m}\;,
\end{equation}
da cui (a parte i termini costanti):
\begin{equation}
\frac{\epsilon a^2}{\hbar^2}=\frac{1}{m}\;.
\end{equation}
\section{Decadimenti}
Se consideriamo $N$ oggetti uguali soggetti a decadimento, possiamo scrivere una legge che lega il numero di oggetti e la variazione nel tempo del numero:
\begin{equation}
\dev{N}{t}=-\gamma N\;,
\end{equation}
dove $\gamma$ è la probabilità di decadere per unità di tempo e il suo inverso $1/\gamma$ rappresenta la \textit{vita media}. Gli stati stazionari di un sistema hanno vita media infinita, quindi è possibile realizzare stati a vita media molto grande se approssimiamo gli stati stazionari. Consideriamo un potenziale costituito da una buca e da una barriera. Gli stati legati con energia positiva della buca sono autostati del continuo, ma assomigliano molto a stati del discreto, Se la barriera fosse infinita, avremo degli stati stazionari; altrimenti dopo un po' la particella riesce ad oltrepassare la barriera. La probabilità di passare, fissato $k$, è come sappiamo $|T|^2$. Se $\tau$ è il periodo classico del moto, allora:
\begin{equation}
\gamma=\frac{1}{\tau}|T|^2\;.
\end{equation}
Questo modello schematizza per esempio i decadimenti $\alpha$ (buca di potenziale di larghezza $a\sim 10^{-13}$ cm, profondità $V_0\sim 20$ MeV, poi potenziale coulombiano).
\section{Calcolo approssimativo di $T$ per un potenziale piccolo}
Fissiamo $k$ in modo tale che $E=\hbar^2k^2/2m\gg V(x)$, e calcoliamo in queste condizioni $R,T$. L'equazione da risolvere è sempre la solita:
\begin{equation}
-\frac{\hbar^2}{2m}\psi''+V(x)\psi=\frac{\hbar^2k^2}{2m}\psi\;,
\end{equation}
con le condizioni al contorno:
\begin{equation}
\psi(x)=\begin{cases}
Te^{ikx}, \qquad x\to+\infty\;, \\
\\
e^{ikx}+Re^{-ikx}, \qquad x\to-\infty\;.
\end{cases}
\end{equation}
Ovviamente se $V\equiv 0$ si avrà $T=1,R=0$. Riscriviamo l'equazione in forma più comoda:
\begin{equation}
\psi''+k^2\psi=\frac{2m}{\hbar^2}V(x)\psi\;.
\end{equation}
Vogliamo sviluppare $\psi(x)=\psi_0(x)+\psi_1(x)+\psi_2(x)+\cdots$, dove nell'$n$-simo termine il potenziale compare con esponente $n$ (i.e. il termine zero non conterrà esplicitamente il potenziale). All'ordine zero:
\begin{equation}
\psi_0''+k^2\psi_0=0\;,
\end{equation}
avremo come soluzione quindi la funzione d'onda per la particella libera, cioè $\psi_0(x)=e^{ikx}$. La prima correzione perturbativa sarà data da:
\begin{equation*}
\psi_1''+k^2\psi_1=\frac{2m}{\hbar^2}V(x)\psi_0(x)\;.
\end{equation*}
Otteniamo quindi l'equazione differenziale non omogenea:
\begin{equation}
\psi_1''+k^2\psi_1=\frac{2m}{\hbar^2}V(x)e^{ikx}\;,
\end{equation}
che è della forma:
\begin{equation}
f''+k^2f=\rho(x)\;, \label{ch5_firstorder}
\end{equation}
con $\rho$ noto. Risolviamo quest'equazione trovando la \textit{funzione di Green} dell'equazione, cioè devo trovare una funzione $G(x,y)$ che risolve:
\begin{equation}
\left(\frac{\diff^2}{\diff{x}^2}+k^2\right)G(x,y)=\delta(x-y)\;. \label{ch5_greenfunction}
\end{equation}
Infatti, trovata la $G(x,y)$ che risolve \eqref{ch5_greenfunction}, presa:
$$
f=\int_{-\infty}^{+\infty} G(x,y)\rho(y)\;\diff{y}\;,
$$
questa risolve l'equazione \eqref{ch5_firstorder}. Il nostro ansatz per l'equazione \eqref{ch5_greenfunction} è:
\begin{equation}
G(x,y)=Ae^{ik|x-y|} \qquad \Longleftrightarrow\quad  G(x)=Ae^{ik|x|}\;.
\end{equation}
Verifichiamo che è soluzione:
\begin{align*}
G'(x) &= ikA\operatorname{sgn}(x)e^{ik|x|}\;, \\
G''(x) &= -k^2Ae^{ik|x|}+ikAe^{ik|x|}2\delta(x)\;,
\end{align*}
quindi:
\begin{equation}
G''+k^2G=-k^2Ae^{ik|x|}+2ikA\delta(x)e^{ik|x|}+k^2Ae^{ik|x|}=2ikA\delta(x)\;.
\end{equation}
Di conseguenza:
\begin{equation}
G(x)=\frac{1}{2ik}e^{ik|x|}\;,
\end{equation}
risolve l'equazione \eqref{ch5_greenfunction}. Da questa, otteniamo:
\begin{equation}
\psi_1(x)=\frac{1}{2ik}\int_{-\infty}^{+\infty} e^{ik|x-y|}\frac{2m}{\hbar^2}V(y)\;\diff{y}=\frac{m}{i\hbar^2k}\int_{-\infty}^{+\infty} e^{ik|x-y|}V(y)\;\diff{y}\;.
\end{equation}
Imponiamo le condizioni asintotiche. Per $x\to+\infty$, si ha:
\begin{equation}
\psi_1(x)\to \frac{m}{i\hbar^2k}\int_{-\infty}^{+\infty}e^{ik(x-y)}V(y)\;\diff{y}=\left(\frac{m}{i\hbar^2k}\int_{-\infty}^{+\infty}V(y)\;\diff{y}\right)e^{ikx}\;,
\end{equation}
da cui:
\begin{equation}
T=1+\frac{m}{i\hbar^2k}\int_{-\infty}^{+\infty}V(y)\;\diff{y}\;.
\end{equation}
Per $x\to-\infty$ si ha invece:
\begin{equation}
\psi_1(x)\to \frac{m}{i\hbar^2 k}\int_{-\infty}^{+\infty} e^{ik(y-x)}V(y)e^{iky}\;\diff{y}=\left[\frac{m}{i\hbar^2 k}\int_{-\infty}^{+\infty} e^{2iky}V(y)\;\diff{y}\right]e^{-ikx}\;,
\end{equation}
da cui:
\begin{equation}
R=\frac{m}{i\hbar^2 k}\int_{-\infty}^{+\infty} e^{2iky}V(y)\;\diff{y}\;.
\end{equation}
Deve comunque valere la relazione di unimodularità $|R|^2+|T|^2=1$. Dato che la correzione a $T$ è puramente immaginaria, abbiamo:
\begin{align}
|T|^2&=1+\mathcal{O}(V^2) \label{ch5_t2}\;, \\
|R|^2&=\left|\frac{m}{i\hbar^2 k}\int_{-\infty}^{+\infty} e^{2iky}V(y)\;\diff{y}\right|^2+\mathcal{O}(V^3)\notag \;.
\end{align}
Se invece scriviamo $|T|^2=1-|R|^2$, otteniamo un'espressione per $|T|^2$ corretta al secondo ordine in $V$, mentre \eqref{ch5_t2} lo era all'ordine zero. \\
\\
Un altro modo per risolvere l'equazione:
\begin{equation}
\left(\frac{\diff^2}{\diff{x}^2}+k^2\right)G(x)=\delta(x)\;,
\end{equation}
è quello di passare in trasformata di Fourier:
\begin{equation}
G(x)=\int_{-\infty}^{+\infty}e^{iqx}\stackrel{\sim}{G}(q)\frac{\diff{q}}{2\pi}\;.
\end{equation}
L'equazione diventa pertanto:
\begin{equation}
(-q^2+k^2)\tilde{G}(q)=1 \qquad \Longrightarrow \qquad \tilde{G}(q)=\frac{1}{k^2-q^2}\;,
\end{equation}
e quindi:
\begin{equation}
G(x)=-\int_{-\infty}^{+\infty} \frac{\diff{q}}{2\pi}\frac{1}{q^2-k^2}e^{iqx}\;.
\end{equation}
Possiamo risolvere questo integrale nel piano complesso. L'integrando ha due poli del prim'ordine in $q=\pm k$. Per $x>0$, prendiamo come cammino sull'asse reale da $-R$ a $R$ (passando con una piccola semicirconferenza sopra $q=-k$ e con un'altra sotto $q=k$ e chiudo la semicirconferenza con $q=Re^{i\theta}$, $0<\theta<\pi$ (cioè nel semipiano $\mathrm{Im} q>0$). In questo modo dentro la curva avremo solo il polo a $q=k$, che calcolato dà un contributo $e^{ikx}$. Per $x<0$, prendo lo stesso cammino sull'asse reale, ma lo chiudiamo con $q=Re^{i\theta}$, $\pi<\theta<2\pi$ (cioè nel semipiano $\mathrm{Im} q<0$), in modo da avere solamente il polo $q=-k$ interno alla curva e il suo residuo dà un contributo $e^{-ikx}$. Complessivamente, avremo una soluzione proporzionale a $e^{ik|x|}$, che è esattamente la forma trovata in precedenza. \\
Anziché deformare il cammino di integrazione sull'asse reale, possiamo fare la sostituzione:
\begin{equation}
q^2-k^2\Longrightarrow q^2-(k^2+i\epsilon)\;,
\end{equation}
quindi i poli adesso stanno a $q=\pm(k+i\epsilon)$. Abbiamo dunque spostato i poli. Alla fine del conto manderemo $\epsilon\to 0$ e riotterremo la stessa soluzione.
\chapter{Rappresentazioni}
\section{Assiomi della Meccanica Quantistica}
\begin{enumerate}
\item Ogni stato fisico può essere descritto come un raggio nello spazio di Hilbert a meno di una fase: $|\psi\ket\in\ham$;
\item ad ogni osservabile fisica $\mathcal{A}$ è associata un operatore autoaggiunto $A$ nello spazio di Hilbert;
\item il valor medio di un'osservabile $\mathcal{A}$ è dato da $\bra\psi|A|\psi\ket$. Se $A$ è autoaggiunto, gli autostati sono un set completo di $\ham$. Allora ogni $|\psi\ket\in\ham$ può essere scritta come:
\begin{equation}
|\psi\ket=\sum_{\alpha}c_{\alpha}|a_{\alpha}\ket\;,
\end{equation}
dove $|a_{\alpha}\ket$ sono gli autostati di $A$. In questa scrittura, $|c_{\alpha}|^2$ rappresenta la probabilità di trovare $|a_{\alpha}\ket$ dalla misura dell'osservabile;
\item esiste un operatore autoaggiunto $H$ (Hamiltoniano) che descrive l'evoluzione temporale di uno stato:
\begin{equation}
H|\psi\ket=i\hbar\frac{\partial}{\partial t}|\psi\ket\;;
\end{equation}
\item alle variabili $q,p$ sono associati gli operatori $Q,P$ nello spazio di Hilbert, e vale la regola di commutazione canonica:
\begin{equation}
[P,Q]=\frac{\hbar}{i}\;;
\end{equation}
\item la relazione di completezza è data da:
\begin{equation}
|\psi\ket=\sum_n c_n|n\ket+\int_{\alpha}\diff{\alpha}\; c_{\alpha}|\alpha\ket, \qquad \bra\alpha|\alpha'\ket=\delta(\alpha'-\alpha)\;,
\end{equation}
e la funzione d'onda $\psi(x)$ di uno stato $|\psi\ket$ è data da $\psi(x)=\bra x|\psi\ket$.
\end{enumerate}
\section{Rappresentazione nelle coordinate}
Gli autostati dell'operatore $Q$ sono determinati dall'equazione $Q|x\ket=x|x\ket$. Dato un generico stato $|\psi\ket$, la quantità $|\bra x|\psi\ket|^2\diff{x}$ deve essere la probabilità di trovare lo stato $|\psi\ket$ nell'autostato $|x\ket$.  Quindi, per come avevamo definito la funzione d'onda, $\psi(x)=\bra x|\psi\ket$. \\
\\
Nello spazio $\mathbb{L}^2$, era $Q|\psi\ket=x\psi(x)$. Anche nel caso astratto l'operatore $Q$ rappresenta una moltiplicazione per $x$:
\begin{equation}
\bra x|Q|\psi\ket=x\bra x|\psi\ket=x\psi(x)\;.
\end{equation}
Per l'impulso, in $\mathbb{L}^2$, $P|\psi\ket=\frac{\hbar}{i}\frac{\partial}{\partial x}\psi(x)$. In generale:
\begin{equation}
\bra \varphi|\psi\ket=\int_x \bra\psi|x\ket\bra x|\psi\ket\;\diff{x}=\int \varphi^*(x)\psi(x)\;\diff{x}\;,
\end{equation}
che identifica nel concreto lo spazio $\mathbb{L}^2$. \\
Per adesso sappiamo che dato $Q$ deve esistere un operatore $P$ tale che $[P,Q]=-i\hbar$. Quindi:
\begin{align}
\bra\varphi|[P,Q]|\psi\ket &= \bra\varphi|PQ|\psi\ket-\bra\varphi|QP|\psi\ket \notag \\
&= \bra P\varphi|x\ket\bra x|Q|\psi\ket- \bra Q\varphi|x\ket\bra x|P|\psi\ket \notag \\
&= \int_x (P\varphi)^*(x)x\psi(x)\;\diff{x}-\int_x x\varphi^*(x)(P\psi)(x)\;\diff{x}\;.
\end{align}
Una realizzazione esplicita in $\mathbb{L}^2$ è quella che prende il nome di \textit{rappresentazione nelle coordinate}:
\begin{align}
Q &\longrightarrow x \notag\;, \\
P &\longrightarrow \frac{\hbar}{i}\frac{\diff}{\diff{x}}\;.
\end{align}
\section{Rappresentazione negli impulsi}
Gli autostati dell'operatore $P$ sono determinati dall'equazione $P|p\ket=p|p\ket$. La funzione d'onda sarà data da:
\begin{equation}
\bra x|P|p\ket=\frac{\hbar}{i}\frac{\diff}{\diff{x}}\bra x|p\ket\stackrel{!}{=} p\bra x|p\ket \quad \Longrightarrow \quad \bra x|p\ket=e^{ipx/\hbar}\;.
\end{equation}
Pertanto uno stato $|\psi\ket$ può essere scritto in due modi:
$$
|\psi\ket=\int_x |x\ket\bra x|\psi\ket\;\diff{x}=\int_p |p\ket\bra p|\psi\ket\;\diff{p}\;,
$$
dove:
\begin{equation}
\bra p|\psi\ket=\int_x \bra p|x\ket\bra x|\psi\ket\;\diff{x}=\int_x e^{ipx/\hbar}\psi(x)\;\diff{x}\;.
\end{equation}
Concludiamo quindi che la funzione d'onda nelle $p$ è la trasformata di Fourier della funzione d'onda nelle $x$.
\section{Trasformazioni unitarie e operatori di Heisenberg}
Una trasformazione unitaria cambia la base su cui si sta lavorando ma lascia invariati i prodotti scalari. In pratica, $U$ è un operatore unitario se e solo se $\bra U\phi|U\psi\ket=\bra\phi|\psi\ket$, infatti:
$$
\bra\phi|\psi\ket=\bra U\phi|U\psi\ket=\bra\phi|\adj{U}U|\psi\ket\qquad \Longrightarrow \qquad\adj{U}U=U\adj{U}=1\;.
$$
Dato un operatore autoaggiunto $A$, possiamo sempre definire un sottogruppo di trasformazioni unitarie ad un parametro:
\begin{align}
U(t) &= e^{itA} \notag\;, \\
U^{-1}(t) &= e^{-itA} \notag\;, \\
\adj{U}(t) &= e^{-it\adj{A}}\;,
\end{align}
tale che:
\begin{align}
U(t)U(s) &= U(t+s) \notag\;, \\
e^{itA}e^{isA}&=e^{i(t+s)A}\;.
\end{align}
L'operatore $A$ è detto \textit{generatore infinitesimale} della trasformazione. Per $t=0$ definisco in astratto e normalizzando $U(0)=1$. Per $t\to 0$, sviluppando in serie (adesso non sappiamo cosa sia $A$):
\begin{align*}
U(t) &\simeq 1+itA+\mathcal{O}(t^2)\;, \\
\adj{U}(t) &\simeq 1-it\adj{A}+\mathcal{O}(t^2)\;, \\
U^{-1}(t) &\simeq 1-itA+\mathcal{O}(t^2)\;.
\end{align*}
Poiché $U$ è unitario, deve essere $U^{-1}=\adj{U}$, da cui si ottiene $A=\adj{A}$, cioè $A$ è appunto un operatore autoaggiunto. In sostanza, abbiamo dimostrato che dato un operatore autoaggiunto $A$, esso induce un sottogruppo di trasformazioni unitarie ad un parametro $U(t)=\exp(itA)$. Vale anche il seguente
\begin{thm}[Stone] $ \\ $
Dato un sottogruppo ad un parametro di trasformazioni unitarie $U(t)$ tali che $U(t)U(s)=U(t+s)$, allora esiste un operatore $A$ autoaggiunto, detto \textit{generatore infinitesimale}, tale che $U(t)=\exp(itA)$.
\end{thm}
Supponiamo adesso di avere un operatore unitario $S$ tale che:
$$
|\psi\ket \to |\psi'\ket=S|\psi\ket\;.
$$
$S$ induce una trasformazione sugli operatori. Sia $A$ un operatore qualunque e $|\varphi\ket=S|\psi\ket$, allora:
$$
|\varphi\ket\to SA|\psi\ket=SAS^{-1}S|\psi\ket\equiv A'|\psi\ket\;,
$$
cioè:
$$
A\to SAS^{-1}\equiv A'\;.
$$
Nell'equazione di \Sch:
\begin{equation}
i\hbar\frac{\partial}{\partial t}|\psi(t)\ket=H|\psi(t)\ket\;,
\end{equation}
la cui soluzione, se $H$ non dipende dal tempo, è:
\begin{equation}
|\psi(t)\ket=e^{-iHt/\hbar}|\psi(0)\ket \qquad\qquad\mbox{rappresentazione di \Sch}\;. \label{ch6_schropicture}
\end{equation}
L'evoluzione temporale è una trasformazione unitaria $U(t)\equiv \exp(-iHt/\hbar)$, il cui generatore infinitesimale è l'Hamiltoniana:
\begin{equation}
U(t)\simeq 1-i\frac{Ht}{\hbar} \qquad t\to 0\;.
\end{equation}
Definiamo una trasformazione unitaria $S(t)$ tale che annulli la dipendenza temporale. Scegliamo $S(t)\equiv \exp(iHt/\hbar)$, allora:
\begin{equation}
S(t)|\psi_S\ket \equiv |\psi_H\ket \qquad\qquad\mbox{rappresentazione di Heisenberg}\;, \label{ch6_heisenpicture}
\end{equation}
dove $|\psi_S\ket$ è lo stato in rappresentazione di \Sch definito dalla \eqref{ch6_schropicture}. La particolarità degli stati in rappresentazione di Heisenberg è che non evolvono nel tempo, mentre sono le osservabili ad evolvere. Un'osservabile in rappresentazione di \Sch\; diventa in rappresentazione di Heisenberg:
\begin{equation}
A_S\to A_H=e^{-iHt/\hbar}A_Se^{iHt/\hbar}\;.
\end{equation}
Scriviamo come evolve nel tempo $A_H$:
\begin{equation}
\dev{A_H(t)}{t}=\frac{i}{\hbar}HA_H+A_H\left(-\frac{i}{\hbar}H\right)=\frac{i}{\hbar}[H,A_H]\;.
\end{equation}
Gli operatori di Heisenberg mantengono le regole di commutazione canoniche:
\begin{equation}
[p_H,q_H]=[p_s,q_s]=\frac{\hbar}{i}\;.
\end{equation}
\subsection{Operatori di Heisenber per la particella libera}
Sappiamo come gli operatori di Heisenberg evolvono nel tempo:
\begin{align*}
\dot{q}_H &=\frac{i}{\hbar}[H,q_H]=\frac{i}{\hbar}\left[\frac{p_H^2}{2m},q_H\right]=\frac{p_H}{m}\;, \\
\dot{p}_H &= \frac{i}{\hbar}[H,p_H]=0\;.
\end{align*}
All'istante iniziale gli operatori di Heisenberg e di \Sch\;devono coincidere, quindi gli operatori di Heisenberg risolvono i problemi di Cauchy:
\begin{equation}
\begin{cases}
\dot{p}_H=0 \\
\\
p_H(0)=p \rightarrow \dfrac{\hbar}{i}\dfrac{\partial}{\partial x}
\end{cases} \qquad 
\begin{cases}
\dot{q}_H=\dfrac{p_H}{m} \\
\\
q_H(0)=q \rightarrow x
\end{cases}\;,
\end{equation}
con soluzione:
\begin{align}
p_H(t)&=p \notag\;, \\
q_H(t)&= \frac{p}{m}t+q\;.
\end{align}
\subsection{Operatori di Heisenberg per l'oscillatore armonico}
L'Hamiltoniana dell'oscillatore armonico è sempre
$$
H=\frac{p^2}{2m}+\frac{1}{2}m\omega^2 q^2\;.
$$
Allora i problemi di Cauchy che determinano gli operatori di Heisenberg sono stavolta:
\begin{equation}
\begin{cases}
\dot{p}_H=\dfrac{i}{\hbar}[H,p_H]=-m\omega^2q_H\;, \\
\\
p_H(0)=p\;,
\end{cases} \qquad
\begin{cases}
\dot{q}_H=\dfrac{i}{\hbar}[H,q_H]=\dfrac{p_H}{m}\;, \\
\\
q_H(0)=q\;,
\end{cases}
\end{equation}
che ammettono come soluzione:
\begin{align}
p_H(t) &= p\cos\omega t-m\omega q\sin\omega t \notag\;, \\
q_H(t) &= q\cos\omega t+\frac{p}{m\omega}\sin\omega t\;.
\end{align}
Consideriamo adesso uno stato $|\psi\ket$ che all'istante $t=0$ è autostato di un operatore $f$:
$$
f|\psi(0)\ket=f_0|\psi(0)\ket\;.
$$
Cosa possiamo dire su $|\psi(t)\ket$? Sappiamo che:
$$
|\psi(t)\ket=e^{-iHt/\hbar}|\psi(0)\ket\;,
$$
e supponiamo di conoscere:
$$
f_H(t)=e^{iHt/\hbar}fe^{-iHt/\hbar}\;.
$$
Allora $|\psi(t)\ket$ è autostato di $f_H(-t)$ con autovalore $f_0$. Infatti:
$$
f_H(-t)=e^{-iHt/\hbar}fe^{iHt/\hbar}\;,
$$
quindi:
$$
f_H(-t)|\psi(t)\ket=e^{-iHt/\hbar}fe^{iHt/\hbar}e^{-iHt/\hbar}|\psi(0)\ket=e^{-iHt/\hbar}f|\psi(0)\ket=f_0e^{-iHt/\hbar}|\psi(0)\ket=f_0|\psi(t)\ket\;.
$$
\textbf{Esempio}. Prendiamo una particella libera localizzata in $x_0$: $Q|x_0\ket=x_0|x_0\ket$. La funzione d'onda è:
$$
\psi(x)=\bra x|x_0\ket=\delta(x-x_0)\;.
$$
Come evolve $x_0$ nel tempo? Consideriamo:
\begin{align*}
q_H(t)&=q+\frac{p}{m}t\;, \\
q_H(-t)&= q-\frac{p}{m}t\;.
\end{align*}
Trovare gli autostati di $q_H(-t)$ in rappresentazione di \Sch\;è equivalente a trovare $|x(t)\ket=\exp(-iHt/\hbar)|x_0\ket$ (come abbiamo appena visto). Dobbiamo quindi risolvere l'equazione:
\begin{equation}
\left(x-\frac{t}{m}\frac{\hbar}{i}\frac{\partial}{\partial x}\right)G=x_0G\;,
\end{equation}
cioè:
\begin{equation}
\pdev{G}{x}=\frac{im}{\hbar t}(x-x_0)G \qquad \Longrightarrow \qquad G=A\exp\left(\frac{im}{2\hbar t}(x-x_0)^2\right)\equiv \bra x|e^{-iHt/\hbar}|x_0\ket\;.
\end{equation}
La costante di normalizzazione è:
\begin{equation}
A=\sqrt{\frac{m}{2\pi\hbar t}}\;.
\end{equation}
La funzione $G$ è chiamata \textit{propagatore} per la particella libera, e rappresenta l'ampiezza di probabilità di trovare la particella nel punto $x$ (partendo da $x_0$) dopo un tempo $t$. $G$ è anche la funzione di Green del problema di evoluzione temporale. Se risolviamo il problema per la funzione di Green:
\begin{equation}
\begin{cases}
i\hbar \dfrac{\partial}{\partial t}G(x,y,t)=HG(x,y,t)\;, \\
\\
G(x,y,0)=\delta(x-y)\;,
\end{cases}
\end{equation}
allora saremo in grado di risolvere qualunque problema di evoluzione temporale, infatti un qualunque stato $\psi$ si può scrivere come:
\begin{equation}
\psi(x,t)=\int\diff{y}\; G(x,y,t)\varphi(y) \qquad\qquad \psi(x,0)=\varphi(x)\;.
\end{equation}
Poiché solamente $G$ dipende dal tempo, per linearità $\psi$ risolve l'equazione di \Sch. Una nota importante è che l'esponente della funzione di Green:
\begin{equation}
\frac{i}{\hbar}\frac{m(x-x_0)^2}{2t}\;,
\end{equation}
(a parte la costante $i/\hbar$) è l'azione classica per passare da $x_0$ a $x$ nel tempo $t$, infatti:
\begin{equation}
S=\int_0^t L\;\diff{t}=\int_0^t \frac{1}{2}mv^2\;\diff{t}=\frac{1}{2}m\frac{(x-x_0)^2}{t^2}t=\frac{m(x-x_0)^2}{2t}\;,
\end{equation}
quindi l'esponente del propagatore è l'azione classica moltiplicata per una fase. \\
Osserviamo che la trasformazione:
\begin{align*}
U(t,t_0) &:=e^{-iH(t-t_0)/\hbar}\;, \\
|\psi(t)\ket &= U(t,t_0)|\psi(t_0)\ket\;,
\end{align*}
è ancora unitaria anche se l'Hamiltoniana dipende dal tempo, infatti se consideriamo:
\begin{equation}
i\hbar\pdev{|\varphi(t)\ket}{t}=H|\varphi(t)\ket\;,
\end{equation}
deve essere:
\begin{equation}
i\hbar\frac{\partial}{\partial t}\bra\varphi(t)|\psi(t)\ket=i\hbar[-\bra\varphi|H|\psi\ket+\bra\varphi|H|\psi\ket]=0\;,
\end{equation}
in quanto:
$$
\bra\varphi|H=-i\hbar\frac{\partial}{\partial t}\bra\varphi|\;,
$$
quindi:
$$
i\hbar\frac{\partial}{\partial t}U(t,t_0)=H\;,
$$
da cui:
\begin{equation}
|\psi(t)\ket=U(t,t_0)|\psi(t_0)\ket, \qquad\qquad U(t_0,t_0)=1\;.
\end{equation}
Scriviamo l'equazione per $U$:
\begin{align}
i\hbar\frac{\partial}{\partial t}|\psi(t)\ket&=\left(i\hbar\pdev{U}{t}\right)|\psi(t_0)\ket\stackrel{!}{=}HU|\psi(t_0)\ket \notag \\
i\hbar\pdev{U}{t} U^{-1}U|\psi(t_0)\ket &= HU|\psi(t_0)\ket \notag \\
i\hbar\pdev{U}{t}U^{-1}&= H \notag \\
i\hbar\pdev{U}{t}&=HU\;.
\end{align}
\section{Operatore impulso}
Vogliamo adesso definire l'impulso allo stesso modo di $H$, cioè come generatore infinitesimale delle traslazioni in questo caso spaziali e verificare che esso coincida con quello canonico. Partiamo dall'operatore posizione $Q$ e dai suoi autostati, definiti da:
\begin{equation}
Q|x\ket=x|x\ket\;.
\end{equation}
Definiamo l'operatore di traslazione:
\begin{equation}
T(a)|x\ket\equiv|x+a\ket\;.
\end{equation}
Verifichiamo che l'operatore è unitario. Consideriamo due autostati di $Q$ (sono un set completo, quindi posso estendere a tutti i vettori dello spazio):
\begin{equation}
\bra T_a(x)|T_a(y)\ket=\bra x+a|y+a\ket=\delta(y+a-x-a)=\delta(y-x)=\bra x|y\ket\;.
\end{equation}
Quindi $T$ è effettivamente unitario e ad un parametro. Per il teorema di Stone, esisterà un generatore infinitesimale di tale sottogruppo, che denotiamo $P$:
\begin{equation}
T(a)=e^{-iPa/\hbar}\simeq 1-\frac{ia}{\hbar}P, \qquad\qquad T(a)T(b)=T(a+b)\;.
\end{equation}
Dimostriamo che $P$ è l'impulso canonico $\hat{P}$. Assunta la regola di commutazione canonica:
\begin{equation}
[\hat{P},\hat{Q}]=\frac{\hbar}{i}\;,
\end{equation}
dobbiamo dimostrare che $\exp(-i\hat{P}a/\hbar)|x\ket=|x+a\ket$. Consideriamo:
\begin{equation}
e^{-i\hat{P}a/\hbar}Qe^{i\hat{P}a/\hbar}\;,
\end{equation}
usando l'identità:
$$
[B,A]=c\mathbb{I} \qquad \Longrightarrow\qquad e^BAe^{-B}=A+[B,A]\;.
$$	
Troviamo:
\begin{align}
e^{i\hat{P}a/\hbar}Qe^{-i\hat{P}a/\hbar}=Q+\frac{ia}{\hbar}[\hat{P},Q]=Q+a \notag \\
Qe^{-i\hat{P}a/\hbar}=e^{-i\hat{P}a/\hbar}Q+ae^{-i\hat{P}a/\hbar}\;.
\end{align}
Allora:
\begin{align}
Qe^{-i\hat{P}a/\hbar}|x\ket &= e^{-i\hat{P}a/\hbar}Q|x\ket+ae^{-i\hat{P}a/\hbar}|x\ket = \notag \\
&= e^{-i\hat{P}a/\hbar}x|x\ket+ae^{-i\hat{P}a/\hbar}|x\ket= \notag \\
&= (x+a)e^{-i\hat{P}a/\hbar}|x\ket\;.
\end{align}
Concludiamo che $\exp(-i\hat{P}a/\hbar)|x\ket$ è autostato di $Q$ con autovalore $x+a$, cioè $\exp(-i\hat{P}a/\hbar)|x\ket=|x+a\ket$. Da ciò segue che $P=\hat{P}$, quindi l'impulso canonico è il generatore infinitesimale delle traslazioni spaziali. \\
In rappresentazione di \Sch, $\psi(x)=\bra x|\psi\ket$, $T(a)=e^{-iPa/\hbar}$, $T(a)|x\ket=|x+a\ket$, $T^{-1}(a)|x\ket=|x-a\ket$. Inoltre:
$$
\bra x|T(a)|\psi\ket=\bra \adj{T}(a)x|\psi\ket=\bra T^{-1}(a)x|\psi\ket=\bra x-a|\psi\ket=\psi(x-a)\;.
$$
Considero una trasformazione infinitesima:
\begin{equation}
\bra x|1-\frac{ia}{\hbar}P|\psi\ket\simeq \psi(x)-\frac{ia}{\hbar}\bra x|P\psi\ket\;.
\end{equation}
Ma:
\begin{equation}
\bra x|1-\frac{ia}{\hbar}P|\psi\ket=\psi(x-a)\simeq \psi(x)-a\frac{\partial}{\partial x}\psi(x)\;,
\end{equation}
da cui:
\begin{equation}
-\frac{ia}{\hbar}\bra x|P\psi\ket=-a\frac{\partial}{\partial x}\psi(x) \qquad \Longrightarrow \qquad \bra x|P\psi\ket=\frac{\hbar}{i}\pdev{\psi(x)}{x}\;,
\end{equation}
che implica:
\begin{equation}
P=\frac{\hbar}{i}\frac{\partial}{\partial x}\;.
\end{equation}
\section{Definizione degli operatori $P$ e $Q$ tramite operatori unitari}
Consideriamo adesso gli operatori:
\begin{align}
T(a)&=e^{iPa/\hbar}\;, \notag \\
V(b)&=e^{iQb/\hbar}\;.
\end{align}
Sono entrambi operatori unitari che inducono un sottogruppo di trasformazioni ad un parametro. Interpretiamo quindi $P$ e $Q$ come generatori infinitesimi delle traslazioni rispettivamente dello spazio e dell'impulso. Ricordando la relazione:
\begin{equation}
e^Xe^Y=e^{X+Y+\frac{1}{2}[X,Y]}\;,
\end{equation}
possiamo scrivere:
\begin{equation}
T(a)V(b)=e^{iPa/\hbar}e^{iQb/\hbar}=\exp\left[\frac{iPa}{\hbar}+\frac{iQb}{\hbar}+\frac{1}{2}\frac{iab}{\hbar}\right]\;,
\end{equation}
in quanto:
\begin{equation}
\left[\frac{iPa}{\hbar},\frac{iQb}{\hbar}\right]=-\frac{ab}{\hbar^2}[P,Q]=\frac{iab}{\hbar}\;,
\end{equation}
mentre:
\begin{equation}
V(b)T(a)=\exp\left[\frac{iPa}{\hbar}+\frac{iQb}{\hbar}-\frac{1}{2}\frac{iab}{\hbar}\right]\;,
\end{equation}
da cui otteniamo la relazione:
\begin{equation}
T(a)V(b)=V(b)T(a)e^{iab/\hbar}\;,
\end{equation}
nota come \textit{regola di commutazione di Weyl}.
\begin{thm}[von Neumann] Date due famiglie di operatori unitari ad un parametro, $T(a),V(b)$ che soddisfano alle regole di commutazione di Weyl su uno spazio di Hilbert separabile $\ham$, allora esistono sottospazi chiusi $\ham_k$ tali che:
\begin{enumerate}
\item $\ham=\bigoplus_{k=1}^N \ham_k$;
\item $T(a):\ham_k\to\ham_k$ e $V(b):\ham_k\to\ham_k$;
\item per ogni $k$ esiste un operatore unitario $U_k:\ham_k\to\mathbb{L}^2(\mathbb{R})$ tale che $U_kT(a)U_k^{-1}$ agisca come una traslazione e $U_kV(b)U_k^{-1}$ agisca come una moltiplicazione per $e^{ibx/\hbar}$.
\end{enumerate}
\end{thm}
Nel caso di una particella che si muove su un cerchio, il teorema di von Neumann non è più valido. Interpretiamo il cerchio come un segmento di estremi $[0,L]$ in cui identifichiamo gli estremi ($L\equiv 0$). Gli autostati dell'impulso $P\psi=\lambda\psi$ sono dati da:
\begin{align}
\psi &= \frac{1}{\sqrt{L}}e^{i2\pi nx/\hbar L}\;, \notag \\
\lambda_n &= \frac{2\pi n}{L}\;.
\end{align}
Questi appartengono a $\mathbb{L}^2([0,L])$, quindi possiamo definire senza problemi la trasformazione $T(a)$. I problemi nascono per $Q$: non è possibile in questo caso definire $V(b)$ con continuità. Al più, possiamo definire per valori discreti di $b$, ovvero multipli di $2\pi\hbar/L$, la trasformazione:
\begin{equation}
W\equiv V\left(\frac{2\pi\hbar}{L}\right)\;.
\end{equation}
Sia $|n\ket$ l'n-esimo autostato dell'impulso. Allora valgono le seguenti relazioni:
\begin{align}
P|n\ket&=\frac{2\pi\hbar}{L}n|n\ket \notag\;, \\
W|n\ket &= |n+1\ket\;,
\end{align}
da cui ricaviamo le relazioni:
\begin{align}
PW|n\ket&=P|n+1\ket=\frac{2\pi\hbar}{L}(n+1)|n+1\ket \notag\;, \\
WP|n\ket&=\frac{2\pi\hbar}{L}nW|n\ket=\frac{2\pi\hbar}{L}n|n+1\ket\;,
\end{align}
sottraendo membro a membro:
\begin{equation}
(PW-WP)|n\ket=\frac{2\pi\hbar}{L}|n+1\ket=W|n\ket\;.
\end{equation}
Quindi possiamo scrivere la regola di commutazione:
\begin{equation}
[P,W]=\frac{2\pi\hbar}{L}W\;.
\end{equation}
Allora:
\begin{equation}
T(a)W=e^{2\pi ia/L}WT(a)\;.
\end{equation}
Nel caso della particella che si muove su un cerchio, sostituiamo l'algebra di Weyl con l'equazione precedente e la conseguente regola di commutazione. Verifichiamo adesso che esistono infinite rappresentazioni. Prendiamo:
\begin{equation}
f_n(x)=\frac{1}{\sqrt{L}}\exp\left(i\frac{2\pi n}{L}x+i\theta\frac{x}{L}\right)\;.
\end{equation}
Si ha che $f_n(x)$ è ancora autostato di $P$ con autovalore $\frac{2\pi n+\theta}{L}$. Dato che le trasformazioni unitarie lasciano inalterato lo spettro, questi autostati non potranno mai essere unitariamente equivalenti a quelli originali, quindi concludiamo che $T(a)$ ha infinite rappresentazioni non unitariamente equivalenti.
\chapter{Stati misti e matrice di densità}
\section{Prodotti tensoriali}
\begin{enumerate}
\item Il valor medio di un operatore $A$ su uno stato $|\psi\ket$ è definito da $\bra\psi|A|\psi\ket$. Questa definizione contiene anche la probabilità di ottenere un autovalore di $A$. Se $|a\ket$ è un autostato di $A$ e considero il suo proiettore $\Pi_a=|a\ket\bra a|$ allora:
\begin{equation}
\bra\psi|\Pi_a|\psi\ket=\bra\psi|a\ket\bra a|\psi\ket=|\bra a|\psi\ket|^2\;;
\end{equation}
\item l'impulso $P$ è definito da:
\begin{equation}
\bra x|P\psi\ket=\frac{\hbar}{i}\frac{\partial}{\partial x}\bra x|\psi\ket\;.
\end{equation}
\end{enumerate}
Siano $V_1,V_2$ due spazi vettoriali e siano $\{e_i\}$ e $\{f_i\}$ basi rispettivamente di $V_1$ e $V_2$. Si definisce \textit{prodotto tensoriale}:
\begin{equation}
\mathcal{T}:=V_1\otimes V_2\;.
\end{equation}
Se $V_1=\{\sum_i a_ie_i\}$, $V_2=\{\sum_i b_if_i\}$ allora:
\begin{equation}
\mathcal{T}=\left\{ \sum_{i,j} c_{ij}e_i\otimes f_j\right\}\;.
\end{equation}
Si ha $\dim\mathcal{T}=\dim V_1\cdot\dim V_2$. Ad esempio, si ha che $\mathbb{L}^2(\mathbb{R}^2)=\mathbb{L}^2(\mathbb{R})\otimes \mathbb{L}^2(\mathbb{R})$, quindi le funzioni di due variabili $f(x,y)$ possono essere considerate come funzioni di $y$ a $x$ fisso o viceversa, e sviluppate in entrambe le basi:
\begin{equation}
f(x,y)=\sum c_j\varphi_j(y)=\sum s_{ij}\stackrel{\sim}{\varphi}_i(x)\varphi_j(y)\;.
\end{equation}
Se abbiamo il prodotto tensoriale $|e_i\ket\otimes |f_j\ket$ (spesso lo indicheremo semplicemente $|e_i\ket|f_j\ket$) e un operatore $A$ che agisce solo su $|e_1\ket$ lasciando invariati gli $|f_j\ket$, possiamo scrivere:
\begin{equation}
A\left(|e_i\ket\otimes|f_j\ket\right)=A_1|e_i\ket\otimes|f_j\ket\;,
\end{equation}
o alternativamente posso scrivere $A=A_1\otimes\mathbb{I}$.
\section{Matrice di densità}
Gli stati sono essenzialmente caratterizzati da alcuni numeri quantici: $|\psi\ket=|E,a\ket$. Gli stati ad energia fissa si distribuiscono secondo la statistica di Boltzmann:
\begin{equation}
\frac{e^{-E/kT}}{Z}\;,
\end{equation}
dove $Z$ è il fattore di normalizzazione. Secondo questa statistica, il valor medio di un operatore $A$ è dato da:
\begin{equation}
\sum_{E,a} \frac{e^{-E/kT}}{Z}\bra Ea|A|Ea\ket\;. \label{ch7_valormediostatistico}
\end{equation}
Riprendendo la solita definizione di valor medio di un operatore $\bra \psi|A|\psi\ket$, sappiamo che $A_{ij}\equiv \bra i|A|j\ket$ e $\tr\, A=\sum_i A_{ii}=\sum_i \bra i|A|i\ket$. Dunque:
\begin{align}
\bra \psi|A|\psi\ket &= \bra\psi|i\ket\bra i|A|j\ket\bra j|\psi\ket = \bra j|\psi\ket\bra \psi|i\ket A_{ij} = \left(\Pi_{\psi}\right)_{ji}A_{ij} = \tr (A\Pi_{\psi})\;.
\end{align}
Vogliamo adesso scrivere il valor medio statistico dato dalla \eqref{ch7_valormediostatistico} come traccia di una matrice. Introduciamo la \textit{matrice di densità}:
\begin{equation}
\rho\equiv \frac{1}{Z}\sum_{E,a}e^{-E/kT}|Ea\ket\bra Ea|\;.
\end{equation}
Allora si ha:
\begin{equation}
\sum_{E,a} \frac{e^{-E/kT}}{Z}\bra Ea|A|Ea\ket=\tr (\rho A)\;.
\end{equation}
In generale, ogni sistema è accoppiato con l'esterno, quindi $\psi\equiv \psi(x,y)$, dove $x$ sono le coordinate del sistema che stiamo studiando e $y$ quelle del resto. Se $|i\ket$ è una base del sistema che stiamo studiando e $|\alpha\ket$ è una base del resto, possiamo scrivere gli stati $|\psi\ket$ come prodotto tensoriale:
\begin{equation}
|\psi\ket=\sum C_{i\alpha}|i\ket|\alpha\ket\;.
\end{equation}
Sarebbe ottimale avere qualcosa indipendente dalla base $|\alpha\ket$. Scriviamo:
\begin{equation}
\bra \psi|A|\psi\ket=C_{j\beta}^*\bra\beta|\bra j|AC_{i\alpha}|i\ket|\alpha\ket\;,
\end{equation}
con $A$ che agisce solo su $|i\ket$. Dunque:
\begin{equation}
\bra\psi|A|\psi\ket =C_{i\alpha}C_{j\alpha}^*\bra j|A|i\ket\;.
\end{equation}
Pertanto:
\begin{equation}
\rho_{ij}\equiv C_{i\alpha}C_{j\alpha}^*=(C\adj{C})_{ij}\;,
\end{equation}
è la matrice di densità. Il valor medio di $A$ su uno stato globale è dato quindi da:
\begin{equation}
\rho_{ji}A_{ij}=\tr(\rho A)\;.
\end{equation}
Gli stati descrivibili tramite la matrice $\rho$ sono detti \textit{stati misti}. Se $\rho$ è un singolo proiettore su uno stato, ritroviamo il caso precedentemente trattato degli \textit{stati puri}, che sono un caso particolare. \\
\\
Dalla definizione della matrice di densità, ricaviamo immediatamente che $\rho$ è una matrice hermitiana e definita positiva sullo spazio generato da $|i\ket$. Sia $|\psi\ket$ uno stato normalizzato. Allora esso si può scrivere:
\begin{equation}
|\psi\ket=C_{i\alpha}|i\ket|\alpha\ket\;,
\end{equation}
dall'ipotesi di normalizzazione segue che:
\begin{equation}
\sum |C_{i\alpha}|^2=\sum C_{i\alpha}C_{j\alpha}^*=\tr\, \rho =1\;.
\end{equation}
Poiché la traccia è un invariante per similitudine, concludiamo che la traccia della matrice di densità è sempre uguale a 1. Si dice che $\rho$ è un operatore di \textit{classe traccia}. \\
Poiché $\rho$ è hermitiana sullo spazio $|i\ket$, allora sarà diagonalizzabile:
\begin{align}
\rho &= \sum_s w_s|s\ket\bra s|, \qquad \qquad w_s>0\quad \forall s \notag \;,\\
&\sum_s w_s=\tr\, \rho = 1\;.
\end{align}
Evidentemente, abbiamo uno stato puro quando un solo $w_s$ è uguale a 1 e tutti gli altri sono nulli. In generale vale la diseguaglianza:
\begin{equation}
\tr\, \rho^2=\sum_s w_s^2\le \sum_s w_s=\tr\,\rho=1 \qquad \Longrightarrow \qquad \tr\,\rho^2\le \tr\,\rho\;.
\end{equation}
Vale l'uguaglianza solo per gli stati puri. Concludiamo quindi che \textbf{uno stato è puro se e solo se la sua matrice di densità è un singolo proiettore}. \\
\\
\textbf{Esempio}. Consideriamo un pione $\pi^0$ che decade in due fotoni collineari e di verso opposto. Assumiamo come stato complessivo:
\begin{equation}
|\Psi\ket=\frac{1}{\sqrt{2}}(|x\ket|y\ket+|y\ket|x\ket), \qquad |x\ket=\left(\begin{matrix}
1 \\
0
\end{matrix}\right), |y\ket=\left(\begin{matrix}
0 \\
1
\end{matrix}\right)\;,
\end{equation}
dove in parentesi abbiamo due prodotti tensoriali: il primo ket si riferisce al fotone diretto verso sinistra, il secondo a quello diretto verso destra. Supponiamo di essere in grado di rivelare solo il fotone diretto a destra. Scriviamo la matrice di densità e il suo quadrato:
\begin{align}
C&=\frac{1}{\sqrt{2}}\left(\begin{matrix}
0 & 1 \\
1 & 0
\end{matrix}\right)\;, \notag \\
C\adj{C}=\rho&=\frac{1}{2}\left(\begin{matrix}
1 & 0 \\
0 & 1
\end{matrix}\right)\;, \qquad \tr\,\rho=1 \notag \\
\rho^2&=\frac{1}{4}\left(\begin{matrix}
1 & 0 \\
0 & 1
\end{matrix}\right)\;, \qquad \tr\,\rho^2\ne \tr\,\rho\;.
\end{align}
Quindi il fotone di destra ha $1/2$ di probabilità di essere polarizzato lungo $x$ o lungo $y$. Questo costituisce un esempio di luce non polarizzata. \\
\\
Il modo più generale di scrivere la matrice di densità è:
\begin{equation}
\rho=\frac{1}{2}\left(\mathbb{I}+\vec{\xi}\cdot\vec{\sigma}\right)=\frac{1}{2}\left(\begin{matrix}
1+\xi_3 & \xi_1-i\xi_2 \\
\xi_1+i\xi_2 & 1-\xi_3
\end{matrix}\right)\;,
\end{equation}
dove $\vec{\sigma}=(\sigma_1,\sigma_2,\sigma_3)$ sono le matrici di Pauli e $\vec{\xi}=(\xi_1,\xi_2,\xi_3)$ sono detti \textit{parametri di Stokes}. Si ha inoltre:
\begin{equation}
\rho^2=\frac{1}{4}(1+\vec{\xi}\cdot\vec{\sigma})(1+\vec{\xi}\cdot\vec{\sigma})=\frac{1}{4}(1+2\vec{\xi}\cdot\vec{\sigma}+(\vec{\xi}\cdot\vec{\sigma})(\vec{\xi}\cdot\vec{\sigma})=\frac{1}{4}(1+\vec{\xi^2})\;,
\end{equation}
da cui:
\begin{equation}
\tr\,\rho^2=\frac{1}{2}(1+\vec{\xi^2})\;.
\end{equation}
Dato che $\tr\,\rho^2\le\tr\,\rho$ segue che $\max|\vec{\xi}|^2\le 1$.
\section{Matrice di densità termica}
Consideriamo una particella libera. Possiamo scrivere le relazioni:
\begin{equation}
\rho=e^{-\beta H}\;, \qquad \qquad -\pdev{\rho}{\beta}=H\rho\;. \label{ch7_matricetermica}
\end{equation}
Essendo inoltre:
\begin{align*}
\bra x|\rho|y\ket &= \rho(x,y)\qquad\mbox{(in generale, non è nota)}\;, \\
\bra x|1|y\ket &= \delta(x-y)\;.
\end{align*}
Possiamo riscrivere la seconda equazione di \eqref{ch7_matricetermica} come:
\begin{equation}
-\frac{\partial}{\partial\beta}\rho(x,y)=\bra x|H\rho|y\ket\;.
\end{equation}
Per la particella libera, $H=p^2/2m$, quindi:
\begin{equation}
-\frac{\partial}{\partial\beta}\rho(x,y)=\bra x|\frac{p^2}{2m}\rho|y\ket=-\frac{\hbar^2}{2m}\frac{\partial^2}{\partial x^2}\rho(x,y)\;.
\end{equation}
La $\rho$ termica soddisfa pertanto l'equazione:
\begin{align}
-\frac{\hbar^2}{2m}\pdev[2]{\rho}{x} &= -\pdev{\rho}{\beta}\;, \notag \\
\rho(x,y,\beta=0)&=\delta(x-y)\;. \label{ch7_rhoeq}
\end{align}
Se $\beta$ fosse puramente immaginario, la \eqref{ch7_rhoeq} assumerebbe la forma di un'equazione di \Sch. Si tratta di un'equazione analoga a quella che avevamo scritto per la funzione di Green:
\begin{equation}
i\hbar\pdev{G}{t}=-\frac{\hbar^2}{2m}\pdev[2]{G}{x}\;,
\end{equation}
la cui soluzione era:
\begin{equation}
G=\sqrt{\frac{m}{2\pi i\hbar t}}\exp\left[\frac{im}{\hbar}\frac{(x-y)^2}{2t}\right]\;.
\end{equation}
Quindi ricaviamo $\rho$ (non normalizzata) con la sostituzione $t\to -i\hbar\beta$:
\begin{equation}
\rho=\sqrt{\frac{m}{2\pi\hbar^2\beta}}\exp\left[-\frac{m(x-y)^2}{2\hbar^2\beta}\right]\;.
\end{equation}
Calcoliamone adesso la traccia:
\begin{equation}
\tr\,\rho=\int_0^L \rho(x,x)\;\diff{x}=\sqrt{\frac{m}{2\pi\hbar^2\beta}}L=e^{-\beta F}\;.
\end{equation}
dove $F$ è l'energia libera di Gibbs.
\chapter{Momento angolare}
\section{Introduzione}
Sappiamo dalla Meccanica Classica che, nel caso di un potenziale centrale, l'Hamiltoniana ha la forma:
\begin{equation}
H=\frac{\mathbf{p}^2}{2m}+V(\mathbf{r})\;.
\end{equation}
In questo caso si conserva il momento angolare totale del sistema. Nel caso invece di due particelle che interagiscono fra loro, l'Hamiltoniana è:
\begin{equation}
H=\frac{\mathbf{p}_1^2}{2m_1}+\frac{\mathbf{p}_2^2}{2m_2}+V(|\mathbf{r}_1-\mathbf{r}_2|)\;.
\end{equation}
In questa situazione si conservano l'impulso totale e il momento angolare del centro di massa. \\
Come traduciamo queste leggi di conservazione nel linguaggio della Meccanica Quantistica? Noi finora sappiamo che:
\begin{enumerate}
\item se $A$ è un'osservabile, allora:
\begin{equation}
\dev{A}{t}=\pdev{A}{t}+\frac{1}{\hbar}[H,A]\;;
\end{equation}
\item dato l'operatore $H$ (Hamiltoniana) hermitiana, esiste un operatore unitario $U(t,0)=\exp(-iHt/\hbar)$ tale che:
\begin{equation}
\dot{U}(t)=-\frac{1}{\hbar}HU \qquad \Longleftrightarrow \qquad \dot{U}U^{-1}=-\frac{1}{\hbar}H\;;
\end{equation}
\item l'operatore unitario delle traslazioni spaziali è $\exp(iPa/\hbar)$, dove $P$ è l'operatore impulso.
\end{enumerate}
Importante ai nostri fini è il seguente:
\begin{thm}[Wigner] $ \\ $
Siano $|\psi\ket, |\phi\ket$ due stati e $|\psi'\ket,|\phi'\ket$ le loro immagini attraverso una generica trasformazione $U$. Allora si ha $|\bra\psi|\phi\ket|^2=|\bra\psi'|\phi'\ket|^2$ solo in due casi:
\begin{enumerate}
\item $U$ è un operatore unitario ($U\adj{U}=1$), tale che:
\begin{equation}
\bra U\psi|U\phi\ket=\bra\psi|\phi\ket\;;
\end{equation}
\item $U$ è antiunitario, cioè tale che:
\begin{equation}
\bra U\psi|U\phi\ket=\bra\psi|\phi\ket^*\;.
\end{equation}
\end{enumerate}
\end{thm}
Una conseguenza molto importante di questo teorema è che la trasformazione che lega $|\psi\ket,|\phi\ket$ a $|\psi'\ket,|\phi'\ket$ è sicuramente lineare (se $U$ è unitario) oppure antilineare (se $U$ è antilineare).
\section{Simmetrie}
\begin{dfn} Sia $S(t)$ una trasformazione unitaria. Si dice che $S$ è una simmetria se commuta con l'Hamiltoniana, cioè se:
\begin{equation}
S(t)U(t,t_0)=U(t,t_0)S(t), \qquad \forall t,t_0 \qquad U(t,t_0)=e^{-iH(t-t_0)/\hbar}\;.
\end{equation}
\end{dfn}
Fissiamo $t_0=0$:
\begin{equation}
U^{-1}SU=S(0)\;,
\end{equation}
derivando rispetto al tempo si ottiene:
\begin{equation}
\dot{U}^{-1}SU+U^{-1}\pdev{S}{t}U+U^{-1}S\dot{U}=0\;.
\end{equation}
Moltiplicando a sinistra per $U$ e a destra per $U^{-1}$ abbiamo:
\begin{equation}
U\dot{U}^{-1}S+\pdev{S}{t}+S\dot{U}U^{-1}=0\;.
\end{equation}
Ricordando le relazioni:
\begin{align}
\dot{U}&= -\frac{i}{\hbar}HU \notag\;, \\
\dot{U}U^{-1}&= -\frac{i}{\hbar}H \notag\;, \\
UU^{-1} = 1 \quad \Longrightarrow \quad \dot{U}U^{-1}+U\dot{U}^{-1}&=0\quad \Longrightarrow\quad U\dot{U}^{-1}=-\dot{U}U^{-1}\;.
\end{align}
Si ottiene:
\begin{equation}
\frac{i}{\hbar}HS-\frac{i}{\hbar}SH+\pdev{S}{t}=\pdev{S}{t}+\frac{i}{\hbar}[H,S]\equiv\dev{S}{t}=0\;.
\end{equation}
Quindi in generale $\diff{S}/\diff{t}=0$. Se $S$ non dipende esplicitamente dal tempo, allora commuta anche con l'Hamiltoniana (cfr. Teorema di Noether). \\
Per un sistema di $N$ particelle descritte dalle coordinate $\mathbf{q}_1,\ldots,\mathbf{q}_N$, effettuando una traslazione di tutte le coordinate otteniamo $\mathbf{q}_1+\mathbf{a},\ldots,\mathbf{q}_N+\mathbf{a}$. La trasformazione unitaria che abbiamo applicato è:
\begin{equation}
S=\exp\left[\frac{i}{\hbar}\left(\mathbf{p}_1\cdot\mathbf{a}+\cdots+\mathbf{p}_N\cdot\mathbf{a}\right)\right]\;,
\end{equation}
il cui generatore infinitesimale è l'impulso del centro di massa:
\begin{equation}
\mathbf{P}_{\mathrm{cm}}=\sum_{i=1}^N \mathbf{p}_i\;.
\end{equation}
Se il sistema è invariante sotto traslazioni $\diff{\mathbf{P}_{\mathrm{cm}}}/\diff{t}=0$. Dato che $\partial\mathbf{P}_{\mathrm{cm}}/\partial t=0$, si ha anche $[\mathbf{P}_{\mathrm{cm}},H]=0$. La variabile canonicamente coniugata all'impulso del centro di massa è la coordinata del centro di massa:
\begin{equation}
\mathbf{Q}_{\mathrm{cm}}=\frac{m_1\mathbf{q}_1+\cdots+m_N\mathbf{q}_N}{m_1+\cdots+m_N}\;.
\end{equation}
Dal fatto che $\mathbf{p}_{\alpha}$ e $\mathbf{q}_{\alpha}$ sono canonicamente coniugate, i.e. $[p_{\alpha,i},q_{\beta,j}]=-i\hbar\delta_{\alpha\beta}\delta_{ij}$, segue che:
\begin{equation}
[\mathbf{P}_{\mathrm{cm}},\mathbf{Q}_{\mathrm{cm}}]=-i\hbar\;,
\end{equation}
cioè $\mathbf{P}_{\mathrm{cm}}$ e $\mathbf{Q}_{\mathrm{cm}}$ sono canonicamente coniugate. \\
In generale, $H\equiv H(\mathbf{P}_{\mathrm{cm}},\mathbf{Q}_{\mathrm{cm}},\tilde{\mathbf{p}},\tilde{\mathbf{q}},\alpha)$, ma, dato che $[H,\mathbf{P}_{\mathrm{cm}}]=0$, si ha $\partial H/\partial \mathbf{Q}_{\mathrm{cm}}=0$ e quindi $H\equiv H(\mathbf{P}_{\mathrm{cm}},\tilde{\mathbf{p}},\tilde{\mathbf{q}},\alpha)$.
\section{Trasformazioni di Galileo}
Una trasformazione infinitesima di Galileo è della forma:
\begin{equation}
\begin{cases}
\mathbf{p}\to \mathbf{p}+M\mathbf{v}\;, \\
\\
\mathbf{q}\to \mathbf{q}+\mathbf{v}t\;,
\end{cases}
\end{equation}
dove $\mathbf{v}$ è la velocità del boost. Sappiamo che $A\to UAU^{-1}$, con $U=\exp(iX)\simeq 1+iX$, $U^{-1}\simeq 1-iX$, allora:
\begin{equation}
UAU^{-1}=A+i[X,A]+\mathcal{O}(X^2)\;,
\end{equation}
quindi la correzione $\delta A$ del prim'ordine è $[X,A]$:
\begin{equation}
\begin{cases}
\delta\mathbf{p}=M\mathbf{v}\;, \\
\\
\delta\mathbf{q}=\mathbf{v}t\;.
\end{cases}
\end{equation}
Devo trovare un operatore autoaggiunto $G$ (il generatore infinitesimale) tale che per ogni $i=1,\ldots,N$:
\begin{equation}
\begin{cases}
[iG,\mathbf{p}_i]=M\mathbf{v}\;, \\
\\
[iG,\mathbf{q}_i]=\mathbf{v}t\;.
\end{cases}
\end{equation}
Si ottiene:
\begin{equation}
G=\frac{i}{\hbar}(\mathbf{P}\cdot t\mathbf{v}-\mathbf{Q}\cdot M\mathbf{v})\;,
\end{equation}
dove $\mathbf{P}$ e $\mathbf{Q}$ sono le coordinate del centro di massa. L'invarianza impone che $G$ sia conservato:
\begin{align}
\dev{G}{t} &=\pdev{G}{t}+\frac{i}{\hbar}[H,G] \notag \\
&= \mathbf{P}\cdot \mathbf{v}+\frac{i}{\hbar}[H,\mathbf{P}\cdot t\mathbf{v}-\mathbf{Q}\cdot M\mathbf{v}] \notag \\
&= \mathbf{P}\cdot \mathbf{v}+\frac{i}{\hbar}M\mathbf{v}\cdot [\mathbf{Q},H] \notag \\
&= \mathbf{P}\cdot \mathbf{v}-M\mathbf{v}\cdot \pdev{H}{\mathbf{P}}=0\;,
\end{align}
poiché l'identità deve essere valida indipendentemente dalla trasformazione, semplificando $\mathbf{v}$ otteniamo:
\begin{equation}
M\pdev{H}{\mathbf{P}}=\mathbf{P}\;,
\end{equation}
da cui:
\begin{equation}
H=\frac{\mathbf{P}^2}{2M}+H_R(\alpha)\;.
\end{equation}
\section{Momento angolare per una particella}
In Meccanica Classica, data l'Hamiltoniana:
\begin{equation}
H=\frac{\mathbf{p}^2}{2m}+V(\mathbf{r})\;,
\end{equation}
il momento angolare era definito come $\mathbf{L}\equiv\mathbf{r}\wedge \mathbf{p}$. Proviamo a scrivere il momento angolare quantistico come quello classico. L'Hamiltoniana può anche essere scritta come:
\begin{equation}
H=\frac{\mathbf{p}_r^2}{2m}+\frac{\mathbf{L}^2}{2mr^2}+V(\mathbf{r})\equiv \frac{\mathbf{p}_r^2}{2m}+V_{\mathrm{eff}}(\mathbf{r})\;.
\end{equation}
L'equazione di \Sch\, è:
\begin{equation}
-\frac{\hbar^2}{2m}\nabla^2\psi+V(\mathbf{r})\psi=E\psi\;.
\end{equation}
Passando in coordinate polari $(r,\theta,\varphi)$:
\begin{equation}
\begin{cases}
x=r\sin\theta\cos\varphi\;, \\
\\
y=r\sin\theta\sin\varphi\;, \\
\\
z=r\cos\theta\;,
\end{cases} \qquad 0\le\theta\le\pi\;, \qquad 0\le\varphi\le 2\pi\;,
\end{equation}
il Laplaciano si scrive:
\begin{equation}
\nabla^2=\frac{1}{r^2}\frac{\partial}{\partial r}\left(r^2\frac{\partial}{\partial r}\right)+\frac{1}{r^2}\left[\frac{1}{\sin\theta}\frac{\partial}{\partial\theta}\left(\sin\theta\frac{\partial}{\partial\theta}\right)+\frac{1}{\sin^2\theta}\frac{\partial^2}{\partial\varphi^2}\right]\;.
\end{equation}
L'elemento di volume è $\diff{V}=r^2\sin\theta\diff{R}\diff{\theta}\diff{\varphi}=r^2\diff{r}\diff{\Omega}$, con $\diff{\Omega}$ elemento di angolo solido. Sappiamo che cambiando le coordinate i prodotti scalari rimangono inalterati:
\begin{equation}
\int\diff^3{x}\;f(x,y,z)g(x,y,z)=\int r^2\diff{r}\diff{\Omega}\; f(r,\theta,\varphi)g(r,\theta,\varphi)\;.
\end{equation}
Consideriamo l'integrale:
\begin{equation}
\int r^2\diff{r}\; f\frac{1}{r^2}\frac{\partial}{\partial r}\left(r^2\pdev{g}{r}\right)\;.
\end{equation}
Integrando due volte per parti otteniamo:
\begin{equation}
\int\diff{r}\,r^2f\frac{1}{r^2}\frac{\partial}{\partial r}\left(r^2\pdev{g}{r}\right)=-\int\diff{r}\;\pdev{f}{r}r^2\pdev{g}{r}=\int r^2\diff{r}\frac{1}{r^2}\frac{\partial}{\partial r}\left(r^2\pdev{f}{r}\right) g\;.
\end{equation}
Questo dimostra che la parte radiale del Laplaciano è autoaggiunta. Lo stesso vale per la parte angolare. Quindi in generale il Laplaciano è autoaggiunto, il che giustifica la forma radiale. In coordinate sferiche, l'equazione di \Sch \, diventa:
\begin{equation}
-\frac{\hbar^2}{2m}\left(\frac{1}{r^2}\frac{\partial}{\partial r}r^2\frac{\partial}{\partial r}\right)\psi-
\frac{\hbar^2}{2m}\frac{1}{r^2}\left(\frac{1}{\sin\theta}\frac{\partial}{\partial\theta}\sin\theta\frac{\partial}{\partial\theta}+\frac{1}{\sin^2\theta}\frac{\partial^2}{\partial\varphi^2}\right)\psi+V(r)\psi=E\psi\;.
\end{equation}
Definiamo $\boldsymbol{\lag}=\mathbf{r}\wedge\mathbf{p}$ ($\boldsymbol{\lag}=\hbar\mathbf{L}$). Si verifica che:
\begin{equation}
\mathbf{L}^2=\left(\frac{1}{\sin\theta}\frac{\partial}{\partial\theta}\sin\theta\frac{\partial}{\partial\theta}+\frac{1}{\sin^2\theta}\frac{\partial^2}{\partial\varphi^2}\right)\;.
\end{equation}
Anche in Meccanica Quantistica l'Hamiltoniana può essere scritta nella forma:
\begin{equation}
H=H_r+\frac{\hbar^2\mathbf{L}^2}{2mr^2}+V(r)\;.
\end{equation}
Per $\mathbf{L}$ valgono le regole di commutazione:
\begin{equation*}
hL_i=(\mathbf{r}\times\mathbf{p})_i=\frac{\hbar}{i}\epsilon_{ijk}x_j\frac{\partial}{\partial x_k}\;,
\end{equation*}
cioè:
\begin{equation}
L_i=\frac{1}{i}\epsilon_{ijk}x_j\frac{\partial}{\partial x_k}\;.
\end{equation}
Valgono i seguenti commutatori:
\begin{align}
[L_i,x_j]&=i\epsilon_{ijk}x_k\;, \\
[L_i,p_j]&=i\epsilon_{ijk}p_k\;, \\
[L_i,L_j]&=i\epsilon_{ijk}L_k\;.
\end{align}
Inoltre si ricava:
\begin{align}
[L_i,\mathbf{L}^2] &= 0\;, \notag \\
[L_i,r] &= 0 \notag\;, \\
[L_i,\mathbf{p}^2]&=0\;.
\end{align}
Dato che $[L_i,H]=0$ per ogni $i$ e $[L_i,\mathbf{L}^2]=0$ per ogni $i$, allora $[\mathbf{L}^2,H]=0$, dunque posso trovare  una base comune di autostati per $\mathbf{L}^2$ e $H$, ma non posso trovare una base comune di autostati per le tre componenti di $\mathbf{L}$. \\
Se conoscessimo gli autostati e gli autovalori di $\mathbf{L}^2$, i.e. $f(\theta,\varphi),\beta$, allora:
\begin{equation}
\psi(r,\theta,\varphi)=R(r)f(\theta,\varphi)\;,
\end{equation}
cioè l'Hamiltoniana è separabile. Infatti, sostituendo:
\begin{align}
H\psi= &f(\theta,\varphi)(H_r+V(r))R(r)+\frac{\hbar^2}{2mr^2}R(r)\mathbf{L}^2f(\theta,\varphi)=ER(r)f(\theta,\varphi)\;, \notag \\
&f(\theta,\varphi)(H_r+V(r))R(r)+\frac{\hbar^2}{2mr^2}R(r)\beta f(\theta,\varphi)=ER(r)f(\theta,\varphi)\;.
\end{align}
Semplificando otteniamo un problema unidimensionale per $R(r)$:
\begin{equation}
H_rR(r)+\left(V(r)+\frac{\hbar^2\beta}{2mr^2}\right)R(r)=ER(r)\;.
\end{equation}
Gli autostati allora saranno della forma $|E,\beta,L_z\ket$. Posso scegliere una sola componente di $\mathbf{L}$ in quanto tra di loro non commutano. Scriviamo $\mathbf{L}$ in coordinate sferiche. Siano $L_+=L_x+iL_y$, $L_-=L_x-iL_y$:
\begin{align}
L_z &= \frac{1}{i}\frac{\partial}{\partial\varphi}\;, \notag \\
L_+ &= e^{i\varphi}\left(\frac{\partial}{\partial\theta}+i\cot\theta\frac{\partial}{\partial\varphi}\right)\;, \notag \\
L_- &= e^{-i\varphi}\left(-\frac{\partial}{\partial\theta}+i\cot\theta\frac{\partial}{\partial\varphi}\right)\;. \label{ch7_lrappschro}
\end{align}
Diagonalizziamo $L_z$:
\begin{equation}
\frac{1}{i}\frac{\partial}{\partial\varphi}f(\varphi)=\lambda f(\varphi)\qquad \Longrightarrow \qquad f(\varphi)=C e^{i\lambda\varphi}
\end{equation}
La periodicità di $2\pi$ impone $\lambda\in\mathbb{Z}$, $C=1/\sqrt{2\pi}$. Quindi gli autostati di $L_z$ sono:
\begin{equation}
f_m(\varphi)=\frac{1}{\sqrt{2\pi}}e^{im\varphi}\;.
\end{equation}
Queste costituiscono un set completo. Allora gli autostati di $\mathbf{L}^2$ si possono scrivere come:
\begin{equation}
f(\theta,\varphi)=\sum_m c_m(\theta)\frac{e^{im\varphi}}{\sqrt{2\pi}}\;.
\end{equation}
Quindi l'equazione agli autovalori per $\mathbf{L}^2$ diventa (semplificando l'esponenziale):
\begin{equation}
\left(\frac{1}{\sin\theta}\frac{\partial}{\partial\theta}\sin\theta\frac{\partial}{\partial\theta}f(\theta)-\frac{m^2}{\sin^2\theta}f(\theta)\right)+\beta f(\theta)=0\;.
\end{equation}
Posto $\xi=\cos\theta$:
\begin{equation}
\frac{\partial}{\partial\xi}\left[(1-\xi^2)\frac{\partial}{\partial\xi}\right]f-\frac{m^2}{1-\xi^2}f+\beta f=0\;.
\end{equation}
Esplicitando la derivata:
\begin{align*}
&(1-\xi^2)f''-2\xi f'+\left(-\frac{m^2}{1-\xi^2}\right)f+\beta f=0\;, \\
&f''-\frac{2\xi}{1-\xi^2}f'+\left(\frac{\beta}{1-\xi^2}-\frac{m^2}{(1-\xi^2)^2}\right)f=0\;.
\end{align*}
Osserviamo che il coefficiente di $f'$ ha due poli del primo ordine in $\xi=\pm 1$, mentre il coefficiente di $f$ ha due poli di ordine due in $\xi=\pm 1$. L'equazione è di tipo Fucsiana. Mi metto in un intorno di $1$, i.e. $\xi=1-x$, per vedere come si comporta la soluzione. Sostituendo $f=(1-\xi)^{\alpha}$, trovo $\alpha=\pm |m|/2$. La soluzione con esponente  negativo la scartiamo in quanto non è regolare. Per $\xi=-1$ trovo gli stessi esponenti, ma stavolta scarto la soluzione con esponente positivo. Possiamo allora scrivere:
\begin{equation}
f(\xi)=(1-\xi^2)^{|m|/2}g(\xi)\;,
\end{equation}
sperando che $g$ sia analitica. Scriviamo $g$ come serie:
\begin{equation}
g(\xi)=\sum_k c_k \xi^k\;.
\end{equation}
Sostituendo otteniamo la relazione di ricorrenza:
\begin{equation}
c_{k+1}=\frac{(k+|m|)(k+|m|+1)-\beta}{(k+1)(k+2)}c_k\;.
\end{equation}
Affinché la serie si tronchi e $g$ sia analitica deve essere $\beta=(k+|m|)(k+|m|+1)$. Posto $\ell\equiv k+|m|\ge |m|$, $k>0$, $\ell\in\mathbb{N}$, otteniamo che gli autovalori di $\mathbf{L}^2$ sono:
\begin{equation}
\beta=\ell(\ell+1),\qquad \qquad \ell\in\mathbb{N}\;.
\end{equation}
Fissato $\ell$, abbiamo il vincolo $|m|\le \ell$, cioè $-\ell\le m\le \ell$, cioè $m$ può assumere solo $2\ell+1$ valori. Ciò implica che nel caso di moto centrale, gli autovalori di $H$ sono $2\ell+1$ volte degeneri. \\
$m$ era l'intero che corrispondeva agli autovalori di $L_z$, quindi concludiamo che \textbf{il momento angolare è quantizzato e può assumere solo $2\ell+1$ valori}.
\section{Metodo alternativo}
Per qualche strano motivo, chiamamo il momento angolare $\mathbf{J}$. Uso gli operatori $J_+,J_-,J_3$. L'algebra è la seguente:
\begin{align}
[J_+,J_-]&= 2J_3 \notag\;, \\
[J_3,J_+]&= J_+ \notag\;, \\
[J_3,J_-]&= -J_-\;. \label{ch7_algebraangolare}
\end{align}
Quindi possiamo scrivere:
\begin{align}
\mathbf{J}^2 &= J_1^2+J_2^2+J_3^2 = J_+J_-+J_3^2-J_3 =  J_-J_++J_3^2+J_3\;.
\end{align}
Notiamo che $\mathbf{J}^2-J_3^2=J_1^2+J_2^2\ge 0$, quindi se $\mathbf{J}^2$ ha autovalore $\beta$, $J_3$ avrà autovalori $m$ tali che $-\sqrt{\beta}\le m\le \sqrt{\beta}$. Fissato $\beta$, sia $\ell$ il massimo autovalore di $J_3$. Supponiamo di conoscere un autostato di $J_3$: $J_3|m\ket=m|m\ket$.\\
Allora $J_+|m\ket$ è ancora un autostato di $J_3$ con autovalore $m+1$ (in analogia con l'operatore di creazione). Infatti dalla seconda delle relazioni \eqref{ch7_algebraangolare}: 
\begin{equation}
J_3J_+|m\ket=J_+J_3|m\ket+J_+|m\ket=mJ_+|m\ket+J_+|m\ket=(m+1)J_+|m\ket\;.
\end{equation}
Concludiamo che:
\begin{equation}
J_+^k|m\ket=C_1|m+k\ket\;,
\end{equation}
e analogamente:
\begin{equation}
J_-^k|m\ket=C_2|m-k\ket\;.
\end{equation}
Chiaramente, non possiamo salire o scendere all'infinito in quanto gli autovalori di $J_3$ sono quantizzati. Quindi deve esistere un autostato $|\ell\ket$ di $J_3$ tale che $J_3|\ell\ket=\ell|\ell\ket$ e $J_+|\ell\ket=0$. Adesso:
\begin{equation}
\mathbf{J}^2|\ell\ket=J_-J_+|\ell\ket+J_3^2|\ell\ket+J_3|\ell\ket=\ell^2|\ell\ket+\ell|\ell\ket=\ell(\ell+1)|\ell\ket\;.
\end{equation}
Per lo stesso motivo, esisterà un autostato $|\ell-n\ket$ di $\mathbf{J}_3$ tale che $J_3|\ell-n\ket=(\ell-n)|\ell-n\ket$ e $J_-|\ell-n\ket=0$. Per ogni $n$ intero, $|\ell-n\ket$ è ancora autostato di $\mathbf{J}^2$ con lo stesso autovalore:
\begin{equation}
\mathbf{J}^2|\ell-n\ket=\ell(\ell+1)|\ell-n\ket\;.
\end{equation}
Questo può essere scritto anche come:
\begin{equation}
\mathbf{J}^2|\ell-n\ket=(J_+J_-+J_3^2-J_3)|\ell-n\ket=[(\ell-n)^2-(\ell-n)]|\ell-n\ket\;.
\end{equation}
Eeguagliando gli autovalori otteniamo l'equazione:
\begin{equation}
\ell(\ell+1)=[(\ell-n)^2-(\ell-n)] \qquad \Longrightarrow \qquad \ell=\frac{n}{2}\;.
\end{equation}
Poiché $n$ è intero, i.e. il numero di volte che scendo con $J_-$, allora $\ell$ può essere intero (per $n$ pari) o semiintero (per $n$ dispari). L'autovalore minimo è quello di $|\ell-n\ket$, cioè:
\begin{equation}
\ell-n=\frac{n}{2}-n=-\frac{n}{2}=-\ell\;.
\end{equation}
Quindi ritroviamo che gli autovalori di $J_3$ variano da $-\ell$ a $\ell$, pertanto la dimensione dello spazio di Hilbert generato dagli autostati di $J_3$ sarà $2\ell+1$.
\section{Matrici del momento angolare}
Gli operatori $\mathbf{J}^2$ e $J_3$ possono essere diagonalizzati simultaneamente: $\mathbf{J}^2$ ha autovalori $j(j+1)$, mentre gli autovalori $m$ di $J_3$ sono tali che $-j\le m\le j$, con la condizione $2j\in \mathbb{N}$. Per gli autostati comuni $|j,m\ket$ valgono le seguenti relazioni:
\begin{align}
J_-|j,m\ket&=c_-|j,m-1\ket \notag\;, \\
J_+|j,m\ket &= c_+|j,m+1\ket \notag\;, \\
J_3|j,m\ket &= m|j,m\ket\;.
\end{align}
Prendendo il modulo quadro della prima relazione:
\begin{align}
|c_-|^2 &= \bra j,m|J_+J_|j,m\ket = \bra j,m|\mathbf{J}^2-(J_3^2-J_3)|j,m\ket \notag \\
&= j(j+1)-(m^2-m)=(j+m)(j+m+1)\;,
\end{align}
da cui:
\begin{equation}
c_-=\sqrt{(j+m)(j+m+1)}\;.
\end{equation}
Così siamo in grado di scrivere le matrici che rappresentano il momento angolare. Nel caso $j=1, m=-1,0,1$ si ha:
\begin{align}
J_- &=\left(\begin{matrix}
0 & 0 & 0 \\
\sqrt{2} & 0 & 0 \\
0 & \sqrt{2} & 0
\end{matrix}\right)\;, \notag \\
J_+ &=\left(\begin{matrix}
0 & \sqrt{2} & 0 \\
0 & 0 & \sqrt{2} \\
0 & 0 & 0
\end{matrix}\right)\;, \notag \\
J_3 &= \left(\begin{matrix}
1 & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & -1
\end{matrix}\right)\;.
\end{align}
Nel particolare caso $j=1/2$, otteniamo:
\begin{align}
J_3 &= \left(\begin{matrix}
1/2 & 0 \\
0 & -1/2
\end{matrix}\right)\;, \notag \\
J_-&= \left(\begin{matrix}
0 & 0 \\
1 & 0
\end{matrix}\right)\;, \notag \\
J_+ &= \left(\begin{matrix}
0 & 1 \\
0 & 0
\end{matrix}\right)\;,
\end{align}
da cui:
\begin{align}
J_1=\frac{J_+ +J_-}{2}&=\frac{1}{2}\left(\begin{matrix}
0 & 1 \\
1 & 0
\end{matrix}\right)\;, \notag \\
J_2=\frac{J_+ - J_-}{2i}&=\frac{1}{2}\left(\begin{matrix}
0 & -i \\
i & 0
\end{matrix}\right)\;,
\end{align}
cioè le matrici del momento angolare sono proporzionali alle matrici di Pauli. In questo caso, il momento angolare si indica con $\mathbf{s}$ (spin) e si ha $s_i=\frac{1}{2}\sigma_i$.
\section{Armoniche sferiche}
Riprendendo la rappresentazione di \Sch data dalle espressioni \eqref{ch7_lrappschro}, diagonlizziamo $L_3$: i suoi autostati sono proporzionali a $e^{im\varphi}$. In generale, gli autostati saranno della forma $Y_{j,m}(\theta,\varphi)$:
\begin{equation}
L_3Y_{j,m}(\theta,\varphi)=mY_{j,m}(\theta,\varphi)=me^{im\varphi}f_{j,m}(\theta)\;,
\end{equation}
quindi $Y_{j,m}(\theta,\varphi)=e^{im\varphi}f_{j,m}(\theta)$. Se $j$ è il massimo autovalore e $j=m$, allora sappiamo che $L_+f_{j,j}=0$, perciò:
\begin{equation}
e^{i\varphi}\left(\frac{\partial}{\partial\theta}-\cot\theta j\right)f_{j,j}(\theta)=0\;,
\end{equation}
che ha come soluzione:
\begin{equation}
f_{j,j}(\theta)=c(\sin\theta)^j\;,
\end{equation}
da cui:
\begin{equation}
Y_{j,j}(\theta,\varphi)=ce^{ij\varphi}(\sin\theta)^j\;,
\end{equation}
con $c$ data da:
\begin{equation}
\int |Y_{j,j}|^2\sin\theta\;\diff{\theta}\diff{\varphi}=1\;.
\end{equation}
Partendo da $Y_{j,j}$ e applicando $L_-$ trovo tutti gli altri autostati. Le $Y_{j,m}$ sono dette \textit{armoniche sferiche}. Le armoniche sferiche sono un set completo, qualunque funzione di $\theta$ e $\varphi$ può essere scritta come:
\begin{equation}
f(\theta,\varphi)=\sum_j\sum_{m=-j}^j c_{jm}Y_{j,m}(\theta,\varphi)\;.
\end{equation}
Perché $j$ non può essere semiintero? Se $j=1/2$, $Y_{1/2,1/2}=e^{i\varphi/2}\sqrt{\sin\theta}$, quindi:
\begin{equation}
L_-Y_{1/2,1/2}=c\frac{\cos\theta}{\sqrt{\sin\theta}}\;.
\end{equation}
Se $Y_{1/2,-1/2}=f(\theta)$ è lo stato più basso, allora $L_-f(\theta)=0$, cioè:
\begin{equation}
e^{-i\varphi}\left(-\frac{\partial}{\partial\theta}+i\frac{\partial}{\partial\varphi}\cot\theta\right)e^{-i\varphi/2}f(\theta)=0\;.
\end{equation}
Da cui $f(\theta)=\sqrt{\sin\theta}$, che però è diversa da quella che avevamo precedentemente trovato.
\section{Rotazioni}
Presa una funzione $\psi(\mathbf{x})$ nello spazio di Hilbert, voglio implementare le rotazioni:
\begin{align}
\psi(\mathbf{x}) &\to \psi_R(\mathbf{x}) \notag\;, \\
\mathcal{U}_R:\psi &\to \psi_R\;.
\end{align}
Ci aspettiamo che sia quantomeno una trasformazione unitaria e, per il teorema di Stone, ammetterà un generatore infinitesimale che dovrà necessariamente essere il momento angolare. \\
Consideriamo lo spazio di Hilbert generato dagli autostati dell'impulso $|\mathbf{p}\ket$ e definiamo le rotazioni:
\begin{equation}
U_R|\mathbf{p}\ket:=|R\mathbf{p}\ket, \qquad \qquad (R\mathbf{p})_i=R_{ij}p_j\;.
\end{equation}
Verifichiamo che la trasformazione sia unitaria:
\begin{equation}
\bra \mathbf{p}|\mathbf{p}'\ket=(2\pi)^3\delta^3(\mathbf{p}-\mathbf{p}')\;.
\end{equation}
Mentre, sfruttando anche le proprietà della delta di Dirac:
\begin{align}
\bra R\mathbf{p}|R\mathbf{p}'\ket &= (2\pi)^3\delta^3(R(\mathbf{p}-\mathbf{p}'))  \notag \\
&= (2\pi)^3 \frac{\delta^3(\mathbf{p}-\mathbf{p}')}{|\det R|}=(2\pi)^3\delta^3(\mathbf{p}-\mathbf{p}')\;,
\end{align}
in quanto le rotazioni hanno determinante 1. Si conclude che $\bra \mathbf{p}|\mathbf{p}'\ket=\bra R\mathbf{p}|R\mathbf{p}'\ket$, quindi la trasformazione è unitaria. \\
Per un generico stato $|\psi\ket$, $U_R|\psi\ket=|\psi_R\ket$:
\begin{equation}
\psi_R(x)=\bra \mathbf{x}|\psi_R\ket=\bra x|U_R|\psi\ket\;,
\end{equation}
ma $U_R|\mathbf{x}\ket=|R\mathbf{x}\ket$, $U_R^{-1}|\mathbf{x}\ket=|R^{-1}\mathbf{x}\ket$ e $\bra R^{-1}\mathbf{x}|=\bra x|U_R$, quindi:
\begin{equation}
\bra x|\psi_R\ket=\bra x|U_R|\psi\ket=\bra R^{-1}x|\psi\ket\;.
\end{equation}
Pertanto l'operatore $\mathcal{U}_R$ è definito sullo spazio $\mathbb{L}^2$ come:
\begin{equation}
\mathcal{U}_R\psi(x)=\psi_{R^{-1}}(x)=\psi(R^{-1}x)\;.
\end{equation}
\begin{dfn} Dato uno spazio vettoriale $V$, esiste il gruppo delle applicazioni lineari da $V$ in $V$, $\lag(V,V)$. Preso un qualunque gruppo $G$, si definisce \textit{rappresentazione} un omomorfismo:
\begin{align}
\Phi:G&\to\lag(V,V) \notag\;, \\
g &\mapsto A_g\;,
\end{align}
che mantenga la struttura del gruppo:
\begin{align}
g_1g_2 &\to A_{g_1}A_{g_2}\;, \notag \\
g^{-1} &\to A_g^{-1}\;.
\end{align}
\end{dfn}
Nel nostro caso abbiamo una rappresentazione del gruppo delle rotazioni. Infatti se $R_1R_2=R_3$ e $R_i$ induce la trasformazione unitaria $\mathcal{U}_{R_i}$, allora:
\begin{equation}
\mathcal{U}_{R_1}\mathcal{U}_{R_2}\psi(x)=U_{R_1}\psi_{R_2}(x)=\psi_{R_2}(R_1^{-1}x)=\psi(R_2^{-1}R_1^{-1}x)=\psi((R_1R_2)^{-1}x)=\psi(R_3^{-1}x)\;.
\end{equation}
Verifichiamo che il momento angolare sia il generatore infinitesimale del gruppo delle rotazioni. Considero una rotazione oraria infinitesima di un vettore $\mathbf{v}$ di un angolo $\boldsymbol{\theta}=\theta\hat{\mathbf{n}}$. Allora
$\delta\mathbf{v}=-\boldsymbol{\theta}\wedge\mathbf{v}$. \\
Per definizione, l'operatore unitario $\mathcal{U}_R(\boldsymbol{\theta})$ si può scrivere come $\mathcal{U}_R(\boldsymbol{\theta})=e^{i\boldsymbol{\theta}\cdot\mathbf{L}}\simeq 1+i\boldsymbol{\theta}\cdot\mathbf{L}$ per $|\boldsymbol{\theta}|\ll 1$. Verifichiamo che $\mathbf{L}$ è difatti il momento angolare. Se lo stato $\psi(\mathbf{x})$ tramite la rotazione va in $\psi(R^{-1}\mathbf{x})$, con $R\mathbf{x}=\mathbf{x}-\boldsymbol{\theta}\wedge \mathbf{x}$ e quindi $R^{-1}\mathbf{x}=\mathbf{x}+\boldsymbol{\theta}\wedge\mathbf{x}$, allora:
\begin{equation}
\psi(R^{-1}\mathbf{x})=\psi(\mathbf{x}+\boldsymbol{\theta}\wedge\mathbf{x})\simeq \psi(\mathbf{x})+(\boldsymbol{\theta} \wedge \mathbf{x})\cdot \nabla\psi \stackrel{!}{=} (1+i\boldsymbol{\theta}\cdot\mathbf{L})\psi(\mathbf{x})\;,
\end{equation}
da cui:
\begin{equation}
i\boldsymbol{\theta}\cdot\mathbf{L}\psi=\boldsymbol{\theta}\cdot(\mathbf{x}\wedge \nabla)\psi \qquad \Longrightarrow \qquad \mathbf{L}=\frac{1}{i}(\mathbf{x}\wedge\nabla)
\end{equation}
che è esattamente il momento angolare che avevamo definito diviso $\hbar$. \\
\\
\textbf{Esempio}. In $\mathbb{R}^3$, una rotazione di un angolo $\theta$ intorno all'asse $\hat{\mathbf{z}}$ si scrive come:
\begin{equation}
R_z=\left(\begin{matrix}
\cos\theta & \sin\theta & 0 \\
-\sin\theta & \cos\theta & 0 \\
0 & 0 & 1
\end{matrix}\right)\;,
\end{equation}
che per $\theta\to 0$ diventa:
\begin{equation}
R_z\simeq\left(\begin{matrix}
1 & \theta & 0 \\
-\theta & 1 & 0 \\
0 & 0 & 1
\end{matrix}\right)=\mathbb{I}+i\theta\Sigma_z\;,
\end{equation}
dove:
\begin{equation}
i\Sigma_z=\left(\begin{matrix}
0 & 1 & 0 \\
-1 & 0 & 0 \\
0 & 0 & 0
\end{matrix}\right)\;,
\end{equation}
è il generatore infinitesimale. Trovando con lo stesso ragionamento $\Sigma_x$ e $\Sigma_y$, si verifica che le tre componenti del generatore infinitesimale soddisfano la relazione:
\begin{equation}
[\Sigma_i,\Sigma_j]=i\epsilon_{ijk}\Sigma_k\;,
\end{equation}
detta \textit{algebra di Lie}. \\
In generale, data $A\in SO(n)$ tale che $A=e^{tB}$, $AA^t=\mathbb{I}\Longleftrightarrow e^{tB}e^{tB^t}=1$, cioè:
$$
(1+tB)(1+tB^t)=\mathbb{I}\qquad \Longleftrightarrow \qquad B=-B^t\;,
$$
allora $B$ è antisimmetrica. Le matrici antisimmetriche di ordine $n$ costituiscono uno spazio vettoriale di dimensione $n(n-1)/2$. \\
I generatori di un qualunque gruppo soddisfano l'algebra di Lie:
\begin{equation}
[T_a,T_b]=if{abc}T_c\;,
\end{equation}
dove i coefficienti $f_{abc}$ sono le \textit{costanti di struttura del gruppo} e dipendono unicamente dalle proprietà della moltiplicazione. \\
Scrivere una rotazione come $e^{i\boldsymbol{\theta}\cdot \boldsymbol{\Sigma}}$ è un'applicazione:
\begin{equation}
\exp: L_{SO(3)} \longrightarrow SO(3)\;.
\end{equation}
Questa applicazione ha l'importante proprietà di essere surgettiva, cioè qualunque rotazione può essere scritta come combinazione lineare degli esponenziali dei generatori.
\section{Rappresentazioni irriducibili}
Sia $V$ uno spazio vettoriale, $V_1\subset V$ un sottospazio e sia $v_1\in V_1$. Si dice che $V_1$ è un sottospazio invariante se:
\begin{equation}
U(g)v_1\in V_1 \qquad \forall g\;,
\end{equation}
con $U(g)$ trasformazione unitaria. \\
Se $V=V_1\oplus V_2$, con $V_1$ invariante, allora $U$ è rappresentato da una matrice a blocchi:
\begin{equation}
U=\left(\begin{matrix}
A & C \\
0 & B
\end{matrix}\right)\;.
\end{equation}
Se $V_1$ è invariante per una trasformazione unitaria, automaticamente anche $V_1^{\perp}$ è invariante, allora $C$ è la matrice nulla, quindi $U$ è rappresentato da:
\begin{equation}
U=\left(
\begin{matrix}
A & 0 \\
0 & B
\end{matrix}\right)\;.
\end{equation}
Possiamo adesso cercare di scomporre in blocchi separatamente $A$ e $B$. Quando ciò non è più possibile, otteniamo ciò che si definisce una \textit{rappresentazione irriducibile}. Un gruppo la cui rappresentazione può essere scomposta a blocchi è detto \textit{completamente riducibile}. \\
Un importante teorema afferma che i gruppi compatti sono sempre completamente riducibili. \\
I generatori $\Sigma_1,\Sigma_2,\Sigma_3$ sono rappresentazioni dell'algebra di Lie e di conseguenza rappresentazioni del gruppo. Ci chiediamo adesso se esistono rappresentazioni del gruppo che non sono rappresentazioni dell'algebra di Lie. \\
Il gruppo che in un intorno soddisfa l'algebra di Lie (e quindi è come $SO(3)$), ma è semplicemente connesso ($SO(3)$ non lo è) prende il nome di $SU(2)$, cioè il gruppo delle matrici unitarie $2\times 2$. Una generica $A\in SU(2)$ è data da:
\begin{equation}
\left(\begin{matrix}
a & b \\
-b^* & a^*
\end{matrix}\right)\;,
\end{equation}
con il vincolo $|a|^2+|b|^2=\det A=1$. Se $a=x_1+ix_2$, $b=x_3+ix_4$, allora il vincolo del determinante diventa:
\begin{equation}
x_1^2+x_2^2+x_3^2+x_4^2=1\;,
\end{equation}
che descrive un'ipersfera (che è appunto semplicemente connessa). Se scriviamo $A=e^{tB}\simeq 1+tB$ in un intorno, allora:
\begin{equation}
A\adj{A}=1\qquad \Longrightarrow \qquad (1+tB)(1+t\adj{B})=1+t(B+\adj{B})+\mathcal{O}(t^2)\stackrel{!}{=} 1\;,
\end{equation}
da cui segue $B=-\adj{B}$, cioè $B$ è antihermitiana. Questa condizione può essere espressa come $B=iM$, con $M$ hermitiana. \\
Se $A=e^B\in SU(2)$, allora $\log\det A=\tr\, B=0$ ($\det A=1$). \\
Concludiamo che i generatori del gruppo $SU(2)$ sono le matrici hermitiane a traccia nulla, cioè le matrici di Pauli. Pertanto:
\begin{equation}
A\in SU(2) \qquad \Longrightarrow \qquad A=e^{i\boldsymbol{\theta}\cdot \boldsymbol{\sigma}/2}\;.
\end{equation}
Posto $s_i=\sigma_i/2$, l'algebra dei generatori è ancora quella di Lie: $[s_i,s_j]=i\epsilon_{ijk}s_k$. Possiamo quindi definire l'omomorfismo:
\begin{equation}
\Phi: SU(2) \longrightarrow SO(3)\;.
\end{equation}
$\Phi$ ha un nucleo non vuoto dovuto al fatto che $SO(3)$ non è semplicemente connesso. \\
In un certo range di energie, una particella è elementare se le trasformazioni del gruppo di Galileo su di essa hanno una rappresentazione irriducibile. \\
\subsection{Gruppo di Galileo}
Il gruppo di Galileo include traslazioni, rotazioni e boost. Il generatore del gruppo di Galileo è:
\begin{equation}
G(\mathbf{v})\equiv\exp\left[\frac{i(\mathbf{Q}\cdot M\mathbf{v}-\mathbf{P}\cdot\mathbf{v}t)}{\hbar}\right]\;.
\end{equation}
\textbf{Proprietà}. Le rappresentazioni irriducibili di un gruppo abeliano sono unidimensionali. \\
In generale, le traslazioni sono un sottogruppo abeliano, quindi:
\begin{equation}
e^{i\mathbf{P}\cdot\mathbf{a}}|\mathbf{p}\ket=\mathrm{fase}\cdot|\mathbf{p}\ket\;.
\end{equation}
Tra tutti gli impulsi, prendiamo quello nullo, che è invariante per rotazione:
\begin{equation}
U(R)|\mathbf{0},m\ket=D_{m'm}(R)|\mathbf{0},m\ket\;.
\end{equation}
In questo caso $D_{m'm}(R)=e^{i\boldsymbol{\theta}\cdot \mathbf{s}}$. La matrice $\mathbf{s}$ (spin) rappresenta il momento angolare nel sistema di riferimento in cui la particella è ferma. Questa è una rappresentazione riducibile del gruppo di Galileo. Ricordando come agisce una rotazione su uno stato a impulso non nullo:
\begin{equation}
U(R)|\mathbf{p},m\ket=D_{m'm}(R)|R\mathbf{p},m\ket\;.
\end{equation}
Gli stati $|\mathbf{p}\ket$ sono definiti a partire da $|\mathbf{0}\ket$ come:
\begin{equation}
|\mathbf{p}\ket\equiv e^{iG(\mathbf{v})/\hbar}|\mathbf{0}\ket\;,
\end{equation}
con $\mathbf{v}=\mathbf{P}/M$. Allora:
\begin{equation}
U(R)e^{i(\mathbf{Q}\cdot M\mathbf{v}-\mathbf{P}\cdot\mathbf{v}t)/\hbar}|\mathbf{0},m\ket= Ue^{iG(\mathbf{v})/\hbar}\adj{U}U|\mathbf{0},m\ket=Ue^{iG(\mathbf{v})/\hbar}\adj{U}D_{m'm}(R)|\mathbf{0},m\ket\;.
\end{equation}
Dato che $Ue^A\adj{U}=e^{UA\adj{U}}$, si ha (la parte in $\mathbf{P}$ sparisce perché $\mathbf{v}=\mathbf{P}/M$):
\begin{equation}
U\mathbf{Q}\cdot M\mathbf{v}\adj{U}=(R^{-1}\mathbf{Q})\cdot M\mathbf{v}=\mathbf{Q}\cdot (MR^{-1}\mathbf{v})\;,
\end{equation}
da cui:
\begin{equation}
Ue^{iG(\mathbf{v})/\hbar}\adj{U}U|\mathbf{0},m\ket=e^{\mathbf{Q}\cdot (MR^{-1}\mathbf{v})}D_{m',m}(R)|\mathbf{0},m\ket=D_{m',m}(R)|R\mathbf{p},m\ket\;.
\end{equation}
In conclusione
\begin{equation}
\left(e^{i\boldsymbol{\theta}\cdot\mathbf{s}}\right)_{\alpha\beta}\psi_{\beta}(R^{-1}\mathbf{x})=e^{i\boldsymbol{\theta}\cdot \mathbf{L}}\left(e^{i\boldsymbol{\theta}\cdot\mathbf{s}}\right)_{\alpha\beta}\psi_{\beta}(\mathbf{x})\;.
\end{equation}
Pertanto l'invarianza per rotazioni non implica che siano conservati singolarmente $\mathbf{L}$ o $\mathbf{s}$ (salvo casi eccezionali), ma che $\mathbf{J}\equiv \mathbf{L}+\mathbf{S}$ è sempre conservato. \\
\textbf{N.B.} Lo spin $\mathbf{s}$ agisce sull'indice intero $\beta$, $\mathbf{L}$ agisce sulla variabile $\mathbf{x}$. \\
\\
\textbf{Lemma di Schur}. \\
Una rappresentazione è irriducibile se non vi sono sottospazi propri dello spazio vettoriale invarianti.
\proof
Supponiamo che $U$ sia irriducibile. Se $B$ è tale che:
\begin{equation}
U(g)B=BU(g)\qquad \forall g\;,
\end{equation}
allora $B=\lambda \mathbb{I}$. Poiché siamo sul campo dei complessi, esiste almeno un $v$ e un $\lambda$ tali che $Bv=\lambda v$. Allora:
\begin{equation}
W\equiv \ker (B-\lambda\mathbb{I})\;,
\end{equation}
è invariante per $U$. Infatti, se $u\in W$ allora:
\begin{equation}
(B-\lambda\mathbb{I})U(g)u=U(g)(B-\lambda \mathbb{I})u=0\;,
\end{equation}
quindi $U(g)u\in W$. Poiché la rappresentazione è per ipotesi irriducibile, allora $W$ coincide con tutto lo spazio e quindi $B=\lambda \mathbb{I}$ su tutto lo spazio.
\endproof

\textbf{Esempio}: se l'Hamiltoniana è invariante sotto rotazioni, allora essa sarà $2j+1$ volte degenere. Infatti se $|\psi\ket=|j,m\ket$, si ha, nello stato più alto ($m=j$):
\begin{equation}
\bra j,j|H|j,j\ket=E\;.
\end{equation}
Si verifica che vale anche:
\begin{equation}
\bra j,j-1|J_+HJ_-|j,j-1\ket=E\;.
\end{equation}
Se un gruppo è abeliano, allora $\forall g_1,g_2$ si ha $U(g_1)U(g_2)=U(g_2)U(g_1)$. Quindi, per il lemma di Schur, $U(g)=\lambda_g\mathbb{I}$ per ogni $g$, quindi la rappresentazione irriducibile è effettivamente unidimensionale. \\
Nel caso delle traslazioni, il gruppo è abeliano. Infatti si vede che per ogni $\mathbf{p}$ (le rappresentazioni irriducibili del gruppo delle traslazioni sono esponenziali):
\begin{equation}
T_a e^{i\mathbf{p}\cdot\mathbf{x}}=e^{i\mathbf{p}\cdot(\mathbf{x}+\mathbf{a})}=e^{i\mathbf{p}\cdot\mathbf{a}}e^{i\mathbf{p}
\cdot\mathbf{x}}=\lambda e^{i\mathbf{p}\cdot\mathbf{x}}\;,
\end{equation}
dove $\lambda=e^{i\mathbf{p}\cdot\mathbf{a}}$ è una fase. Quindi la rappresentazione irriducibile è effettivamente unidimensionale. \\
\\
\textbf{Esercizio}. \\
Se $j=1/2$, $2j+1=2$, le matrici delle rotazioni erano della forma $e^{i\boldsymbol{\theta}\cdot\mathbf{s}}$. Il generatore infinitesimale era la matrice di spin $\mathbf{s}$ data da $s_i=\sigma_i/2$, denotando con $\sigma_i$ le matrici di Pauli. $\mathbf{s}$ soddisfa l'algebra di Lie: $[s_i,s_j]=i\epsilon_{ijk}s_k$. Si ha quindi:
\begin{equation}
e^{i\boldsymbol{\theta}\cdot\mathbf{s}}=e^{i\boldsymbol{\theta}\cdot\boldsymbol{\sigma}/2}=\cos\frac{\theta}{2}+i\hat{\mathbf{n}}\cdot\boldsymbol{\sigma}\sin\frac{\theta}{2}\;,
\end{equation}
con $\boldsymbol{\theta}=\theta\hat{\mathbf{n}}$. Notiamo che:
\begin{equation}
(\hat{\mathbf{n}}\cdot\boldsymbol{\sigma})^2=n_i\sigma_in_j\sigma_j=n_in_j(\delta_{ij}+i\epsilon_{ijk}\sigma_k)=1\;,
\end{equation}
quindi:
\begin{equation}
e^{i\theta\hat{\mathbf{n}}\cdot\boldsymbol{\sigma}/2}=\sum_{k=0}^{\infty}\left(\frac{\theta}{2}\right)^k i^k (\hat{\mathbf{n}}\cdot\boldsymbol{\sigma})^k\frac{1}{k!}\;.
\end{equation}
Prendiamo in considerazione $\sigma_3$. Nella base:
\begin{align}
w_+=|+\ket=|\uparrow\ket &=\left(\begin{matrix}
1 \\
0
\end{matrix}\right) \qquad \mbox{spin 1/2}\notag \;,\\
w_-=|-\ket=|\downarrow\ket &=\left(\begin{matrix}
0 \\
1
\end{matrix}\right)\qquad \mbox{spin -1/2}\;,
\end{align}
$\sigma_3$ è data da:
\begin{equation}
\sigma_3=\left(\begin{matrix}
1 & 0 \\
0 & -1
\end{matrix}\right)\;.
\end{equation}
$|\uparrow\ket,|\downarrow\ket$ sono autovettori di $\mathbf{s}^2$ con autovalore $3/4$. Lungo una generica direzione $\hat{\mathbf{n}}$ giacente nel piano $yz$, $\mathbf{s}\cdot\hat{\mathbf{n}}$ avrà due autostati $w_+',w_-'$. Verifichiamo che questi due autostati sono i ruotati di $w_+,w_-$ intorno all'asse $x$.
\begin{align}
w_+' &= e^{i\theta\sigma_x/2}w_+=\left(\cos\frac{\theta}{2}+i\sigma_x\sin\frac{\theta}{2}\right)\left(\begin{matrix}
1 \\
0
\end{matrix}\right) = \notag \\
&= \left(\begin{matrix}
\cos\frac{\theta}{2} & i\sin\frac{\theta}{2} \\
i\sin\frac{\theta}{2} & \cos\frac{\theta}{2}
\end{matrix}\right)\left(
\begin{matrix}
1 \\
0
\end{matrix}\right)=\left(
\begin{matrix}
\cos\frac{\theta}{2} \\
i\sin\frac{\theta}{2}
\end{matrix}\right)\;.
\end{align}
Verifichiamo se $(\boldsymbol{\sigma}\cdot\hat{\mathbf{n}})w_+'=w_+'$. Dato che:
\begin{align}
\hat{\mathbf{n}}&=(0,\sin\theta,\cos\theta)\;, \notag \\
\boldsymbol{\sigma}\cdot \hat{\mathbf{n}} &= \sin\theta \sigma_y+\cos\theta \sigma_z=
\left(\begin{matrix}
\cos\theta & -i\sin\theta \\
i\sin\theta & \cos\theta
\end{matrix}\right)\;.
\end{align}
Allora:
\begin{align}
\left(\begin{matrix}
\cos\theta & -i\sin\theta \\
i\sin\theta & -\cos\theta
\end{matrix}\right)\left(\begin{matrix}
\cos\frac{\theta}{2} \\
i\sin\frac{\theta}{2}
\end{matrix}\right) &= \left(
\begin{matrix}
\cos\theta\cos\frac{\theta}{2}+\sin\theta\sin\frac{\theta}{2} \\
i\sin\theta\cos\frac{\theta}{2}-i\cos\theta\sin\frac{\theta}{2}
\end{matrix}\right) \notag \\
&= \left(\begin{matrix}
\cos\frac{\theta}{2} \\
i\sin\frac{\theta}{2}
\end{matrix}\right)=w_+'\;.
\end{align}
Consideriamo adesso un sistema a due stati. La più generica Hamiltoniana è data da:
\begin{equation}
H=E_0+\frac{1}{2}\mathbf{A}\cdot\boldsymbol{\sigma}\;.
\end{equation}
Calcoliamo gli autovalori di $H$. Eseguiamo prima una rotazione $R$ intorno a $\sigma_3$:
\begin{equation}
U(R)H\adj{U}(R)=E_0+(\mathbf{A}\cdot R^{-1}\boldsymbol{\sigma})=E_0+(R\mathbf{A}\cdot\boldsymbol{\sigma})\;.
\end{equation}
L'ultima uguaglianza è dovuta all'invarianza del prodotto scalare per rotazioni. Quello che abbiamo fatto sostanzialmente è ruotare $\mathbf{A}$ posizionandolo lungo $\sigma_3$. Quindi (le rotazioni sono trasformazioni unitarie che lasciano invariati gli autovalori) possiamo scrivere:
\begin{equation}
H=E_0+\left(\begin{matrix}
|\mathbf{A}| & 0 \\
0 & -|\mathbf{A}|
\end{matrix}\right)\;.
\end{equation}

\textbf{Esercizio}. Prendiamo una particella ferma con spin $1/2$ avente un momento magnetico $\mu$. Vogliamo scrivere l'Hamiltoniana di interazione con un campo magnetico esterno. Per il teorema di Larmor, sappiamo che $\boldsymbol{\mu}\propto \mathbf{s}$, quindi:
\begin{equation}
H=-\boldsymbol{\mu}\cdot\mathbf{B}=-k\mathbf{s}\cdot\mathbf{B}=-\frac{1}{2}k\boldsymbol{\sigma}\cdot\mathbf{B}\;.
\end{equation}
Si assume come unità di misura del momento magnetico il \textit{magnetone di Bohr}, definito come:
\begin{equation}
\mu_B\equiv \frac{e\hbar}{2mc}\;.
\end{equation}
Il momento magnetico è definito come il massimo autovalore di $\boldsymbol{\sigma}$, che nel caso di spin $1/2$ è 1, quindi:
\begin{equation}
\frac{k}{2}=\mu \qquad \Longleftrightarrow \qquad k=2\mu\;.
\end{equation}
Consideriamo l'Hamiltoniana:
\begin{equation}
H=\hbar \boldsymbol{\Omega}\cdot \mathbf{s}\;,
\end{equation}
con $\boldsymbol{\Omega}$ (momento magnetico) costante. Vogliamo scrivere l'equazione di Heisenberg per l'operatore $\mathbf{s}(t)$, con $\mathbf{s}(0)=\boldsymbol{\sigma}/2$ (ci aspettiamo di trovare il moto di precessione). Abbiamo quindi, componente per componente:
\begin{equation}
\dev{s_i}{t}=\frac{i}{\hbar}[H,s_i]=i\Omega_k[s_k,s_i]=i\Omega_k i\epsilon_{kij}s_j=-\epsilon_{ijk}s_j\Omega_k=-(\boldsymbol{\Omega}\wedge\mathbf{s})_i
\end{equation}
In forma vettoriale
\begin{equation}
\dev{\mathbf{s}}{t}=-\boldsymbol{\Omega}\wedge\mathbf{s}\;,
\end{equation}
Scegliamo l'asse 3 ($\hat{\mathbf{z}}$) lungo $\boldsymbol{\Omega}$, cioè $\boldsymbol{\Omega}=\Omega\hat{\mathbf{z}}$. Le tre equazioni saranno quindi:
\begin{align}
\dev{s_1}{t} &= \Omega s_2\;, \notag \\
\dev{s_2}{t} &= -\Omega s_1\;, \notag \\
\dev{s_3}{t} &= 0\;.
\end{align}
Le cui soluzioni sono:
\begin{equation}
\begin{cases}
s_+(t)=e^{i\Omega t}s_+(0)\;, \\
\\
s_-(t)=e^{-i\Omega t}s_-(0)\;, \\
\\
s_3(t)=s_3(0)=\dfrac{\sigma_3}{2}\; (\mbox{costante})\;.
\end{cases}
\end{equation}
Dove $s_{\pm}=s_1\pm is_2$. Si arrivava allo stesso risultato considerando che per un qualunque operatore $A$:
\begin{equation}
A_H(t)=e^{iHt/\hbar}Ae^{-iHt/\hbar}\;.
\end{equation}
Allora:
\begin{equation}
\mathbf{s}(t)=e^{it\boldsymbol{\Omega}\cdot\mathbf{s}}\mathbf{s}(0)e^{-it\boldsymbol{\Omega}\cdot\mathbf{s}}\;,
\end{equation}
che rappresenta appunto una rotazione intorno a $\boldsymbol{\Omega}$ con angolo $\theta=|t\boldsymbol{\Omega}|$, cioè una precessione, esattamente come prima. \\
\\
\textbf{Esercizi sulle armoniche sferiche}. \\
Ricordando l'espressione delle armoniche sferiche con $m$ massimo, cioè $m=l$:
\begin{equation}
Y_{ll}=c\sin^l\theta e^{il\varphi}=c\frac{(x+iy)^l}{r^l}\;.
\end{equation}
Definiamo l'operatore inversione spaziale $I$, il cui effetto su $\mathbf{x}$ e $\mathbf{P}$ è definito da:
\begin{align}
I\mathbf{x}\adj{I}=-\mathbf{x} \qquad &\Longrightarrow \qquad I\mathbf{x}=-\mathbf{x}I\;, \notag \\
I\mathbf{P}\adj{I}=-\mathbf{P} \qquad &\Longrightarrow \qquad I\mathbf{P}=-\mathbf{P}I\;.
\end{align}
Quindi $\mathbf{x},\mathbf{P}$ non commutano con $I$. Il momento angolare però non cambia, quindi commuta con $I$:
\begin{equation}
I\mathbf{L}\adj{I}=I\mathbf{x}\wedge\mathbf{P}\adj{I}=\mathbf{x}\wedge\mathbf{P}=\mathbf{L}\;.
\end{equation}
Come cambiano le armoniche sferiche sotto rotazione? Se indichiamo con $\hat{\mathbf{n}}$ il versore individuato dagli angoli $\theta,\varphi$, allora $Y_{lm}(\theta,\varphi)=Y_{lm}(\hat{\mathbf{n}})$. Sappiamo che valeva:
\begin{equation}
\mathcal{U}_R\psi(\mathbf{x})=\psi(R^{-1}\mathbf{x}),\qquad \mathcal{U}_R=\exp(i\boldsymbol{\theta}\cdot\mathbf{L})\;.
\end{equation}
Allora:
\begin{equation}
\mathcal{U}_RY_{lm}(\hat{\mathbf{n}})=Y_{lm}(R^{-1}\hat{\mathbf{n}})\;.
\end{equation}
Dato che:
\begin{align}
Y_{lm}(\hat{\mathbf{n}}) &= \bra\hat{\mathbf{n}}|l,m\ket\;, \notag \\
Y_{lm}(R^{-1}\hat{\mathbf{n}}) &= \bra R^{-1}\hat{\mathbf{n}}|l,m\ket=\bra\hat{\mathbf{n}}|U(R)|l,m\ket\;.
\end{align}
Poiché $U$ è una rappresentazione irriducibile (può mischiare gli $m$, ma non gli $l$), si ha allora:
\begin{equation}
Y_{lm}(R^{-1}\hat{\mathbf{n}})=\bra\hat{\mathbf{n}}|l,m'\ket\bra l,m'|U(R)|l,m\ket\;.
\end{equation}
In conclusione si ottiene:
\begin{equation}
Y_{lm}(R^{-1}\hat{\mathbf{n}})=D^{(l)}_{m'm}(R)Y_{lm'}(\hat{\mathbf{n}})\;,
\end{equation}
cioè le armoniche ruotate vanno in se stesse. \\
\\
Ricordando l'espressione del Laplaciano in coordinate polari:
\begin{equation}
\nabla^2=\frac{1}{r^2}\frac{\partial}{\partial r}r^2\frac{\partial}{\partial r}-\frac{\mathbf{L}^2}{r^2}\;,
\end{equation}
si dice che una funzione $f$ è armonica se $\nabla^2f=0$. Cerchiamo i polinomi armonici omogenei di grado $l$:
\begin{equation}
p(x,y,z)=r^l f(\theta,\varphi)\;,
\end{equation}
perché in coordinate polari i polinomi omogenei di grado $l$ sono proporzionali a $r^l$. Sostituendo nell'equazione si ottiene:
\begin{equation}
\nabla^2p=l(l+1)r^{l-2}f(\theta,\varphi)-\mathbf{L}^2 f r^{l-2}=0\;,
\end{equation}
da cui:
\begin{equation}
\mathbf{L}^2f=l(l+1)f\;,
\end{equation}
che è l'equazione che caratterizza le armoniche sferiche. Per cui concludiamo che le armoniche sferiche sono la parte angolare dei polinomi armonici.
\section{Composizione dei momenti angolari}
Dati due spazi vettoriali $V_1,V_2$ con $\dim V_1=d_1$ e $\dim V_2=d_2$, con basi $|e_i\ket,|f_{\alpha}\ket$ tali che siano entrambi rappresentazioni del gruppo delle rotazioni $G$, vogliamo studiare come si compongono le rappresentazioni. Un modo è quello di considerare lo spazio $V_1\oplus V_2$, in cui ogni $|\psi\ket$ può essere scritto in modo unico come combinazione lineare dei vettori di base di entrambi gli spazi:
\begin{equation}
|\psi\ket\in V_1\oplus V_2 \qquad \Longrightarrow\qquad |\psi\ket=\sum c_i|e_i\ket+\sum d_{\alpha}|f_{\alpha}\ket=
\left(\begin{matrix}
c_1 \\
\vdots \\
d_1 \\
\vdots
\end{matrix}\right)\;,
\end{equation}
e quindi vedere come agiscono le rotazioni su $\psi\ket$. Chiaramente, essendo i due spazi invarianti, si avrà:
\begin{equation}
D=\left(\begin{matrix}
D^{(1)} & 0 \\
0 & D^{(2)}
\end{matrix}\right)\;.
\end{equation}
Questa è quella che si chiama \textit{rappresentazione somma}, cioè abbiamo decomposto lo spazio di Hilbert nella somma diretta di due sottospazi invarianti. Tuttavia, possiamo anche definire il prodotto tensoriale $V_1\otimes V_2$, avente base $|e_i\ket\otimes |f_{\alpha}\ket=|e_i\ket|f_{\alpha}\ket$. Lo spazio $V_1\otimes V_2$ è definito come:
\begin{equation}
V_1\otimes V_2=\left\{\sum A_{ij}|e_i\ket|f_j\ket\right\}\;,
\end{equation}
e in generale $\dim(V_1\otimes V_2)=\dim V_1\cdot\dim V_2$. Se su $V_1$ e $V_2$ ho due rappresentazioni irriducibili del gruppo delle rotazioni:
\begin{align}
D_{ij}^{(1)} \qquad d_1\times d_1\qquad \mbox{agisce su $V_1$}\;, \notag \\
D_{\alpha\beta}^{(2)} \qquad d_2\times d_2\qquad \mbox{agisce su $V_2$}\;,
\end{align}
allora si ha:
\begin{equation}
U(R)|e_i\ket|f_{\alpha}\ket=D_{ji}^{(1)}|e_j\ket D_{\beta\alpha}^{(2)}|f_{\beta}\ket=D_{ji}^{(1)}D_{\beta\alpha}^{(2)}|e_i\ket|f_{\alpha}\ket\;.
\end{equation}
quello che abbiamo ottenuto è ancora una rappresentazione, detta \textit{rappresentazione prodotto}, e si indica con $D^{(1)}\otimes D^{(2)}$. La rappresentazione prodotto in generale non è irriducibile.\\
Un vettore $|\psi\ket\in V_1\otimes V_2$ si può scrivere come:
\begin{equation}
|\psi\ket=A_{i\alpha}|e_i\ket|f_{\alpha}\ket\;.
\end{equation}
Applichiamo una rotazione:
\begin{equation}
|\psi\ket \longrightarrow |\psi'\ket= A_{i\alpha}'|e_i\ket|f_{\alpha}\ket, \qquad A_{i\alpha}'=D_{ij}^{(1)}D_{\alpha\beta}^{(2)}A_{j\beta}\;.
\end{equation}
Per $\theta \simeq 0$ si ha:
\begin{align}
D^{(1)} &\simeq 1+i\boldsymbol{\theta}\cdot \mathbf{J}_1\;, \notag \\
D_{ij}^{(1)} &\simeq \delta_{ij}+i\boldsymbol{\theta}(\mathbf{J}_1)_{ij} \notag\;, \\
D^{(2)} &\simeq 1+i\boldsymbol{\theta}\cdot\mathbf{J}_2 \notag\;, \\
D_{\alpha\beta}^{(2)} &\simeq \delta_{\alpha\beta}+i\boldsymbol{\theta}(\mathbf{J}_2)_{\alpha\beta}\;.
\end{align}
Quindi:
\begin{align}
(D^{(1)})_{ij}\otimes (D^{(2)})_{\alpha\beta} &= (\delta_{ij}+i\boldsymbol{\theta}(\mathbf{J}_1)_{ij})(\delta_{\alpha\beta}+i\boldsymbol{\theta}(\mathbf{J}_2)_{\alpha\beta}) \notag \\
&= \delta_{ij}\delta_{\alpha\beta}+i\boldsymbol{\theta}(\mathbf{J}^1_{ij}\delta_{\alpha\beta}+\delta_{ij}\mathbf{J}^2_{\alpha\beta})  \notag \\
&= 1+i\boldsymbol{\theta}(\mathbf{J}_1+\mathbf{J}_2)\;.
\end{align}
$\mathbf{J}_1$ agisce su uno spazio di dimensione $2j_1+1$, mentre $\mathbf{J}_2$ su uno spazio di dimensione $2j_2+1$. Quindi lo spazio prodotto tensoriale avrà dimensione $(2j_1+1)(2j_2+1)$. Per trovare la rappresentazione irriducibile, mi basta trovare gli autovalori di $\mathbf{J}^2$ e $J_z$ nello spazio $V=V_1\otimes V_2$. Gli autostati di $\mathbf{J}_1$ e $\mathbf{J}_2$ sono $|j_1,m_1\ket$ e $|j_2,m_2\ket$. Cominciamo da $J_z=J_{1z}+J_{2z}$. I suoi autostati saranno il prodotto tensoriale $|j_1,m_1\ket|j_2,m_2\ket$. Infatti:
\begin{equation}
(J_{1z}+J_{2z})|j_1,m_1\ket|j_2,m_2\ket=(m_1+m_2)|j_1,m_1\ket|j_2,m_2\ket\;.
\end{equation}
Pertanto gli autovalori di $J_z$ saranno $m_1+m_2$. Adesso passiamo a $\mathbf{J}^2$. Definiamo:
\begin{equation}
J_-=J_{1-}+J_{2-}\;.
\end{equation}
Lo stato con autovalore massimo è quello per cui $m_1=j_1$ e $m_2=j_2$, cioè $|j_1,j_1\ket|j_2,j_2\ket$. Da questo, applicando $J_-$, siamo in grado di costruire tutta la rappresentazione. L'autovalore massimo è chiaramente $j_1+j_2$. \\
Se adesso applichiamo $J_-$ otteniamo:
\begin{equation}
J_-(|j_1,j_1\ket|j_2,j_2\ket)=c_1|j_1,j_1-1\ket|j_2,j_2\ket+c_2|j_1,j_1\ket|j_2,j_2-1\ket\equiv |J,J-1\ket\;,
\end{equation}
da cui ricaviamo che la somma $J$ dei momenti angolari $J_1,J_2$ sarà tale che $|J_1-J_2|\le J\le J_1+J_2$. \\
\textbf{Esempio 1}. Se consideriamo il caso di spin $1/2$, avremo quattro stati possibili:
\begin{align}
|+\ket|+\ket &\qquad |-\ket|+\ket \notag\;, \\
|+\ket|-\ket &\qquad |-\ket|-\ket\;.
\end{align}
Effettuiamo una rotazione $\exp(i\boldsymbol{\theta}\cdot\boldsymbol{\sigma}_1/2)\exp(i\boldsymbol{\theta}\cdot\boldsymbol{\sigma}_2/2)$, e indichiamo con $\mathbf{s}=\mathbf{s}_1+\mathbf{s}_2$. Il momento angolare totale varietà dal massimo $\frac{1}{2}+\frac{1}{2}=1$ al minimo zero. Il massimo di $\mathbf{s}$ si ha quando entrambi gli elettroni hanno spin $+1/2$:
\begin{equation}
|+\ket|+\ket=|s=1,s_z=1\ket\;.
\end{equation}
Dato questo stato, devono necessariamente esistere altri due stati tali che:
\begin{equation}
|s=1,s_z=0\ket, \qquad \qquad |s_1,s_z=-1\ket\;.
\end{equation}
Infatti:
\begin{align}
s_-|s=1,s_z=1\ket&=\sqrt{2}|s=1,s_z=0\ket\;, \notag \\
s_-|s=1,s_z=0\ket&=\sqrt{2}|s=1,s_z=-1\ket\;.
\end{align}
D'altronde:
\begin{equation}
(s_{1-}+s_{2-})|+\ket|+\ket=|-\ket|+\ket+|+\ket|-\ket\;,
\end{equation}
quest'ultima espressione, per definizione, deve essere necessariamente uguale al secondo membro della prima espressione di (8.10.16), quindi:
\begin{equation}
|s=1,s_z=0\ket =\frac{1}{\sqrt{2}}(|-\ket|+\ket+|+\ket|-\ket)\;.
\end{equation}
Inoltre:
\begin{equation}
|s=1,s_z=-1\ket=|-\ket|-\ket\;.
\end{equation}
Abbiamo così trovato tre dei quattro stati possibili. Quello che manca è l'ortogonale di (8.10.18), cioè:
\begin{equation}
|s=0,s_z=0\ket=\frac{1}{\sqrt{2}}(|-\ket|+\ket-|+\ket|-\ket)\;.
\end{equation}
\textbf{Esempio 2}. Supponiamo $L=1$ e consideriamo due elettroni descritti dalle funzioni d'onda:
\begin{equation}
\psi_1=R(r_1)Y_{1m}(\theta_1,\varphi_1) \qquad \psi_2=R(r_2)Y_{1m}(\theta_2,\varphi_2)\;.
\end{equation}
Le funzioni d'onda totali (cioè il prodotto tra quelle dei singoli elettroni), al variare di $m$ possono essere $9$. Il momento angolare totale $\mathbf{L}=\boldsymbol{\ell}_1+\boldsymbol{\ell}_2$ può assumere valori $\ell_1-\ell_2=0,1,2=\ell_1+\ell_2$, cioè in termini di rappresentazioni:
\begin{equation}
3\otimes 3=5\oplus 3\oplus 1=9\;.
\end{equation}
In altri termini, dobbiamo avere cinque combinazioni che si trasformano come $L=2$, tre come $L=1$ e una come $L=0$. Supponiamo che il primo elettrone abbia coordinate $\mathbf{X}\equiv (x_1,y_1,z_1)$ e il secondo abbiamo coordinate $\mathbf{Y}\equiv (x_2,y_2,z_2)$. \\
$L=0$ rappresenta uno scalare. Infatti l'unico scalare ottenibile da due vettori è proprio il prodotto scalare $\mathbf{X}\cdot\mathbf{Y}\equiv X_iY_i$. \\
$L=1$ rappresenta un vettore (tre componenti, appunto), quindi sarà $(\mathbf{X}\wedge\mathbf{Y})_k=\epsilon_{ijk}X_iY_j$ per $k=1,2,3$. \\
$L=2$ rappresenta un tensore a due indici (nove componenti, troppe). Ogni tensore a due indici può essere scritto come:
\begin{equation}
T_{ij}=\frac{1}{2}(T_{ij}+T_{ji})+\frac{1}{2}(T_{ij}-T_{ji})\;,
\end{equation}
dove il primo pezzo rappresenta la parte simmetrica del tensore, la seconda quella antisimmetrica. La parte antisimmetrica (tre componenti) rappresenta appunto il prodotto vettoriale, che trasforma indipendentemente. La parte simmetrica ha dunque $6$ componenti, ancora troppe. Tuttavia, queste non sono indipendenti, in quanto una di essere deve rappresentare lo scalare ($L=0$), che trasforma indipendentemente. Allora scrivo la parte simmetrica $S_{ij}$ come:
\begin{equation}
S_{ij}=S_{ij}-\frac{1}{3}\delta_{ij}\tr S+\frac{1}{3}\delta_{ij}\tr\, S\;.
\end{equation}
L'ultimo addendo rappresenta $L=0$ (la traccia è il prodotto scalare). Quindi le cinque componenti rimanenti che rappresentano $L=2$ sono date dai tensori simmetrici a traccia nulla. \\
In generale, si potrà scrivere:
\begin{equation}
|J,M\ket=\sum \mathcal{C}(J,M,j_1,m_1,j_2,m_2)|j_1,m_1\ket|j_2,m_2\ket\;,
\end{equation}
dove i coefficienti $\mathcal{C}(J,M,j_1,m_1,j_2,m_2)$ sono chiamati \textit{coefficienti di Clebsch-Gordan}. \\
Se lo spazio di Hilbert su cui stiamo lavorando si può scrivere come prodotto tensoriale di due sottospazi, $\ham=\ham_1 \otimes \ham_2$ e quindi gli stati di $\ham$ si possono scrivere come $\psi(\mathbf{x}_1)\varphi(\mathbf{x}_2)$, prendiamo come base $|j_1,m_1\ket|j_2,m_2\ket$ dove $|j_i,m_i\ket$ sono autostati di $\mathbf{J}^2$ e $J_z$:
\begin{align*}
\mathbf{J}^2|j_i,m_i\ket &= j_i(j_i+1)|j_i,m_i\ket\;, \\
J_z|j_i,m_i\ket&=m_i|j_i,m_i\ket\;,
\end{align*}
e definiamo le rotazioni:
\begin{equation}
U(R)|j_1,m_1\ket|j_2,m_2\ket=R^{(j_1)}_{m_1'm_1}|j_1,m_1\ket R^{(j_2)}_{m_2'm_2}|j_2,m_2\ket\;,
\end{equation}
con $U(R)=e^{i\boldsymbol{\theta}\cdot\mathbf{J}}=1+i\boldsymbol{\theta}\cdot\mathbf{J}$. Possiamo scrivere inoltre:
\begin{align}
\mathbf{J}&=\mathbf{j}_1+\mathbf{j}_2=j_1\otimes 1+ 1\otimes j_2 \notag\;, \\
J_z &= j_{1z}+j_{2z}\;,
\end{align}
e si ha $|j_1-j_2|\le J\le j_1+j_2$. Possiamo tuttavia prendere come base dello spazio di Hilbert gli autostati del momento angolare totale $|J,M\ket$, $M=m_1+m_2$, allora per la completezza del primo set scelto si ha:
\begin{equation}
|J,M,j_1,j_2\ket=\sum |j_1,m_1,j_2,m_2\ket\bra j_1,m_1,j_2,m_2|J,M,j_1,j_2\ket\;,
\end{equation}
dove $\bra j_1,m_1,j_2,m_2|J,M,j_1,j_2\ket$ sono proprio i coefficienti di Clebsch-Gordan.
\section{Regole di selezione}
Vogliamo adesso stabilire dei criteri per capire se un elemento di matrice di un operatore $A$ scalare (invariante sotto rotazioni) è non nullo:
\begin{equation}
\bra \beta,j',m'|A|\alpha,j,m\ket\;.
\end{equation}
Posto $|\psi\ket=A|\alpha,j,m\ket$, applichiamo una rotazione:
\begin{equation}
U(R)|\psi\ket=U(R)AU^{-1}(R)U(R)|\alpha,j,m\ket=AR^{(j)}_{m'm}|\alpha,j,m\ket\;.
\end{equation}
Dato che $\mathbf{J}^2$ è un operatore hermitiano se $j\ne j'$ l'elemento di matrice considerato è non nullo, quindi una prima condizione è $j=j'$. Ragionando allo stesso modo per $J_z$ otteniamo la seconda regola di selezione $m=m'$. \\
Per un vettore il calcolo risulta un po' più complicato. Prendiamo ad esempio $\mathbf{r}\equiv \mathbf{r}(x,y,z)$. Sappiamo che $U(R)\mathbf{r}U^{-1}(R)=R_{ij}r_j$. Invece delle componenti cartesiane, risulta utile scrivere un generico vettore $\mathbf{v}$ usando le componenti $v_{+1},v_0,v_{-1}$ date da:
\begin{align}
v_{+1} &= -\frac{v_x+iv_y}{\sqrt{2}} \notag\;, \\
v_0 &= v_z \notag\;, \\
v_{-1} &= -\frac{v_x-iv_y}{\sqrt{2}}\;.
\end{align}
Notiamo che queste dipendenze sono le stesse delle armoniche sferiche $x\pm iy,z$, dunque $v_{+1},v_0,v_{-1}$ trasformeranno sotto rotazione come le armoniche sferiche:
\begin{equation*}
U(R)Y_{lm}(\mathbf{r})U^{-1}(R)=R^{(l)}_{m'm}Y_{lm}(\theta,\varphi)\;.
\end{equation*}
Scriviamo adesso gli elementi di matrice del generico operatore vettore $\mathbf{v}$:
\begin{equation}
\bra\beta,j',m'|v_q|\alpha,j,m\ket \qquad \qquad q=+1,0,-1\;.
\end{equation}
Posto $|\psi\ket=v_q|\alpha,j,m\ket$ si ha:
\begin{equation}
U(R)|\psi\ket=U(R)v_qU^{-1}(R)U(R)|\alpha,j,m\ket=R^{(1)}_{q'q}v_{q'}R^{(j)}_{m'm}|\alpha,j,m'\ket\;.
\end{equation}
$|\psi\ket$ può dunque avere momento angolare $j+1,j,j-1$ e $m'=m+q$. Quindi le regole di selezione saranno:
\begin{align}
j'&=j+1,j,j-1 \qquad \Longleftrightarrow \qquad \Delta j=j'-j=+1,0,-1 \notag\;, \\
m'&= m+q\;.
\end{align}
\begin{exm}
Vogliamo calcolare il valor medio di dipolo $\mathbf{d}=e\mathbf{x}$ sullo stato $|3p,m\ket$ dell'atomo di idrogeno. Usiamo le componenti $d_q$:
\begin{equation}
\bra nl,m'|d_q|3p,m\ket\;.
\end{equation}
Per quanto detto prima, $l$ può essere $0,1,2$ e $m'=m+q$. Dato che $\mathbf{d}$ è dispari e la parità di $|3p,m\ket$ è $(-1)^l=(-1)^1=-1$, cioè dispari, allora lo stato finale deve essere pari, quindi $l$ non può essere 1.
\end{exm}
Dopo gli scalari ($j=0$), i vettori ($j=1$), ci sono i tensori ($j=2$). Per i tensori si sfrutta il seguente:
\begin{thm}[Wigner-Eckart] Per un tensore di rango $k$, $T^{(k)}$, vale la seguente relazione:
\begin{equation}
\bra \beta,j',m'|T_q^{(k)}|\alpha,j,m\ket =A\cdot \mathcal{C}(j',m';kq,jm)\;,
\end{equation}
cioè l'elemento di matrice di $T^{(k)}$ è proporzionale al coefficiente di Clebsch-Gordan $\mathcal{C}(j',m';kq,jm)$ ($A$ è una costante).
\end{thm}
\chapter{Atomo di idrogeno}
\section{Soluzione generale}
Un atomo di idrogeno è costituito da un protone (massa $m_p$, carica $+e$) e un elettrone (massa $m_e$, carica $-e$). Il potenziale di interazione è Coulombiano, quindi l'Hamiltoniana dell'atomo di idrogeno sarà:
\begin{equation}
H=\frac{\mathbf{p}_1^2}{2m_p}+\frac{\mathbf{p}_2^2}{2m_e}-\frac{e^2}{|\mathbf{r}_1-\mathbf{r}_2|}\;.
\end{equation}
Ci aspettiamo che $\psi=\psi(\mathbf{r}_1,\mathbf{r}_2)$, cioè abbiamo sei gradi di libertà. Tuttavia, il sistema è invariante sotto traslazione, quindi si conserva l'impulso totale. Passando nelle coordinate del centro di massa:
\begin{align}
\mathbf{X}_{\mathrm{cm}}&=\frac{m_p\mathbf{r}_1+m_e\mathbf{r}_2}{m_p+m_e}\; \notag \\
\mathbf{r}&=\mathbf{r}_1-\mathbf{r}_2\;,
\end{align}
i cui impulsi coniugati sono:
\begin{align}
\mathbf{P}_{\mathrm{cm}}&=\mathbf{p}_1+\mathbf{p}_2\equiv\frac{\hbar}{i}\frac{\partial}{\partial\mathbf{X}_{\mathrm{cm}}}\;, \notag \\
\mathbf{p} &=\frac{\hbar}{i}\frac{\partial}{\partial\mathbf{r}}\;,
\end{align}
l'Hamiltoniana assume la forma:
\begin{equation}
H=\frac{\mathbf{P}_{\mathrm{cm}}^2}{2M}+\frac{\mathbf{p}^2}{2\mu}-\frac{e^2}{|\mathbf{r}|}\;,
\end{equation}
dove $M=m_p+m_e$ è la massa totale del sistema e $\mu=m_pm_e/(m_p+m_e)$ è la massa ridotta. In questa forma, l'Hamiltoniana è separabile, quindi $\Psi(\mathbf{X}_{\mathrm{cm}},\mathbf{r})=\exp(i\mathbf{P}_{\mathrm{cm}}\cdot\mathbf{X}_{\mathrm{cm}}/\hbar)\psi(\mathbf{r}$, in quanto la parte dipendente dalla coordinata del centro di massa è l'Hamiltoniana della particella libera. Allora l'equazione di \Sch\; sarà:
\begin{equation}
H\Psi=E_{\mathrm{tot}}\Psi\;, \qquad \qquad E_{\mathrm{tot}}=\frac{\mathbf{P}_{\mathrm{cm}}^2}{2M}+E\;,
\end{equation}
dove $E$ rappresenta l'energia nel sistema del centro di massa e corrisponde agli autovalori dell'Hamiltoniana:
\begin{equation}
H_r=\frac{\mathbf{p}^2}{2\mu}-\frac{e^2}{|\mathbf{r}|}\;.
\end{equation}
Dobbiamo quindi risolvere l'equazione:
\begin{equation}
-\frac{\hbar^2}{2\mu}\nabla^2\psi+V(r)\psi=E\psi\;.
\end{equation}
In coordinate polari si ha:
\begin{equation}
\nabla^2\equiv \frac{1}{r^2}\frac{\partial}{\partial r}r^2\frac{\partial}{\partial r}-\frac{\mathbf{L}^2}{r^2}\;.
\end{equation}
Allora l'Hamiltoniana $H_r$ è ulteriormente separabile in una parte radiale e una angolare, quindi $\psi(\mathbf{r})=R(r)f(\theta,\varphi)$. Sappiamo già che la parte angolare sarà proporzionale alle armoniche sferiche, quindi $\psi(\mathbf{r})=R(r)Y_{lm}(\theta,\varphi)$, con $\mathbf{L}^2Y_{lm}=l(l+1)Y_{lm}$. Sostituendo troviamo l'equazione per la funzione d'onda radiale:
\begin{equation}
-\frac{\hbar^2}{2\mu}\left[\frac{1}{r^2}\frac{\partial}{\partial r}r^2\frac{\partial}{\partial r}\right]R(r)+\left[\frac{\hbar^2l(l+1)}{2\mu r^2}+V(r)\right]R(r)=ER(r)\;.
\end{equation}
La condizione di normalizzazione per la $\psi$ è data da:
\begin{equation}
\int \diff^3{r}\;|\psi|^2=\int r^2\;\diff{r}\int \diff{\Omega}|R(r)|^2|Y_{lm}|^2=1\;.
\end{equation}
Essendo le armoniche sferiche già normalizzate, questa si riduce ad imporre:
\begin{equation}
\int_0^{+\infty}\diff{r}\;r^2|R(r)|^2=1\;.
\end{equation}
Se introduciamo la \textit{funzione d'onda radiale ridotta} $u(r)=rR(r)$, allora l'equazione diventa:
\begin{equation}
-\frac{\hbar^2}{2\mu}\dev[2]{u}{r}+V_{\mathrm{eff}}(r)u(r)=Eu(r)\;,
\end{equation}
dove:
\begin{equation}
V_{\mathrm{eff}}(r)=\frac{\hbar^2l(l+1)}{2\mu r^2}+V(r)\;,
\end{equation}
è il potenziale efficace. Le condizioni al bordo e di normalizzazione invece sono:
\begin{equation}
u(0)=0,\qquad\qquad \int_0^{+\infty} |u|^2\;\diff{r}=1\;,
\end{equation}
cioè ci siamo ridotti ad un problema standard unidimensionale nell'incognita $u(r)$. L'equazione completa è:
\begin{equation}
-\frac{\hbar^2}{2\mu}\dev[2]{u}{r}+\left[\frac{\hbar^2}{2\mu}\frac{l(l+1)}{r^2}-\frac{e^2}{r}\right]u=Eu\;.
\end{equation}
Se cerchiamo una soluzione $u=r^{\alpha}$, sostituendo troviamo le condizioni $\alpha=l+1$ e $\alpha=-l$. La seconda però non è accettabile come soluzione, in quanto non regolare. Otteniamo dunque che:
\begin{equation}
R=\frac{u}{r}\propto r^l\;.
\end{equation}
Passiamo in unità naturali (adimensionali) ponendo:
\begin{equation}
x=\frac{2r}{r_0}, \qquad \qquad r_0=\sqrt{\frac{\hbar^2}{2\mu|E|}}\;.
\end{equation}
Allora:
\begin{equation}
\dev[2]{u}{x}+\left(-\frac{1}{4}+\frac{A}{x}-\frac{l(l+1)}{x^2}\right)u=0, \qquad A=\frac{e^2}{2r_0|E|}\;.
\end{equation}
Per $x\to+\infty$, l'equazione diventa $u''=u/4$, che ammette come soluzioni esponenziali reali $e^{\pm x/2}$. Anche in questo caso, la soluzione $e^{x/2}$ va scartata in quanto non regolare. In definitiva, cerchiamo la soluzione della forma:
\begin{equation}
u(x)=x^{l+1}e^{-x/2}f(x)\;,
\end{equation}
con $f(x)$ che diverga al più come un polinomio, cioè:
\begin{equation}
f(x)=\sum_s \frac{a_s}{s!}x^s\;.
\end{equation}
Se la serie non si tronca, $f$ divergerà come un esponenziale, causando problemi a infinito. Quindi la serie deve necessariamente troncarsi. Sostituendo l'espressione di $u$ troviamo l'equazione per $f$:
\begin{equation}
xf''+f'(2+2l-x)+(A-l-1)f=0\;,
\end{equation}
e inserendo lo sviluppo di $f$ in serie di potenze, otteniamo la relazione di ricorrenza per i coefficienti $a_s$:
\begin{equation}
a_{s+1}=\frac{s+l+1-A}{(s+1)(s+2l+1)}a_s\;.
\end{equation}
Per troncarsi, dovrà essere $A=s+l+1$. Essendo sia $s$ che $l$ interi, otteniamo che $A$ deve essere un intero $n$ maggiore di 1 affinché la serie si tronchi. \\
L'indice $s$ per cui si tronca la serie è il grado massimo del polinomio. Tale indice viene indicato $n_r$, detto \textit{numero quantico radiale}, $n_r=0,1,2,\ldots$. Quindi la condizione su $A$ è $A=n=n_r+l+1$. Sostituendo quanto trovato, otteniamo per l'energia l'espressione:
\begin{equation}
|E|=\frac{1}{2}\frac{e^4\mu}{\hbar^2}\frac{1}{n^2}\;,
\end{equation}
ricordando che l'energia degli stati legati è negativa, e introducendo il \textit{raggio di Bohr}:
\begin{equation}
a_B=\frac{\hbar}{\mu e^2}\simeq 0.5\cdot 10^{-8}\;\mathrm{cm}\;,
\end{equation}
abbiamo
\begin{equation}
E=-\frac{1}{2n^2}\frac{e^2}{a_B^2}\;,
\end{equation}
per $n=1$, $e^2/2a_B\simeq 13.6$ $e$V, $e^2/a_B\simeq 27.2$ $e$V. Questa espressione, insieme al raggio di Bohr, costituiscono le unità fondamentali atomiche per l'energia e la lunghezza, cioè tutte le energie e tutte le lunghezze sono multipli rispettivamente di $e^2/a_B$ e $a_B$. Quindi l'energia si può scrivere:
\begin{equation}
E=-\frac{1}{2n^2}\;,
\end{equation}
sottointendendo $e^2/a_B$. Questo equivale a porre, nell'equazione di \Sch , $\hbar=\mu=e=1$. \\
Gli stati dovrebbero avere una degenerazione $2l+1$, ma dai risultati ottenuti, si ha che i livelli hanno in realtà una degenerazione pari a
\begin{equation}
\sum_{l=0}^{n-1}(2l+1)=n^2\;.
\end{equation}
Per scrivere adesso l'espressione delle autofunzioni, si usano i \textit{polinomi di Laguerre} nella variabile adimensionale $x=2r/na_B$, definiti da:
\begin{equation}
L_k(x)=e^x\frac{\diff^k}{\diff{x^k}}(x^ke^{-x})\;.
\end{equation}
I polinomi di Laguerre soddisfano l'equazione:
\begin{equation}
xL_k''+(1-x)L_k'+kL_k=0\;.
\end{equation}
Accanto ai polinomi di Laguerre, si introducono i \textit{polinomi di Laguerre generalizzati}:
\begin{equation}
L_k^{(j)}(x)=\frac{\diff^j}{\diff{x^j}}\left[e^x\frac{\diff^k}{\diff{x^k}}(x^ke^{-x})\right]\;,
\end{equation}
che verificano:
\begin{equation}
xL_k^{(j)''}+(j+1-x)L_k^{(j)'}+(k-j)L_k^{(j)}(x)=0\;,
\end{equation}
questa equazione è identica alla (9.1.21) per $f$, a patto che $j=2l+1$, $k=n+l$. Quindi, a meno di una costante di normalizzazione, si ha:
\begin{equation}
f(x)\propto L_{n+l}^{(2l+1)}(x)\;.
\end{equation}
Quindi:
\begin{align*}
R_{1s}&=\frac{c}{\sqrt{a_B^3}}e^{-r/a_B}\;, \\
R_{2s}&=\frac{c}{\sqrt{a_B^3}}e^{-r/2a_B}\left(1-\frac{r}{2a_B}\right)\;, \\
R_{2p}&=\frac{c}{\sqrt{a_B^3}}e^{-r/2a_B}\frac{r}{a_B}\;, \\
R_{3s}&=\frac{c}{\sqrt{a_B^3}}e^{-r/3a_B}(1+c_1+c_2r^2)\;,
\end{align*}
e via dicendo. In particolare, per $l=l_{\mathrm{max}}=n-1$:
\begin{equation}
R_{n,n-1}=\frac{c}{\sqrt{a_B^3}}e^{-r/na_B}\left(\frac{r}{a_B}\right)^{n-1}\;.
\end{equation}
A energia fissata, le orbite circolari classiche corrispondono a quelle con $l$ massimo. \\
Riassumendo, nell'atomo di idrogeno i livelli discreti hanno energie della forma:
\begin{equation}
E_n=-\frac{1}{2n^2}\mathcal{E},\qquad\qquad n=1,2,\ldots\;,
\end{equation}
con $\mathcal{E}_0=me^4/\hbar^2$ che rappresentà l'unità di energia atomica e $n=n_r+\ell+1$, dove $n_r$ è il numero di nodi della funzione d'onda radiale. Pertanto la degenerazione è sempre maggiore di $1$. Lo stato fondamentale $(n=1)$ ha energia:
\begin{equation}
-\frac{1}{2}\mathcal{E}\simeq -13.6\;\mbox{eV}\equiv -1\;\mbox{Ry}\;(\mbox{Rydberg})\;.
\end{equation}
I livelli dell'atomo di idrogeno si indicano mettendo prima il numero quantico principale $n$ e poi il momento angolare $\ell$: $n\ell$, con la convenzione:
\begin{align}
\ell=0 &\longrightarrow s \notag\;, \\
\ell=1 &\longrightarrow p \notag\;, \\
\ell=2 &\longrightarrow d \notag\;, \\
\ell=3 &\longrightarrow f \notag\;, \\
\ell=4 &\longrightarrow g\;.
\end{align}
La degenerazione degli stati è dovuta al fatto che, fissato $n$, tutti i valori di $\ell\le n-1$ sono possibili, e ogni $\ell$ ha degenerazione $2\ell+1$, quindi la degenerazione dell'$n$-esimo livello è:
\begin{equation}
\sum_{\ell=0}^{n-1} (2\ell+1)=n^2\;.
\end{equation}
Come si è visto prima, l'energia di $1s$ è $-13.6$ eV. Si dice anche che \textit{l'energia di ionizzazione} dello stato $1s$ è $+13.6$ eV. L'energia di ionizzazione è l'energia che bisogna fornire affinché un elettrone si liberi dallo stato legato. \\
Un'altra osservazione importante è che, dato che $V\equiv V(|\mathbf{x}_1-\mathbf{x}_2|)$, l'Hamiltoniana è invariante per parità e commuta con essa, quindi è sempre possibile scegliere gli autostati dell'Hamiltoniana in modo tale che siano autostati anche per la parità.
\section{Atomi idrogenoidi}
Tramite le considerazioni fatte, siamo in grado di risolvere il problema per un potenziale coulombiano di un nucleo con carica diversa da $+e$ (i.e. $+Ze$), a patto di considerare un solo elettrone. Il potenziale sarà quindi:
\begin{equation}
V(r)=-\frac{Ze^2}{r}\;.
\end{equation}
Avremo quindi un raggio effettivo $a(Z)=a_B/Z$ e le energie saranno:
\begin{equation}
E_n(Z)=-\frac{1}{2n^2}\mathcal{E}Z^2\;.
\end{equation}
Quindi il taglio dell'esponenziale diminuisce di un fattore $1/Z$ rispetto all'atomo di idrogeno e le energie aumentano di un fattore $Z^2$.
\section{Correzioni relativistiche}
Vogliamo adesso valutare le correzioni relativistiche, cioè il valore del fattore $v^2/c^2$, sperando che non siano grosse. Per far ciò, riprendiamo il teorema del viriale: se il potenziale è omogeneo di grado $\nu$, cioè se:
\begin{equation}
V(\lambda x)=\lambda^\nu V(x)\;,
\end{equation}
allora i valori medi dell'energia cinetica e di quella potenziale sono legati dalla relazione:
\begin{equation}
-2\bra T\ket+\nu\bra V\ket=0\;.
\end{equation}
Nel nostro caso, il potenziale è coulombiano, quindi $\nu=-1$, da cui segue:
\begin{equation}
\bra V\ket =-2\bra T \ket\;.
\end{equation}
Inoltre per gli stati legati dell'idrogeno si ha:
\begin{equation}
\bra T\ket+\bra V\ket=E=-\frac{1}{2n^2}\mathcal{E}\;.
\end{equation}
Combinando le due precedenti relazioni, si ottiene:
\begin{equation}
\bra T\ket=\frac{1}{2}\frac{\mathcal{E}}{n^2} \qquad \Longleftrightarrow \qquad \left\langle \frac{1}{2}mv^2\right\rangle=\frac{1}{2n^2}\frac{me^4}{\hbar^2}\;.
\end{equation}
Mettiamoci nel caso più disastroso possibile, cioè nello stato fondamentale ($n=1$):
\begin{equation}
\bra v^2\ket=\frac{e^4}{\hbar^2}\;,
\end{equation}
da cui:
\begin{equation}
\frac{\bra v^2\ket}{c^2}=\left(\frac{e^2}{\hbar c}\right)^2\;.
\end{equation}
La costante:
\begin{equation}
\alpha=\frac{e^2}{\hbar c}\;,
\end{equation}
prende il nome di \textit{costante di struttura fine} e vale circa $1/137$. Quindi si ha $v^2/c^2\sim 10^{-4}$, cioè i risultati che abbiamo ottenuto sono corretti a meno di una parte su $10^4$, che è un buon risultato. \\
Se invece il nucleo avesse avuto carica $+Ze$, la correzione sarebbe stata $(Z\alpha)^2$, quindi per i nuclei pesanti le correzioni relativistiche non saranno trascurabili. \\
Combinando ulteriormente le relazioni (9.3.3) e (9.3.4) ricaviamo anche:
\begin{equation}
\left\langle \frac{1}{r}\right\rangle =\frac{1}{n^2}\frac{1}{a_B}\;.
\end{equation}
\begin{quoting}
Se avessero scoperto prima l'atomo di idrogeno, avrebbero preso il raggio di Bohr come unità di misura delle lunghezze, non il metro conservato al museo.
\begin{flushright}
G.P.
\end{flushright}
\end{quoting}
È interessante valurare anche $\bra 1/r^2 \ket$. In unità atomiche:
\begin{align}
V_{\mathrm{eff}}&=-\frac{1}{r}+\frac{\ell(\ell+1)}{2r^2} \notag\;, \\
\pdev{V_{\mathrm{eff}}}{\ell} &= \frac{2\ell+1}{2r^2}\;.
\end{align}
Dal teorema di Hellmann-Feynman: se $H\equiv H(\lambda)$ ammette autovalori $E\equiv E(\lambda)$ allora:
\begin{equation}
\pdev{E(\lambda)}{\lambda}=\bra \lambda|\pdev{H}{\lambda}|\lambda \ket\;.
\end{equation}
Nel nostro caso gli autovalori dell'Hamiltoniana sono:
\begin{align}
E_n &=-\frac{1}{2}\frac{1}{(n_r+\ell+1)^2} \notag\;, \\
\pdev{E_n}{\ell}&=\frac{1}{(n_r+\ell+1)^3}=\frac{1}{n^3}\;,
\end{align}
e dunque:
\begin{equation}
\pdev{E}{\ell}=\frac{1}{n^3}=\left\langle \frac{2\ell+1}{2r^2}\right\rangle =\left\langle \pdev{H}{\ell}\right\rangle=\left\langle \pdev{V_{\mathrm{eff}}}{\ell} \right\rangle\;.
\end{equation}
Quindi otteniamo:
\begin{equation}
\left\langle \frac{1}{r^2} \right\rangle= \frac{2}{2\ell+1}\frac{1}{n^3}\;:
\end{equation}
Possiamo ricavare anche i valori medi per potenze superiori a $2$. Calcoliamo $\bra 1/r^3\ket$. Dall'equazione per la funzione d'onda radiale ridotta:
\begin{equation}
-\frac{1}{2}u''+Vu=Eu\;.
\end{equation}
Moltiplicando per $u'$ e integrando da $0$ a $\infty$:
\begin{align}
-\frac{1}{2}\int_0^{\infty} u'u''\;\diff{r}+\int_0^{\infty} Vuu'\;\diff{r} &= \int_0^{\infty} Euu'\;\diff{r}\;, \notag \\
-\frac{1}{2}\int_0^{\infty}\dev{(u^{'2})}{r}\;\diff{r}+\int_0^{\infty} V\dev{u^2}{r}\;\diff{r} &= \int_0^{\infty} E \dev{u^2}{r}\;\diff{r}\;.
\end{align}
Il secondo membro è nullo in quanto $u^2(0)=u^2(\infty)=0$. Deve quindi essere:
\begin{equation}
+\frac{1}{2}\int_0^{\infty} \dev{u^{'2}}{r}\;\diff{r}-\int_0^{\infty} V\dev{u^2}{r}\;\diff{r}=0\;.
\end{equation}
Integrando il secondo integrale per parti si ottiene:
\begin{equation}
\frac{1}{2}\int_0^{\infty} \dev{u^{'2}}{r}\;\diff{r}+\left. Vu^2\right|^{\infty}_0+\int_0^{\infty} \dev{V}{r}u^2\;\diff{r}=0\;.
\end{equation}
Il secondo addendo, per lo stesso motivo di prima, sarà nullo, mentre l'ultimo addendo rappresenta il valor medio di $\diff{V}/\diff{r}$. Quindi abbiamo:
\begin{equation}
\frac{1}{2}|u'(0)|^2-\left\langle\dev{V}{r}\right\rangle=0\;,
\end{equation}
dato che $u\sim r^{\ell+1}$, si ha $u'(0)=0$ per $\ell>0$, mentre per $\ell=0$ si ha:
\begin{equation}
\frac{u(r)}{r}=R(r)\;,
\end{equation}
che per $r\to 0$ tende a $u'(0)=R(0)$. In conclusione si ha:
\begin{equation}
\begin{cases}
\dfrac{1}{2}R^2(0)=\left\langle \dfrac{\diff{V}}{\diff{r}}\right\rangle \qquad \ell=0 \;,\\
\\
\left\langle\frac{\diff{V}}{\diff{r}}\right\rangle=0\qquad \ell>0\;.
\end{cases}
\end{equation}
Nel caso coulombiano, $V=-1/r$, $\partial V/\partial r=1/r^2$ per $\ell=0$, quindi:
\begin{equation}
R^2(0)=2\bra \frac{1}{r^2}\ket=\frac{4}{n^3}\;.
\end{equation}
Si ha inoltre:
\begin{equation}
|\psi(0)|^2=R^2(0)Y^2_{00}=\frac{1}{4\pi}R^2(0)=\frac{1}{\pi n^3}\;.
\end{equation}
Per $\ell\ne 0$:
\begin{align}
\left\langle \dev{V_{\mathrm{eff}}}{r}\right\rangle=\left\langle \frac{1}{r^2}-\frac{\ell(\ell+1)}{r^3}\right\rangle=0\;, \\
\left\langle \frac{\ell(\ell+1)}{r^3}\right\rangle=\left\langle \frac{1}{r^2}\right\rangle=\frac{2}{2\ell+1}\frac{1}{n^3}\;.
\end{align}
da cui:
\begin{equation}
\left\langle \frac{1}{r^3}\right\rangle= \frac{2}{\ell(\ell+1)(2\ell+1)}\frac{1}{n^3}\;.
\end{equation}
Un'altra osservazione interessante è la seguente: riprendendo le soluzione radiali con $\ell=0$:
\begin{equation}
R_{n,0}=ce^{-r/n}L^1_n\left(\frac{2r}{n}\right)\;.
\end{equation}
Si ha che i polinomi di Laguerre sono un set completo ortogonale rispetto alla misura $e^{-x}$:
\begin{equation}
\int_0^{\infty}e^{-x}L_k(x)L_n(x)\;\diff{x}=k\delta_{k,n}\;.
\end{equation}
I polinomi di Laguerre generalizzati invece non sono completi perché non comprenderebbero gli autostati dello spettro continuo, in quanto l'indice $n$ compare anche nella variabile. \\
\textbf{Esempio.} Consideriamo l'oscillatore armonico tridimensionale:
\begin{equation}
H=\frac{p_x^2}{2m}+\frac{p_y^2}{2m}+\frac{p_z^2}{2m}+\frac{1}{2}m\omega^2r^2\;.
\end{equation}
L'Hamiltoniana è separabile, quindi possiamo scrivere a colpo i livelli energetici:
\begin{equation}
E=E_1+E_2+E_3=\frac{3}{2}\hbar\omega +\hbar\omega(n_1+n_2+n_3)\;.
\end{equation}
Posto $n=n_1+n_2+n_3$, la degenerazione dei livelli è data da:
\begin{equation}
\binom{n+2}{2}=\frac{(n+2)!}{n! 2!}=\frac{(n+2)(n+1)}{2}\;.
\end{equation}
Per $n=0$, la degenerazione è 1 e:
\begin{equation}
\psi_{000}=e^{-\alpha r^2/2}\;,
\end{equation}
in quanto deve essere $n_1=n_2=n_3=0$ e i polinomi di Hermite di ordine zero è 1. Gli stati dell'oscillatore hanno una parità definita:
\begin{equation}
(-1)^{n_1+n_2+n_3}=(-1)^n\;.
\end{equation}
Quindi se $n$ è pari,compariranno solo gli $\ell$ pari. Stessa cosa per gli $n$ dispari.
\chapter{Teoria delle perturbazioni}
\section{Calcolo delle correzioni}
Data un'Hamiltoniana $H_0$ che sappiamo trattare (i.e. oscillatore armonico, idrogeno), vogliamo adesso studiare come cambiano gli autostati e i livelli energetici se perturbiamo il sistema con un termine $V$, cioè vogliamo studiare l'Hamiltoniana $H=H_0+V$ e valutare le correzioni rispetto al sistema non perturbato. \\
Chiamiamo $E_k$ i livelli energetici di $H_0$ (noti) e $\varphi_k$ i rispettivi autostati. Come sempre l'equazione da risolvere è quella di \Sch, $H\psi=E\psi$. Se non vi fosse la perturbazione, gli stati $\psi$ dovrebbero obbedire alla consueta equazione $H_0\varphi_i=E_i\varphi_i$. Quindi posso sviluppare in serie $\psi$ e $E$, gli stati e i livelli energetici perturbati, ricordando che all'ordine zero essi devono coincidere con quelli perturbati:
\begin{align}
\psi&=\psi^{(0)}+\psi^{(1)}+\psi^{(2)}+\cdots = \varphi_i+\psi^{(1)}+\psi^{(2)}+\cdots\;, \notag \\
E &= \varepsilon^{(0)}+\varepsilon^{(1)}+\varepsilon^{(2)}+\cdots=E_i+\varepsilon^{(1)}+\varepsilon^{(2)}+\cdots\;.
\end{align} 
Ci limiteremo a calcolare le correzioni fino al second'ordine. Sostituendo gli sviluppi nell'equazione, troviamo:

\begin{equation}
(H_0+V)(\varphi_1+\psi^{(1)}+\psi^{(2)}+\cdots)=(E_i+\varepsilon^{(1)}+\varepsilon^{(2)}+\cdots)\;.
\end{equation}
Visto che la normalizzazione è arbitraria, la scelgo in modo tale che $\psi^{(0)}=\varphi_i$, senza coefficienti, dove $\varphi_i$ è il nostro stato di partenza di cui andiamo a calcolare la correzione. In questo modo, si verifica che $\bra\varphi_i|\psi^{(k)}\ket=0$ per ogni $k\ne 0$. Facciamo inoltre l'ipotesi che lo stato di partenza $\varphi$ sia non degenere (il caso degenere verrà trattato in seguito). Sviluppando i prodotti e isolando tutti i termini di ordine zero, uno e due si ottengono le tre equazioni:
\begin{align}
&H_0\varphi_i = E_i\varphi_i &\mbox{all'ordine zero}\;, \notag \\
&H_0\psi^{(1)}+V\varphi_i = E_i\psi^{(1)}+\varepsilon^{(1)}\varphi_i &\mbox{al primo ordine} \notag\;, \\
&H_0\psi^{(2)}+V\psi^{(1)} = E_i\psi^{(2)}+\varepsilon^{(1)}\psi^{(1)}+\varepsilon^{(2)}\varphi_i &\mbox{al secondo ordine}\;.
\end{align}
L'equazione all'ordine zero è nota in partenza. Partiamo dal primo ordine. Le incognite sono $\psi^{(1)},\varepsilon^{(1)}$. Moltiplichiamo allora scalarmente l'equazione per $\bra i|\equiv \bra \varphi_i|$:
\begin{equation}
\bra i|\left(H_0|\psi^{(1)}\ket+V|i\ket\right)=E_i\bra i|\psi^{(1)}\ket+\varepsilon^{(1)}\bra i|i\ket\;.
\end{equation}
Dato che $\bra i|H_0|\psi^{(1)}\ket=E_i\bra i|\psi^{(1)}\ket$, poiché abbiamo imposto che $|i\ket$ sia ortogonale a tutti gli $|\psi^{(k)}\ket$ con $k\ne 0$, otteniamo immediatamente $\bra i|\psi^{(1)}\ket=0$ e quindi ricaviamo immediatamente:
\begin{equation}
\varepsilon^{(1)}=\bra i|V|i\ket\;,
\end{equation}
cioè la correzione del valore dell'energia del livello che stiamo considerando è data, al primo ordine, dal valor medio del termine perturbativo $V$ sullo stato iniziale (nell'ipotesi che il livello non sia degenere). \\
Per calcolare $|\psi^{(1)}\ket$ proiettiamo l'equazione su un qualunque stato $|k\ket\equiv |\varphi_k\ket$ con $k\ne i$:
\begin{equation*}
\bra k|\left(H_0|\psi^{(1)}\ket+V|i\ket\right)=E_i\bra k|\psi^{(1)}\ket+\varepsilon^{(1)}\bra k|i\ket\;.
\end{equation*}
L'ultimo termine è nullo in quanto $k\ne i$ e gli stati $|\varphi_n\ket$ sono un set completo ortogonale. Otteniamo quindi:
\begin{equation}
E_k\bra k|\psi^{(1)}\ket+\bra k|V|i\ket=E_i\bra k|\psi^{(1)}\ket\;,
\end{equation}
da cui:
\begin{equation}
(E_i-E_k)\bra k|\psi^{(1)}\ket=\bra k|V|i\ket= V_{ki}\;.
\end{equation}
Poiché gli autostai $|n\ket$ sono un set completo, possiamo scrivere $|\psi^{(1)}\ket$ come:
\begin{equation}
|\psi^{(1)}\ket=|i\ket+\sum_{k\ne i}c_k|k\ket\;.
\end{equation}
Perciò:
\begin{equation}
c_k=\bra k|\psi^{(1)}\ket=\frac{V_{ki}}{E_i-E_k}\;.
\end{equation}
In conclusione si ha per la correzione al primo ordine degli autostati:
\begin{equation}
|\psi^{(1)}\ket=\sum_{k\ne i} \frac{V_{ki}}{E_i-E_k}|k\ket\;.
\end{equation}
Passiamo adesso al secondo ordine proiettando la terza delle equazioni (10.1.3) su $|i\ket$:
\begin{equation*}
\bra i|H_0|\psi^{(2)}\ket+\bra i|V|\psi^{(1)}\ket=E_i\bra i|\psi^{(2)}\ket+\varepsilon^{(1)}\bra i|\psi^{(1)}\ket+\varepsilon^{(2)}\bra i|i\ket\;.
\end{equation*}
Nelle ipotesi di prima si ha $\bra i|H_0|\psi^{(2)}\ket=E_i\bra i|\psi^{(2)}\ket=0$ e $\varepsilon^{(1)}\bra i |\psi^{(1)}\ket=0$. Quindi si trova:
\begin{equation}
\varepsilon^{(2)}=\bra i|V|\psi^{(1)}\ket\;.
\end{equation}
Sostituendo a $|\psi^{(1)}\ket$ l'espressione (10.1.10):
\begin{equation}
\varepsilon^{(2)}=\sum_{k\ne i}\bra i|V\frac{V_{ki}}{E_i-E_k}|k\ket=\sum_{k\ne i}\frac{V_{ki}}{E_i-E_k}\bra i|V|k\ket=\sum_{k\ne i} \frac{V_{ki}V_{ik}}{E_i-E_k}=\sum_{k\ne i}\frac{|V_{ki}|^2}{E_i-E_k}\;.
\end{equation}
L'ultimo passaggio essendo valido in quanto $V_{ik}=V_{ki}^*$. Notiamo che se per $|i\ket$ prendiamo lo stato fondamentale, allora $E_i-E_k\le 0$ per ogni $k$, dunque al secondo ordine l'energia dello stato fondamentale decresce. \\
Adesso trattiamo il caso in cui il livello $|i\ket$ sia degenere (tratteremo solo le correzioni all'ordine zero). Si pone il problema della scelta dello $|\psi^{(0)}\ket$ da cui partire. Se il livello ha degenerazione $p$, possiamo scrivere:
\begin{equation}
|\psi^{(0)}\ket=\sum_{\alpha=1}^p c_{\alpha}|\alpha\ket\;,
\end{equation}
dove i $|\alpha\ket$ sono gli autostati relativi all'energia iniziale $E_i$. Allora l'equazione al primo ordine sarà:
\begin{equation}
H_0|\psi^{(1)}\ket+\sum_{\alpha} c_{\alpha} V|\alpha\ket=E_i|\psi^{(1)}\ket+\varepsilon^{(1)}\sum_{\alpha} c_{\alpha}|\alpha\ket\;.
\end{equation}
Proiettiamo questa su uno stato $|\beta\ket$:
\begin{equation}
\bra \beta|H_0|\psi^{(1)}\ket+\sum_{\alpha} c_{\alpha}\bra\beta|V|\alpha\ket=E_i\bra\beta|\psi^{(1)}\ket+\varepsilon^{(1)}\sum_{\alpha}c_{\alpha}\bra\beta|\alpha\ket=\varepsilon^{(1)}c_{\beta}\;.
\end{equation}
Quindi otteniamo l'equazione:
\begin{equation}
\sum_{\alpha} V_{\beta\alpha}c_{\alpha}=\varepsilon^{(1)}c_{\beta}\;,
\end{equation}
cioè $c_{\beta}$ è autovettore di $V$ con autovalore $\varepsilon^{(1)}$. In conclusione, per trovare le correzioni all'ordine zero nel caso di stato degenere, è sufficiente diagonalizzare la matrice $V$. \\
\\
Un calcolo alternativo valido sia nel caso non degenere che in quello degenere è il seguente: supponiamo che la nostra Hamiltoniana sia $H=H_0+\lambda V$ e sia $\mathcal{V}$ una varietà dello spazio di Hilbert con degenerazione $g$. Prediamo $\phi\in \mathcal{V}$, $\psi_{\perp}\in\mathcal{V}^{\perp}$ e poniamo $\psi=\phi+\psi_{\perp}$. L'equazione che vogliamo risolvere è al solito $H\psi=E\psi$, e trovare le correzioni ai livelli energentici $E=E_0+\delta E$. Sostituendo troviamo quindi:
\begin{align*}
H_0(\psi+\psi_{\perp})+\lambda V(\phi+\psi_{\perp}) &=E_0(\phi+\psi_{\perp})+\delta E(\phi+\psi_{\perp})\;, \\
H_0\psi_{\perp}+\lambda V\phi+\lambda V\psi_{\perp} &= E_0\psi_{\perp}+\delta E\phi+\delta E\psi_{\perp}\;.
\end{align*}
In quanto per ipotesi $H_0\phi=E_0\phi$. Siano adesso $|\varphi_{\alpha}\ket\equiv |\alpha\ket$ una base di $\mathcal{V}$ e $|\varphi_k\ket\equiv|k\ket$ una base di $\mathcal{V}^{\perp}$. Proiettiamo l'equazione su $\mathcal{V}^{\perp}$, ottenendo:
\begin{equation}
E_k\bra k|\psi_{\perp}\ket+\lambda\bra k|V|\phi\ket=E_0\bra k|\psi_{\perp}\ket\;,
\end{equation}
cioè:
\begin{equation}
|\psi_{\perp}\ket=\sum_k \lambda\frac{\bra k|V|\phi\ket}{E_0-E_k}|k\ket.
\end{equation}
Adesso proiettiamo su $\mathcal{V}$:
\begin{equation}
\lambda\bra\beta|V|\phi\ket+\lambda\bra\beta|V|\psi_{\perp}\ket=\delta E c_{\beta}\:,
\end{equation}
da cui sostituendo l'espressione di $|\psi_{\perp}\ket$ appena ottenuta:
\begin{equation}
\delta E c_{\beta}=\sum_{\alpha}\left[\lambda V_{\beta\alpha}c_{\alpha}+\lambda^2\sum_k\frac{V_{\beta\alpha}V_{k\alpha}}{E_0-E_k}c_{\alpha}\right]\equiv \sum_{\alpha} H^{\mathrm{eff}}_{\beta\alpha}c_{\alpha}\;,
\end{equation}
dove:
\begin{equation}
H^{\mathrm{eff}}_{\beta\alpha}=\lambda V_{\beta\alpha}+\lambda^2\sum_k\frac{V_{\beta\alpha}V_{k\alpha}}{E_0-E_k}\;,
\end{equation}
è una matrice $g\times g$ chiamata \textit{Hamiltoniana effettiva}. Otteniamo quindi per $\delta E$ e $c_{\beta}$ l'equazione agli autovalori:
\begin{equation}
\sum_{\alpha} H^{\mathrm{eff}}_{\beta\alpha}c_{\alpha}=\sum_{\alpha}\left[\lambda V_{\beta\alpha}+\lambda^2\sum_k \frac{V_{\beta\alpha}V_{k\alpha}}{E_0-E_k}\right]c_{\alpha}=\delta Ec_{\beta}\;.
\end{equation}
Il caso particolare non degenere si ottiene ponendo $g=1$. Per evitare conti allucinanti, è utile scegliere in partenza una base per cui $H^{\mathrm{eff}}$ sia già diagonale.
\section{Atomo di idrogeno}
L'Hamiltoniana di un generico atomo di valenza $Z$ con un solo elettrone è data da:
\begin{equation}
H_0=\frac{\mathbf{p}^2}{2m}-\frac{Ze^2}{r}\;,
\end{equation}
i cui livelli energetici sono:
\begin{equation}
E_n=-\frac{Z^2}{2n^2}\frac{e^2}{a(Z)} \qquad \qquad a_B=\frac{\hbar^2}{Zme^4}\;.
\end{equation}
È possibile perturbare questo sistema in due modi: o inserendo un campo elettrico (\textit{effetto Stark-Lo Surdo} \footnote{«Nell'ordine, un nazista e un fascista.» [cit. G.P.]}), o inserendo un campo magnetico (\textit{effetto Zeeman}).
\subsection{Effetto Zeeman}
Inserendo un campo magnetico $\mathbf{B}$ esterno, l'Hamiltoniana perturbata è, in termini del potenziale vettore $\mathbf{A}$:
\begin{equation}
H=\frac{1}{2m}\left(\mathbf{p}-\frac{e}{c}\mathbf{A}\right)^2+V(r)\;.
\end{equation}
Ci mettiamo nell'approssimazione che i campi esterni siano classici. Scegliamo $\mathbf{A}$ in modo tale che soddisfi la \textit{gauge di Coulomb} $\nabla\cdot\mathbf{A}=0$, ad esempio:
\begin{equation}
\mathbf{A}=\frac{1}{2}\mathbf{B}\wedge \mathbf{r}\;.
\end{equation}
Se $\nabla\cdot \mathbf{A}=0$, allora si verifica anche che $\mathbf{p}\cdot\mathbf{A}=\mathbf{A}\cdot\mathbf{p}$, quindi esplicitando l'Hamiltoniana si ha:
\begin{equation}
H=\frac{1}{2m}\left[\mathbf{p}^2-\frac{e}{c}(\mathbf{p}\cdot\mathbf{A}+\mathbf{A}\cdot\mathbf{p})+\frac{e^2}{c^2}\mathbf{A}^2\right]+V(r)\;,
\end{equation}
da cui (scartando i termini in $1/c^2$ in quanto siamo interessati al primo ordine in $1/c$) otteniamo:
\begin{equation}
H=\frac{\mathbf{p}^2}{2m}-\frac{e}{mc}\mathbf{p}\cdot\mathbf{A}+V(r)=H_0-\frac{e}{mc}\mathbf{p}\cdot\mathbf{A}\;.
\end{equation}
Il termine perturbativo è:
\begin{equation}
-\frac{e}{mc}\mathbf{p}\cdot\mathbf{A}=-\frac{e}{mc}\frac{1}{2}(\mathbf{B}\wedge\mathbf{r})\cdot\mathbf{p}=-\frac{e}{2mc}\mathbf{B}\cdot(\mathbf{r}\wedge\mathbf{p})=-\frac{e\hbar}{2mc}\mathbf{B}\cdot\mathbf{L}\;,
\end{equation}
che è denominato \textit{accoppiamento di momento magnetico}. Per un elettrone l'Hamiltoniana di interazione è:
\begin{equation}
H_I=\frac{|e|\hbar}{2m_ec}\mathbf{B}\cdot\mathbf{L}\equiv \mu_B\mathbf{B}\cdot\mathbf{L}\;,
\end{equation}
dove $\mu_B=|e|\hbar/(2m_ec)$ è il \textit{magnetone di Bohr}. \\
Se prendiamo adesso $\mathbf{B}=B\hat{\mathbf{z}}$, allora $H_I=\mu_BBL_z$, e pertanto la correzione al prim'ordine dello stato fondamentale dell'atomo di idrogeno è:
\begin{equation}
\bra 1s|\mu_BBL_z|1s\ket=0\;.
\end{equation}
Al secondo ordine invece l'energia è variata da $\hbar\omega_0$ a :
\begin{equation}
\hbar \omega=E_{2p}+\left[
\begin{matrix}
\mu_BB \\
0 \\
-\mu_BB
\end{matrix}\right]-E_{1s}=\hbar\omega_0+\left[
\begin{matrix}
\mu_BB \\
0 \\
-\mu_BB
\end{matrix}\right]\;.
\end{equation}
Quindi la variazione in frequenza è data da:
\begin{equation}
\Delta\omega=\omega-\omega_0=\frac{\mu_BB}{\hbar}=\frac{|e|B}{2mc}\;,
\end{equation}
che è la nota \textit{frequenza di ciclotrone} (o di Larmor). \\
Il problema adesso è che sperimentalmente non torna niente; infatti non abbiamo considerato lo spin: anch'esso avrà un accoppiamento del tipo $-\boldsymbol{\mu}\cdot\mathbf{B}$, dove $\boldsymbol{\mu}$ è il momento magnetico intrinseco dato da:
\begin{equation}
\boldsymbol{\mu}=\frac{|e|\hbar}{2mc}\mathbf{s}\;.
\end{equation}
Allora l'Hamiltoniana di interazione sarà della forma:
\begin{equation}
H_I=\frac{|e|\hbar}{2mc}\mathbf{B}\cdot\mathbf{L}+g\frac{|e|\hbar}{2mc}\mathbf{B}\cdot\mathbf{s}\;,
\end{equation}
dove $g$ è detto \textit{fattore giromagnetico} e per l'elettrone si è misurato sperimentalmente che $g\simeq 2$. \\
Il valore tipico del magnetone di Bohr è $\mu_B\simeq 5.8\times 10^{-5}$ eV/T. Sappiamo che le correzioni relativistiche erano, per $Z$ non troppo grandi, dell'ordine di $v^2/c^2\sim \alpha^2\sim 10^{-4}$. Visto che le energie in gioco con il campo magnetico sono tipicamente dell'ordine di $10^{-5}$ (nell'ipotetico caso di avere $|\mathbf{B}|=1$ T), dobbiamo innanzitutto cercare di tenere sotto controllo le correzioni relativistiche prima di applicare la teoria delle perturbazioni. \\
La correzione relativistica all'energia cinetica è:
\begin{equation}
T=\frac{\mathbf{p}^2}{2m}-\frac{1}{8}\frac{\mathbf{p}^4}{m^3c^2}\;,
\end{equation}
quindi l'Hamiltoniana corretta sarà per adesso:
\begin{equation}
H=H_0-\frac{1}{8}\frac{\mathbf{p}^4}{m^3c^2}+\frac{Ze^2\hbar^2}{2\pi m^2c^2}\delta^3(\mathbf{r})+\cdots\;,
\end{equation}
dove :
\begin{equation}
\frac{Ze^2\hbar^2}{2\pi m^2c^2}\delta^3(\mathbf{r})\;,
\end{equation}
è la correzione di Darwin (non si sa bene da dove salta fuori). Sia questa correzione che quella in $\mathbf{p}^4$ commutano con tutti i numeri quantici, quindi avranno unicamente l'effetto di spostare un po' i livelli energetici e quindi sono poco interessanti.\\
Dobbiamo adesso vedere se lo spin si accoppia, dando luogo a un termine aggiuntivo di interazione. Sappiamo che l'accoppiamento con un campo magnetico è $-\boldsymbol{\mu}\cdot\mathbf{B}$, ma il campo magnetico nel sistema che stiamo trattando sembra non esserci. Tuttavia, nel sistema di riferimento a riposo dell'elettrone è presente un campo magnetico dato dalle trasformazioni di Lorentz:
\begin{equation}
\mathbf{B}'=\mathbf{E}\wedge \frac{\mathbf{v}}{c}\;.
\end{equation}
Quindi possiamo scrivere il termine di accoppiamento di spin:
\begin{equation}
H_I=g\frac{e\hbar}{2mc}\mathbf{s}\cdot\left(\mathbf{E}\wedge \frac{\mathbf{v}}{c}\right)\;.
\end{equation}
Il campo elettrico dell'atomo è dato da:
\begin{equation}
\mathbf{E}=\frac{Ze}{r^3}\mathbf{r}\;,
\end{equation}
quindi sostituendo:
\begin{align}
H_I &=g\frac{Ze^2\hbar}{2mc^2}\frac{1}{r^3}\mathbf{s}\cdot(\mathbf{r}\wedge\mathbf{v})=g\frac{Ze^2\hbar}{2m^2c^2}\frac{1}{r^3}\mathbf{s}\cdot(\mathbf{r}\wedge\mathbf{p}) \notag \\
&=g\frac{Ze^2\hbar^2}{2m^2c^2}\frac{1}{r^3}\mathbf{s}\cdot\boldsymbol{\ell}\;.
\end{align}
Quindi possiamo scrivere l'Hamiltoniana con perturbazione:
\begin{equation}
H=H_0-\frac{1}{8}\frac{\mathbf{p}^4}{m^3c^2}+\frac{Ze^2\hbar^2}{2\pi m^2c^2}\delta^3(\mathbf{r})+g\frac{Ze^2\hbar^2}{2m^2c^2}\frac{1}{r^3}\mathbf{s}\cdot\boldsymbol{\ell}\;.
\end{equation}
Tuttavia, se applichiamo la teoria delle perturbazioni all'Hamiltoniana (10.2.21) otteniamo un risultato che è 2 volte quello che si ottiene sperimentalmente. Il problema sembra essersi originato dall'aver inserito il fattore giromagnetico $g=2$ nel termine di accoppiamento, ma se $g$ non vi fosse, non vi sarebbe accordo tra i risultati teorici e quelli sperimentali dell'effetto Zeeman. Ovviamente, c'è qualcosa che non abbiamo considerato. \\
\\
Una generica trasformazione di Lorentz si può scrivere (analogamente a quanto avevamo fatto con le rotazioni) come $e^{i\boldsymbol{\theta}\cdot\mathbf{J}+i\boldsymbol{\alpha}\cdot\mathbf{k}}$ dove $\alpha$ è la \textit{rapidità}, definita da $\tanh\alpha= v/c$ e $\mathbf{k}$ è il generatore infinitesimale dei boost, che soddisfa la seguente algebra:
\begin{equation}
[k_i,k_j]=-i\epsilon_{ijk}J_k\;.
\end{equation}
Consideriamo i due boost $\Lambda(\mathbf{v}+\delta\mathbf{v})$ e $\Lambda^{-1}(\mathbf{v})$ e verifichiamo se la loro composizione sia ancora un boost o vi sia anche un termine di rotazione. Posto $\boldsymbol{\alpha}'=\boldsymbol{\alpha}+\delta\boldsymbol{\alpha}$ si ha:
\begin{equation}
e^{i\boldsymbol{\alpha}'\cdot\mathbf{k}}e^{-i\boldsymbol{\alpha}\cdot\mathbf{k}}=e^{i\delta\boldsymbol{\alpha}\cdot\mathbf{k}+\frac{1}{2}[\boldsymbol{\alpha}\cdot\mathbf{k}',\boldsymbol{\alpha}\cdot\mathbf{k}]}\;.
\end{equation}
Osserviamo che:
\begin{equation}
\frac{1}{2}[\boldsymbol{\alpha}\cdot\mathbf{k}',\boldsymbol{\alpha}\cdot\mathbf{k}]=-\frac{i}{2}(\boldsymbol{\alpha}'\wedge\boldsymbol{\alpha})\cdot\mathbf{J}=-\frac{i}{2}(\delta\boldsymbol{\alpha}\wedge\boldsymbol{\alpha})\cdot\mathbf{J}+\frac{1}{2}(\boldsymbol{\alpha}\wedge\delta\boldsymbol{\alpha})\cdot\mathbf{J}\;.
\end{equation}
Quindi la composizione di due boost di Lorentz in generale è un boost unito ad una rotazione. Si ha in particolare:
\begin{equation}
\delta\boldsymbol{\theta}=\frac{1}{2c^2}\mathbf{v}\wedge\delta\mathbf{v}\quad \Longrightarrow \quad \boldsymbol{\omega}_T=\frac{1}{2c^2}\mathbf{v}\wedge\mathbf{a}\;,
\end{equation}
dove $\mathbf{a}$ è l'accelerazione, $\mathbf{a}=-e\mathbf{E}/m$. L'Hamiltoniana di interazione sarà quindi $H_I=-\hbar\boldsymbol{\omega}_T\cdot\mathbf{s}$. Inoltre notiamo che:
$$
\hbar\boldsymbol{\omega}_T=\frac{\hbar^2}{2mc^2}\mathbf{v}\wedge\left(-\frac{e\mathbf{E}}{m}\right)=-\frac{e\hbar}{2mc^2}\frac{Ze}{r^3}(\mathbf{v}\wedge\mathbf{r})=\frac{e^2\hbar^2Z}{2m^2c^2}\frac{1}{r^3}\boldsymbol{\ell}\;,
$$
cioè:
\begin{equation}
H_I=-\frac{Ze^2\hbar^2}{2m^2c^2}\frac{1}{r^3}\boldsymbol{\ell}\cdot\mathbf{s}\;.
\end{equation}
In conclusione, l'Hamiltoniana completa con le perturbazioni è:
\begin{equation}
H=H_0-\frac{1}{8}\frac{\mathbf{p})^4}{m^3c^2}+\frac{Ze^2\hbar^2}{2\pi m^2c^2}\delta^3(\mathbf{r})+(g-1)\frac{Ze^2\hbar^2}{2m^2c^2}\frac{1}{r^3}\boldsymbol{\ell}\cdot\mathbf{s}\;,
\end{equation}
dove l'ultimo termine viene chiamato \textit{accoppiamento} $\ell-s$. \\
\\
Per il livello $1s$ si ha:
$$
\psi=R_{1s}(r)Y_{0,0}(\theta,\varphi)\begin{cases}
|+\ket\;, \\
|-\ket\;.
\end{cases}
$$
Per semplificare i conti, notiamo che:
\begin{equation*}
\frac{\mathbf{p}^2}{2m}=E_n+\frac{Ze^2}{r}\;,
\end{equation*}
allora:
\begin{equation}
\bra n\ell|\frac{1}{8}\frac{\mathbf{p}^4}{m^3c^2}|n\ell\ket=-\frac{1}{2mc^2}\bra n\ell|\left(E_n+\frac{Ze^2}{r}\right)^2|n\ell\ket\;,
\end{equation}
e si possono eseguire agilmente i conti. \\
\\
Per il $2p$, notiamo che il termine di accoppiamento $\ell-s$ commuta con $\boldsymbol{\ell}^2,\mathbf{s}^2$ e con tutte le componenti di $\mathbf{j}$. Quindi conviene usare come base gli autostati di $\mathbf{j}^2$ e $j_z$, in modo che la matrice della perturbazione si spezzi in un blocco $4\times 4$ con $j=3/2$ e un blocco $2\times 2$ con $j=1/2$. Poiché $H_I$ commuta con tutte le componenti di $\mathbf{j}$ dal teorema di Wigner-Eckart segue che entrambi i blocchi sono multipli dell'identità, quindi:
\begin{equation}
H_I=\left(\begin{matrix}
3/2 & 0 & 0 & 0 & 0 & 0 \\
0 & 3/2 & 0 & 0 & 0 & 0 \\
0 & 0 & 3/2 & 0 & 0 & 0 \\
0 & 0 & 0 & 3/2 & 0 & 0 \\
0 & 0 & 0 & 0 & 1/2 & 0 \\
0 & 0 & 0 & 0 & 0 & 1/2
\end{matrix}\right)\;.
\end{equation}
Quindi il livello $2p$ si splitta in due livelli (\textit{struttura fine}): $2p_{3/2},2p_{1/2}$. Per calcolare $\boldsymbol{\ell}\cdot\mathbf{s}$ notiamo che $(\boldsymbol{\ell}+\mathbf{s})^2=\mathbf{j}^2$, quindi:
\begin{equation}
\boldsymbol{\ell}\cdot\mathbf{s}=\frac{\mathbf{j}^2-\boldsymbol{\ell}^2-\mathbf{s}^2}{2}\;.
\end{equation}
Poiché $\boldsymbol{\ell}$ e $\mathbf{s}$ sono fissati, l'unico fattore che discrimina i due livelli è l'autovalore di $\mathbf{j}^2$, cioè $j(j+1)$. \\
\\
Tornando all'effetto Zeeman, in presenza di un campo magnetico $\mathbf{B}=B\hat{\mathbf{z}}$ si ha:
\begin{equation}
H_I=\frac{e\hbar}{2mc}(\boldsymbol{\ell}+2\mathbf{s})\cdot\mathbf{B}=\frac{e\hbar}{2mc}(\ell_z+2s_z)B\;.
\end{equation}
Applico la teoria delle perturbazioni ai livelli della struttura fine: $2p_{1/2},2p_{3/2},2s_{1/2}$. I numeri quantici sono $|n,\ell,s,j,j_z\ket$. Per il teorema di Wigner-Eckart, sappiamo che all'interno di una rappresentazione irriducibile i vettori sono proporzionali a $\mathbf{j}$, quindi:
\begin{equation}
\mathbf{s}=c\mathbf{j}\quad \Longrightarrow \quad \mathbf{s}\cdot\mathbf{j}=c\mathbf{j}^2\quad \Longrightarrow\quad c=\frac{\mathbf{s}\cdot\mathbf{j}}{\mathbf{j}^2}\;.
\end{equation}
Dato che:
\begin{equation}
\mathbf{j}\cdot\mathbf{s}=\frac{\mathbf{j}^2+\mathbf{s}^2-\boldsymbol{\ell}^2}{2}\;.
\end{equation}
Si ha (ricordando che $l_z+2s_z=l_z+s_z+s_z=j_z+s_z$):
\begin{equation}
H_I=\frac{e\hbar}{2mc}(j_z+s_z)B=\mu_BBj_z\left(1+\frac{j(j+1)+s(s+1)-\ell(\ell+1)}{2j(j+1)}\right)\;,
\end{equation}
dove:
\begin{equation}
g_j\equiv 1+\frac{j(j+1)+s(s+1)-\ell(\ell+1)}{2j(j+1)}\;,
\end{equation}
è il \textit{fattore giromagnetico di Landé}. \\
Adesso il termine perturbativo $H_I$ è diagonale, e dunque i livelli energetici perturbati saranno:
\begin{equation}
E=E_0+\mu_BBg_jj_z\;.
\end{equation}
\section{Perturbazioni dipendenti dal tempo}
Supponiamo adesso di perturbare il sistema descritto inizialmente dall'Hamiltoniana $H_0$ con un termine $V(t)$ dipendente dal tempo, assumendo che all'istante iniziale $t=t_0$ lo stato iniziale $|\psi(t_0)\ket\equiv |0\ket$ verifichi l'equazione $H_0|0\ket=E_0|0\ket$. L'insieme $\{|k\ket\}$ degli autostati di $H_0$ è completo, quindi al generico istante $t$ la funzione d'onda può essere scritta come:
\begin{equation}
|\psi(t)\ket=\sum_k c_k(t)|k\ket\;.
\end{equation}
La probabilità che, partendo da $|0\ket$, si abbia all'istante $t$ un altro autostato $|f\ket$ di $H_0$ è $|\bra f|\psi(t)\ket|^2=P_f(t)$. I coefficienti $c_k$ possono essere fattorizzati come:
\begin{equation}
c_k(t)=e^{-iE_kt/\hbar}a_k(t)\;,
\end{equation}
dove il termine esponenziale è presente indipendentemente dalla perturbazione, in quanto descrive l'evoluzione temporale normale. Quindi:
\begin{equation}
|\psi(t)\ket=\sum_k e^{-iE_kt/\hbar}a_k(t)|k\ket\;,
\end{equation}
che sostituita nell'equazione di \Sch\; $i\hbar\partial_t\psi=(H_0+V)\psi$ restituisce:
\begin{equation}
\sum_s(i\hbar\dot{a}_s(t)+E_sa_s(t)e^{-iE_st/\hbar})|s\ket=\sum_s a_s(t)E_se^{-iE_st/\hbar}|s\ket+\sum_sa_s(t)e^{-iE_st/\hbar}V|s\ket\;.
\end{equation}
Eliminando i termini uguali e proiettando su $|k\ket$ generico autostato di $H_0$ otteniamo:
\begin{equation*}
i\hbar\dot{a}_k(t)e^{-iE_kt/\hbar}=\sum_s a_s(t)e^{-iE_st/\hbar}\bra k|V|s\ket\;,
\end{equation*}
cioè:
\begin{equation}
i\hbar \dot{a}_k(t)=\sum_s V_{ks}e^{i(E_k-E_s)t/\hbar}a_s(t)\;.
\end{equation}
Supponiamo di conoscere $a_k(0)$ e poniamo:
\begin{equation}
a_k(0)=\begin{cases}
1\qquad \mbox{se}\;k=0\;, \\
\\
0\qquad \mbox{se}\;k\ne 0\;.
\end{cases}
\end{equation}
Adesso trasformiamo il problema differenziale in uno integrale: posto $\tilde{V}_{ks}(t)=V_{ks}(t)e^{i(E_k-E_s)t/\hbar}$, vale la relazione (per un generico valore $a_k(0)=b_k$):
\begin{equation}
a_k(t)=b_k-\frac{i}{\hbar}\sum_s\int_{t_0}^t\tilde{V}_{ks}(t)a_s\;\diff{t}\;.
\end{equation}
Possiamo risolvere questo problema ricorsivamente: se $a_k^{(n)}(t)$ è l'approssimazione all'ordine $n$ della soluzione, allora:
\begin{equation}
a_k^{(n+1)}(t)=b_k-\frac{i}{\hbar}\sum_s\int_{t_0}^t\tilde{V}_{ks}a_s^{(n)}(t)\;\diff{t}\;.
\end{equation}
In prima approssimazione, essendo $a_k^{(0)}=b_k$:
\begin{equation}
a_k(t)=b_k-\frac{i}{\hbar}\sum_s\int_{t_0}^t \tilde{V}_{ks}b_s\;\diff{t}\;.
\end{equation}
Siamo interessati ai $k\ne 0$, quindi (ricordando che $b_s=1$ per $s=0$ e $b_s=0$ per $s\ne 0$):
\begin{equation}
a_k(t)=-\frac{i}{\hbar}\int_{t_0}^t \tilde{V}_{k0}(t')\;\diff{t'}\;.
\end{equation}
Possiamo supporre che $V$ sia costante ($\tilde{V}$ ovviamente non lo è perché contiene la fase), cioè $\tilde{V}_{ks}=V_{ks}e^{i(E_k-E_s)t/\hbar}$. Otteniamo pertanto, ponendo $t_0=0$:
\begin{equation}
a_k(t)=-\frac{i}{\hbar}V_{k0}\int_0^t e^{i(E_k-E_0)t'/\hbar}\;\diff{t'}=-\frac{i}{\hbar}V_{k0}\frac{e^{i(E_k-E_0)t/\hbar}-1}{\frac{i}{\hbar}(E_k-E_0)}\;.
\end{equation}
Quindi la probabilità di cambiare stato è:
\begin{equation}
|a_k(t)|^2=\frac{\frac{1}{\hbar^2}|V_{k0}|^24\sin^2(\omega_{k0}t/2)}{\omega_{k0}^2}=\frac{4|V_{k0}|^2\sin^2(\omega_{k0}t/2)}{\hbar^2\omega_{k0}^2}\;,
\end{equation}
dove $\omega_{k0}=(E_k-E_0)/\hbar$.
Se $|V_{k0}|^2\gg \hbar^2\omega_{k0}^2$, cioè
\begin{quoting}
«Ci metto una bestia di campo magnetico.»
\begin{flushright}
G.P.
\end{flushright}
\end{quoting}
riusciamo comunque a risolvere senza problemi. I problemi invece saltano fuori come i funghi quando $|k\ket$ non appartiene allo spettro discreto. \\
La funzione $|a_k(t)|^2$ ha una larghezza tipica $\delta l=2\pi/\omega_{k0}$ e, per $t\to\infty$ (cioè dopo la fase transiente):
\begin{equation}
\lim_{t\to\infty}\frac{\sin^2(xt)}{x^2}=\pi t\delta(x)\;.
\end{equation}
Quindi:
\begin{align}
P_k(t)&=|a_k(t)|^2\to \frac{|V_{k0}|^2}{\hbar^2}\pi t\delta\left(\frac{\omega_{k0}}{2}\right) \notag \\
&=\frac{1}{\hbar^2}|V_{k0}|^2\pi t\delta\left(\frac{E_k-E_0}{2\hbar}\right) \notag \\
&= \frac{1}{\hbar^2}|V_{k0}|^2\pi t 2\hbar\delta(E_k-E_0) \notag \\
&=\frac{2\pi}{\hbar}|V_{k0}|^2\delta(E_k-E_0) \cdot t\;.
\end{align}
Da questa espressione si ottiene la \textit{regola d'oro di Fermi}:
\begin{equation}
\dev{P_k}{t}=\frac{2\pi}{\hbar}|V_{k0}|^2\delta(E_k-E_0)\;.
\end{equation}
Moltiplicando questa espressione per $\rho(E)\diff{E}$ (dove $\rho(E)$ è la densità degli stati) otteniamo la probabilità differenziale per unità di tempo (adesso stiamo trattando $E$ come una variabile continua):
\begin{equation}
\diff{\gamma}=\frac{2\pi}{\hbar}|V_{E,0}|^2\delta(E-E_0)\rho(E)\diff{E}\;.
\end{equation}
Integrando su $E$ otteniamo:
\begin{equation}
\gamma=\frac{2\pi}{\hbar}|V_{00}|^2\rho(E_0)\;,
\end{equation}
che rappresenta la probabilità totale per unità di tempo di decadere dallo stato $|0\ket$. La probabilità per unità di tempo di decadere nello stato $|s\ket$ è invece data da:
\begin{equation}
\gamma_s=\frac{2\pi}{\hbar}|\bra s|V|0\ket|^2\delta(E_s-E_0)\;.
\end{equation}
Ci aspettiamo che $\gamma=\sum_s \gamma_s$, dobbiamo quindi verificare che la definizione epistemica della probabilità concordi con quella quantistica (ossia, il modulo quadro della funzione d'onda).
\section{Rappresentazione di interazione}
In generale, possiamo scrivere:
\begin{equation}
|\psi(t)\ket=\sum_k a_k(t)e^{-iE_kt/\hbar}|k\ket\equiv e^{-iH_0t/\hbar}|\varphi(t)\ket\;,
\end{equation}
passando così dalla rappresentazione di \Sch\; a quella di interazione. La funzione:
\begin{equation}
|\varphi(t)\ket=e^{iH_0t/\hbar}|\psi(t)\ket\;,
\end{equation}
è incognita. Un generico operatore $A$ si scriverà, in rappresentazione di interazione:
\begin{equation}
\tilde{A}=e^{iH_0t/\hbar}Ae^{-iH_0t/\hbar}\;.
\end{equation}
Allora:
\begin{align}
i\hbar\frac{\partial}{\partial t}|\varphi(t)\ket &= -H_0|\varphi(t)\ket+e^{iH_0t/\hbar}(H_0+V)|\psi(t)\ket \notag \\
&= -H_0|\varphi(t)\ket+e^{iH_0t/\hbar}(H_0+V)e^{-iH_0t/\hbar}|\varphi(t)\ket \notag \\
&= -H_0|\varphi(t)\ket+H_0|\varphi(t)\ket+e^{iH_0t/\hbar}Ve^{-iH_0t/\hbar}|\varphi(t)\ket \notag \\
&= \tilde{V}|\varphi(t)\ket \qquad\qquad \tilde{V}=e^{iH_0t/\hbar}Ve^{-iH_0t/\hbar}\;.
\end{align}
Quindi, per quanto visto:
\begin{equation}
|\varphi(t)\ket=|\varphi(t_0)\ket-\frac{i}{\hbar}\int_{t_0}^t\tilde{V}|\varphi(t)\ket\diff{t}=|0\ket-\frac{i}{\hbar}\int_{t_0}^t\tilde{V}(t)|\varphi(t)\ket\;\diff{t}\;.
\end{equation}
La cui soluzione (al secondo ordine) è:
\begin{equation}
|\varphi(t)\ket=|0\ket-\frac{i}{\hbar}\int_0^t\tilde{V}(t_1)|0\ket\;\diff{t}_1+\left(\frac{i}{\hbar}\right)^2\int_0^t\diff{t}_1\tilde{V}(t_1)\int_0^{t_1}\tilde{V}(t_2)|0\ket\;\diff{t}_2+\cdots\;.
\end{equation}
Introducendo il \textit{prodotto T-ordinato}:
\begin{equation}
T\left(A(t_1)A(t_2)\right)=\begin{cases}
A(t_1)A(t_2) \qquad t_1>t_2\;, \\
\\
A(t_2)A(t_1) \qquad t_1<t_2\;.
\end{cases}
\end{equation}
Si ha formalmente la \textit{serie di Dyson}:
\begin{equation}
|\varphi(t)\ket=T\left[\exp\left(-\frac{i}{\hbar}\int_0^t\stackrel{\sim}{V}(\tau)\diff{\tau}\right)\right]|0\ket\;.
\end{equation}
\begin{quoting}
«La serie di Dyson è un tentativo di tradurre nel linguaggio degli umani i diagrammi di Feynman.»
\end{quoting}
\begin{flushright}
G.P.
\end{flushright}
\section{Adiabatic switching}
Supponiamo adesso che la perturbazione sia $V\to Ve^{\eta t}$, $\eta>0$, così che $V\to 0$ per $t\to t_0\equiv -\infty$. Al primo ordine si ha:
\begin{equation}
\bra k|\varphi(t)\ket\equiv a_k=-\frac{i}{\hbar}\int_{-\infty}^t V_{k0}e^{i(E_k-E_0)t'/\hbar+\eta t'}\diff{t}'=
-\frac{i}{\hbar}\frac{e^{i\omega_{k0}t+\eta t}}{i\omega_{k0}+\eta}V_{k0}\;,
\end{equation}
da cui:
\begin{equation}
P_k=|a_k|^2=\frac{|V_{k0}|^2}{\hbar^2}\frac{e^{2\eta t}}{\omega_{k0}^2+\eta^2}\;.
\end{equation}
Derivando rispetto al tempo si ottiene:
\begin{equation}
\dot{P}_k=\frac{|V_{k0}|^2}{\hbar^2}\frac{2\eta e^{2\eta t}}{\omega_{k0}^2+\eta^2}\;.
\end{equation}
Ricordando il limite notevole:
\begin{equation}
\lim_{y\to 0}\frac{y}{x^2+y^2}=\pi\delta(x)\;,
\end{equation}
si ha, per $\eta\to 0$:
\begin{equation}
\lim_{\eta\to 0}\dot{P}_k=\frac{2\pi}{\hbar}|V_{k0}|^2\delta(E_k-E_0)\;.
\end{equation}
Proiettiamo adesso sullo stato iniziale l'equazione (10.4.4):
\begin{equation}
i\hbar\frac{\partial}{\partial t}\bra 0|\varphi(t)\ket=\bra 0|\stackrel{\sim}{V}|\varphi(t)\ket=
\bra 0|\stackrel{\sim}{V}|0\ket\bra 0|\varphi(t)\ket+\sum_{s\ne 0}\bra 0|\stackrel{\sim}{V}|s\ket\bra s|\varphi(t)\ket\;,
\end{equation}
dividiamo per $\bra 0|\varphi(t)\ket$ otteniamo correttamente a meno di termini cubici:
\begin{align}
i\hbar\frac{\partial}{\partial t}\ln(\bra 0|\varphi(t)\ket)&\simeq \bra 0|\stackrel{\sim}{V}|0\ket+\sum_{s\ne 0}\bra 0|\stackrel{\sim}{V}|s\ket\bra s|\varphi(t)\ket \notag \\
&=\bra 0|\stackrel{\sim}{V}|0\ket+\sum_{s\ne 0}e^{i(E_0-E_s)t/\hbar}V_{0s}\left(-\frac{i}{\hbar}\right)\frac{e^{i(E_0-E_s)t/\hbar+\eta t}}{i(E_s-E_0)+\eta}V_{s0} \notag \\
&=\stackrel{\sim}{V}_{00}+\frac{1}{\hbar}\sum_{s\ne 0}\frac{|V_{0s}|^2}{\frac{E_0-E_s}{\hbar}+\eta} \notag \\
&=\stackrel{\sim}{V}_{00}+\sum_{s\ne 0}\frac{|V_{0s}|^2}{(E_0-E_s)+i\varepsilon}\;,
\end{align}
dove $\varepsilon=\hbar\eta$. Per $\varepsilon\to 0$ si ha, nel senso delle distribuzioni:
\begin{equation}
i\hbar\frac{\partial}{\partial}\ln(\bra 0|\varphi(t)\ket\to V_{00}+\sum_{s\ne 0}\operatorname{PV}\left(\frac{|V_{0s}|^2}{E_0-E_s}\right)-i\pi\sum_s \delta(E_s-E_0)|V_{0s}|^2\equiv \Delta E-i\frac{\Gamma}{2}\;.
\end{equation}
Quindi l'equazione per $a_0$ è:
\begin{equation}
i\hbar\frac{\partial}{\partial t}a_0=\Delta E -i\frac{\Gamma}{2}\qquad \Longrightarrow \qquad a_0=e^{-i\Delta Et/\hbar-\Gamma t/2\hbar}\;.
\end{equation}
Dato che avevamo calcolato:
\begin{equation*}
\gamma_s=\frac{2\pi}{\hbar}\delta(E_s-E_0)|V_{0s}|^2\;,
\end{equation*}
si ha:
\begin{equation}
-i\pi\sum_s\delta(E_0-E_s)|V_{0s}|^2=-i\frac{\hbar}{2}\sum_s\gamma_s=-\frac{i\hbar \gamma}{2}\;,
\end{equation}
quindi:
\begin{equation}
P_0=|a_0|^2=e^{-\gamma t}\;,
\end{equation}
da cui si ricava che $\gamma=1/\tau$, dove $\tau$ è la \textit{vita media} dello stato.\\
Sostituendo adesso il valore di $a_0$ appena ricavato nella (10.3.10) si ottiene:
\begin{equation}
a_k=-\frac{i}{\hbar}\int_0^t\stackrel{\sim}{V}_{k0}\;\diff{t}\cdot a_0=-\frac{i}{\hbar}\int_0^t e^{i(E_k-E_0)t/\hbar} V_{k0} e^{-i(E_k-E_0)t/\hbar} e^{-i\Delta Et/\hbar-\gamma t/2}\diff{t}\;.
\end{equation}
Posto $\stackrel{\sim}{\omega}_{k0}=(E_k-E_0-\Delta E)/\hbar$ si ha:
\begin{align}
a_k &= -\frac{i}{\hbar}\frac{e^{i\stackrel{\sim}{\omega}_{k0}t-\gamma t/2}-1}{i\stackrel{\sim}{\omega}_{k0}-\gamma/2}V_{k0} \notag \\
P_k(t)&= |a_k|^2=\frac{1}{\hbar^2}\frac{1+e^{-\gamma t}-2\cos(\stackrel{\sim}{\omega}_{k0}t)e^{-\gamma t/2}}{\stackrel{\sim}{\omega}_{k0}^2+\gamma^2/4}|V_{k0}|^2\;.
\end{align}
Il termine in coseno si annulla mediando sul periodo, quindi in definitiva:
\begin{equation}
P_{\alpha,E}=\frac{1}{\hbar^2}\frac{1-e^{-\gamma t}}{\stackrel{\sim}{\omega}_{\alpha 0}^2+\gamma^2/4}|V_{\alpha 0}|^2\rho_{\alpha}(E)\diff{E}\;.
\end{equation}
Per $t\gg 1/\gamma$ ($\Gamma=\hbar\gamma$):
\begin{equation}
P_{\alpha,E}=\frac{1}{(E-\stackrel{\sim}{E}_0)^2+\Gamma^2/4}|V_{\alpha 0}|^2\rho_{\alpha}(E)\diff{E}=|V_{\alpha 0}(\stackrel{\sim}{E}_0)|^2\rho(\stackrel{\sim}{E}_0)\frac{\diff{E}}{(E-\stackrel{\sim}{E}_0)^2+\Gamma^2/4}\;.
\end{equation}
La distribuzione di probabilità in frequenza dei fotoni emessi è quindi una Lorentziana, la cui larghezza a metà altezza è $\Gamma/2$. \\
Un altro modo di risolvere il problema è moltiplicare l'operatore $e^{-iHt/\hbar}$ per la funzione di Heavyside, ottendendo la funzione di Green $K(t)=\theta(t)e^{iHt/\hbar}$. In trasformata di Fourier:
\begin{equation}
K(t)=\frac{i}{2\pi}\int_{-\infty}^{+\infty}\frac{e^{-iEt/\hbar}}{E-H+i\varepsilon}\diff{E}\;.
\end{equation}
L'integrando presenta un polo per $E=H-i\varepsilon$. Per il lemma di Jordan, per $t<0$ l'espressione è nulla, in accordo con la presenza della $\theta(t)$. Per $t>0$, calcolando il residuo otteniamo proprio $e^{-iHt/\hbar}$, quindi l'espressione è effettivamente corretta. Poniamo adesso:
\begin{equation}
G(E)=\frac{1}{E-H+i\varepsilon},\qquad H=H_0+V\;.
\end{equation}
Se $V=0$, abbiamo la funzione di Green libera:
\begin{equation}
G_0(E)=\frac{1}{E-H_0+i\varepsilon}\;.
\end{equation}
Notando che:
\begin{equation}
G(E)-G_0(E)=\frac{1}{E-H+i\varepsilon}-\frac{1}{E-H_0+i\varepsilon}=\frac{V}{(E-H_0+i\varepsilon)(E-H+i\varepsilon)}\;,
\end{equation}
dobbiamo calcolare $\bra 0|G(E)|0\ket\equiv G_{00}(E)$ (contribuiscono solo i poli).
\section{Perturbazioni esplicitamente dipendenti dal tempo}
Data l'Hamiltoniana $H=H_0+V(t)$, l'espressione della probabilità di transizione da un autostato di $H_=$ $|i\ket$ a un altro autostato $|f\ket$ è:
\begin{equation}
P_{i\to f}=\frac{1}{\hbar^2}\left|\int_{t_i}^{t_f} V_{fi}(t)e^{i\omega_{fi}t}\diff{t}\right|^2\;.
\end{equation}
Finora abbiamo supposto che l'elemento di matrice $V_{fi}$ fosse costante. Adesso consideriamo i casi in cui questo non avviene. \\
Il primo caso è quello di una perturbazione di tipo gaussiano, cioè $V(t)\equiv 0$ per $t\to\pm\infty$ e localizzata entro un certo intervallo di tempo caratteristico. Dato che per $t$ grande non abbiamo perturbazione, siamo autorizzati nella formula (10.6.1) a porre $t_1=-\infty$ e $t_2=+\infty$, ottenendo:
\begin{equation}
P_{if}=\frac{1}{\hbar^2}\left|\int_{-\infty}^{+\infty} V_{fi}(t)e^{-i\omega_{fi}t}\diff{t}\right|^2\;.
\end{equation}
L'integrale rappresenta effettivamente la trasformata di Fourier della funzione $V_{fi}(t)$. Quindi il problema è praticamente risolto (considerando che in questo caso $V$ è molto regolare, non abbiamo problemi rilevanti).\\
Il secondo caso è quello di una perturbazione nulla a $t=-\infty$, che cresce per un certo intervallo e poi si assesta ad un valore costante. Abbiamo in questo caso problemi a $t=+\infty$, in quanto l'Hamiltoniana non è più quella di partenza. Allora possiamo scrivere:
\begin{align}
\int_{-\infty}^t V_{fi}(t)e^{i\omega_{fi}t}\diff{t}&= \int_{-\infty}^t V_{fi}\frac{1}{i\omega_{fi}}i\omega_{fi}e^{i\omega_{fi}t} \notag \\
&= \frac{1}{i\omega_{fi}}\int_{-\infty}^t V_{fi}\frac{\partial}{\partial t}e^{i\omega_{fi}t}\diff{t} \notag \\
&= \left.\frac{e^{i\omega_{fi}t}}{i\omega_{fi}}V_{fi}\right|^t_{-\infty}-\frac{1}{i\omega_{fi}}\int_{-\infty}^t\pdev{V_{fi}}{t}e^{i\omega_{fi}t}\diff{t}\;.
\end{align}
Il primo termine è un termine di bordo che esprime il mixing tra i livelli, mentre nel secondo, possiamo notare che, per come è fatta la perturbazione, $\partial V_{fi}/\partial t\to 0$ per $|t|\to\infty$. Se $|s\ket$ sono gli autostati di $H_0$, $H_0|s\ket=E_s|s\ket$, gli autostati di $H=H_0+V(\infty)$ ($V(\infty)=V$ è costante) si ottengono applicando la teoria perturbativa:
\begin{equation}
|\psi_s\ket=|s\ket+\sum_k\frac{V_{ks}}{E_k-E_s}|k\ket\;.
\end{equation}
Se ad un certo istante $t$ abbiamo:
\begin{equation}
H(t)|k\ket=E_k(t)|k\ket\;.
\end{equation}
Possiamo sempre scrivere:
\begin{equation}
|\psi(t)\ket=\sum_s a_s(t)\exp\left(-\frac{i}{\hbar}\int_0^t E_s(t)\diff{t}\right)|s\ket\;,
\end{equation}
dove abbiamo scelto come fase (è arbitraria):
\begin{equation}
\exp\left(-\frac{i}{\hbar}\int_0^t E_s(t)\;\diff{t}\right)\equiv e^{-i\phi_s}\;.
\end{equation}
Allora l'equazione di \Sch\; è:
\begin{align}
i\hbar\dev{|\psi(t)\ket}{t} &= H\psi \notag \;,\\
\sum_s\left[i\hbar\dot{a}_s(t)+E_sa_s\right]e^{-i\phi_s}|s\ket+i\hbar\sum_s a_s(t)e^{-i\phi_s}\pdev{|s\ket}{t} &= \sum_s a_sE_se^{-i\phi_s}|s\ket\;, \notag \\
\sum_s \dot{a}_s(t)e^{-i\phi_s}|s\ket +\sum_sa_s(t)e^{-i\phi_s}\pdev{|s\ket}{t}&=0\;,
\end{align}
che proiettata sull'autostato di $H_0$ $|k\ket$ diventa:
\begin{equation}
\dot{a}_ke^{-i\phi_k}=\sum_s a_s(t)e^{-i\phi_s}\bra k|\pdev{s}{t}\ket\;.
\end{equation}
Derivando la relazione $H(t)|s\ket=E_s(t)|s\ket$ otteniamo invece:
\begin{equation}
\pdev{H}{t}|s\ket+H\pdev{|s\ket}{t}=\pdev{E_s}{t}|s\ket+E_s\pdev{|s\ket}{t}\;.
\end{equation}
Proiettiamo anche questa su $|k\ket$:
\begin{equation}
\bra k|\pdev{H}{t}|s\ket+E_k\bra k|\pdev{s}{t}\ket=E_s\bra k|\pdev{s}{t}\ket\;,
\end{equation}
da cui ricaviamo:
\begin{equation}
\bra k|\pdev{s}{t}\ket=\frac{1}{E_s-E_k}\bra k|\pdev{H}{t}|s\ket=\frac{1}{E_s-E_k}\bra k|\pdev{V}{t}|s\ket\;.
\end{equation}
Sostituendo questa espressione nella (10.6.9) otteniamo:
\begin{equation}
\dot{a}_k(t)=\sum_s a_s(t)e^{i(\phi_k-\phi_s)}\frac{1}{E_k-E_s}\bra k|\pdev{V}{t}|s\ket\;.
\end{equation}
Dato che $\partial V/\partial t$ è già al primo ordine in $V$, è sufficiente considerare tutti gli altri termine all'ordine zero. Notando che $\phi_k-\phi_s=-i(E_k-E_s)t/\hbar=-i\omega_{ks}t$ all'ordine zero, ritroviamo la formula che avevamo ricavato in precedenza. \\
Esaminiamo adesso il termine:
\begin{equation}
\frac{1}{\omega_{fi}}\int \pdev{V_{fi}}{t}e^{-i\omega_{fi}t}\diff{t}\;.
\end{equation}
Questo termine non dà in generale problemi e tende sempre a zero, a meno che non vi sia level-crossing: in tal caso si ha $\omega_{fi}=0$. Notando adesso che possiamo scrivere:
\begin{equation}
\pdev{V_{fi}}{t}=\pdev{V_{fi}}{\lambda}{\lambda}{t}=\pdev{V_{fi}}{\lambda}\dot{\lambda}\;,
\end{equation}
($\lambda$ rappresenta la perturbazione, i.e. campo elettrico, magnetico, etc...). Nel limite adiabatico $\dot{\lambda}\to 0,\dot{\lambda}T=$cost, si ha $P_{fi}=0$, cioè la probabilità di cambiare livello nel limite adiabatico è nulla. In questo tipo di perturbazione, gli autostati di $H_0$ non esistono più quando la perturbazione si assesta, perché ho un'Hamiltoniana diversa $H_0'=H_0+V$. Ha senso, tuttavia, chiedersi quale sia la probabilità, pertendo dallo stato fondamentale di $H_0$, di arrivare allo stato fondamentale di $H_0'$. Dato che gli autostati di $H_0'$ sono comunque un set completo, possiamo scrivere:
\begin{equation}
|0\ket=\sum_s c_s|s'\ket=c_0|0'\ket+\sum_{s\ne 0} c_s|s'\ket\;.
\end{equation}
Se per $s\ne 0$ qualche coefficiente $c_s$ è diverso da zero, allora possiamo avere una transizione. Se invece solo $c_0$ è non nullo, non avremo transizioni di livello: il sistema andrà dallo stato fondamentale di $H_0$ allo stato fondamentale di $H_0'$. Inoltre, perturbativamente, si ha:
\begin{align}
|0'\ket &=|0\ket+\sum_k \frac{\bra k|V|0\ket}{E_0-E_k}|k\ket\;, \notag \\
|k'\ket &=|k\ket+\sum_s \frac{\bra s|V|k\ket}{E_k-E_s}|s\ket\;.
\end{align}
Possiamo a questo punto definire il coefficiente di mixing:
\begin{equation}
\bra k'|0\ket=\frac{\bra 0|V|k\ket}{E_k-E_0}\;.
\end{equation}
\begin{exm} (Oscillatore armonico con campo elettrico) \\
Consideriamo l'Hamiltoniana perturbata:
\begin{equation*}
H=\frac{p^2}{2m}+\frac{1}{2}m\omega^2x^2-eE(t)x\;,
\end{equation*}
dove:
\begin{equation*}
E(t)=\varepsilon f(t)=\varepsilon\begin{cases}
\dfrac{1}{2}e^{t/\tau}\qquad t<0\;, \\
\\
1-\dfrac{1}{2}e^{-t/\tau}\qquad t>0\;.
\end{cases}
\end{equation*}

Dato che abbiamo una perturbazione in $x\propto (a+\adj{a})$, sarà possibile rimanere nello stato fondamentale oppure arrivare al più al primo eccitato. Calcoliamo $P_{0\to 1}$ (si ha $\omega_{fi}=\omega$):
\begin{equation*}
\frac{1}{\hbar\omega_{fi}}\int_{-\infty}^{+\infty} \pdev{V_{fi}}{t}e^{i\omega_{fi}t}\diff{t}\;,
\end{equation*}
con $V_{fi}(t)=e\varepsilon\bra f|x|i\ket f(t)$. Per $f(t)$ si ha invece:
\begin{align*}
f(t) &= \frac{1}{2}e^{t/\tau}\theta(-t)+\left(1-\frac{1}{2}e^{-t/\tau}\right)\theta(t)= \theta(t)-\frac{1}{2}\operatorname{sgn}(t)e^{-|t|/\tau}\;, \\
f'(t) &= \delta(t)-\delta(t)e^{-|t|/\tau}+\frac{1}{2\tau}e^{-|t|/\tau}=\frac{1}{2\tau}e^{-|t|/\tau}\;.
\end{align*}
Svolgendo i conti si ottiene:
\begin{equation*}
\int_{-\infty}^{+\infty}\pdev{V_{fi}}{t}e^{i\omega t}\diff{t}=-\frac{1}{2\tau}e\varepsilon x_{fi}\left(\frac{1}{i\omega +1/\tau}-\frac{1}{i\omega-1/\tau}\right)=-e\varepsilon x_{fi}\frac{1}{\tau^2}\frac{1}{\omega^2+1/\tau^2}\;.
\end{equation*}
Quindi:
\begin{equation*}
P_{fi}=\frac{e^2\varepsilon^2|x_{fi}|^2}{\hbar^2\omega^2}\left|\frac{1}{\tau^2}\frac{1}{\omega^2+1/\tau^2}\right|^2\;.
\end{equation*}
Per $\tau\to\infty$ (limite adiabatico) $P_{fi}\to0$ come $1/\tau^2$ (è il massimo ottenibile, visto che $f$ non è di classe $C^2$. Per $\tau\to 0$ (perturbazione impulsiva) $P_{fi}\to e^2\varepsilon^2|x_{fi}|^2/\hbar^2\omega^2$. \\
Prendiamo adesso:
\begin{align*}
f(t)&=\frac{1}{2}\left(1+\frac{t/\tau}{\sqrt{1+t^2/\tau^2}}\right)\;, \\
\pdev{f}{t} &= \frac{1}{2\tau}\frac{1}{(1+t^2/\tau^2)^{3/2}}\;.
\end{align*}
L'ampiezza di transizione è:
\begin{equation*}
A_{fi}=e\varepsilon x_{fi}\int_{-\infty}^{+\infty} \frac{1}{2\tau}\frac{1}{(1+t^2/\tau^2)^{3/2}}e^{i\omega t}\diff{t}=\frac{e\varepsilon x_{fi}}{2}\int_{-\infty}^{+\infty}\frac{1}{(1+t^2)^{3/2}}e^{i\omega\tau t}\diff{t}\;.
\end{equation*}
Per $\tau\to 0$ l'integrale tende a 2, quindi $A_{fi}=e\varepsilon x_{fi}$. Per $\tau\to\infty$ usando lo sviluppo di Bessel si ottiene:
\begin{equation*}
A_{fi}\to \frac{e\varepsilon x_{fi}}{2}\sqrt{2\pi\omega\tau}e^{-\omega\tau}\;,
\end{equation*}
e $P_{fi}=|A_{fi}|^2$.
\end{exm}
\section{Perturbazioni periodiche}
Scegliamo adesso come perturbazione un segnale monocromatico:
\begin{equation}
V(t)=Fe^{-i\omega t}+\adj{F}e^{i\omega t}\;,
\end{equation}
dove $F$ è un operatore. Studiamo per questo tipo di perturbazioni il rate di transizioni $|i\ket\to|f\ket$, $f\ne i$. Sappiamo che:
\begin{align}
a_f&=\frac{1}{i\hbar}\int_0^t V_{fi}(t)e^{i\omega_{fi}t}\diff{t} \notag \\
&=\frac{1}{i\hbar}\int_0^t\left(F_{fi}e^{i(\omega_{fi}-\omega)t}+\adj{F}_{fi}e^{i(\omega_{fi}+\omega)t}\right)\diff{t} \notag \\
&= \frac{1}{i\hbar}\left[ F_{fi}\frac{e^{i(\omega_{fi}-\omega)t}-1}{i(\omega_{fi}-\omega)}+\adj{F}_{fi}\frac{e^{-i(\omega_{fi}+\omega)t}-1}{i(\omega_{fi}+\omega)}\right]\;.
\end{align}
Se siamo in fase di assorbimento, cioè $\omega_{fi}>0$, allora solo il primo termine va in risonanza, mentre in emissione $\omega_{fi}<0$, e solo il secondo termine va in risonanza. Supponiamo di essere in assorbimento (il caso di emissione è speculare). Trascurando dunque il secondo addendo la probabilità di transizione è:
\begin{equation}
|a_f|^2=\frac{1}{\hbar^2}|F_{fi}|^2\frac{4\sin^2[(\omega_{fi}-\omega)t/2]}{|\omega_{fi}-\omega|^2} \longrightarrow \frac{|F_{fi}|^2}{\hbar^2}\pi t\delta\left(\frac{\omega_{fi}-\omega}{2}\right)\;,
\end{equation}
da cui:
\begin{equation}
\gamma_{i\to f}=\frac{2\pi}{\hbar}|F_{fi}|^2\delta(E_f-E_i-\hbar\omega)\;.
\end{equation}
Prendiamo in esame il caso di un campo elettrico in approssimazione di dipolo: l'accoppiamento sarà il solito $-\mathbf{d}\cdot\mathbf{E}$. Scegliamo come campo elettrico un'onda piana:
\begin{equation}
\mathbf{E}=E_0\hat{\mathbf{x}}\cos\omega t=\frac{E_0}{2}(e^{i\omega t}+e^{-i\omega t})\;.
\end{equation}
Quindi $-\mathbf{d}\cdot\mathbf{E}=-d_xE_x$ e $F=E_0d_x/2$. Posto $E_f-E_i=\hbar\omega_0$ otteniamo:
\begin{equation}
\gamma= \frac{2\pi}{\hbar}\left(\frac{E_0}{2}\right)^2|\bra f|d_x|i\ket|^2\delta(\omega-\omega_0)\;.
\end{equation}
\begin{quote}
«Le trasformazioni di Lorentz in MKS sono una cosa che non sta né in cielo né in terra.»
\begin{flushright}
G.P.
\end{flushright}
\end{quote}
Possiamo riscrivere il $\gamma$ in termini dell'intensità dell'onda incidente ricordando la definizione del vettore di Poiynting e la sua relazione con l'intensità dell'onda:
\begin{align}
|\mathbf{S}| &= \frac{c}{4\pi}|\mathbf{E}\wedge\mathbf{B}|=\frac{c}{4\pi}E_0^2\cos^2\omega t \notag\;, \\
I&=\bra |\mathbf{S}|\ket=\frac{c}{8\pi}E_0^2\;.
\end{align}
Quindi:
\begin{equation}
\gamma=\frac{2\pi}{\hbar}\frac{2\pi}{c}I|\bra f|d_x|i\ket|^2\delta(\omega-\omega_0)=\frac{4\pi^2}{\hbar^2c}I_{\omega}|\bra f|d_x|i\ket|^2\delta(\omega-\omega_0)\diff{\omega}\;,
\end{equation}
dove abbiamo introdotto l'intensità spettrale di una riga di spessore infinitesima $I_{\omega}=\diff{I}/\diff{\omega}\diff{\omega}$. In definitiva:
\begin{equation}
\diff{\gamma}=\frac{4\pi^2}{\hbar^2c}|\bra f|d_x|i\ket|^2I_{\omega}\delta(\omega-\omega_0)\diff{\omega}\;,
\end{equation}
che integrata su tutte le frequenze restituisce il rate di transizioni:
\begin{equation}
\gamma=\frac{4\pi^2}{\hbar^2 c}I_{\omega}(\omega_0)|\bra f|d_x|i\ket|^2\;.
\end{equation}
Queste considerazioni valgono solo nel caso di luce incoerente, in cui si assume che i termini di interferenza si medino statisticamente a zero, e quindi:
\begin{align}
|E(t)|^2 &= \left|\sum_i e^{i\omega_it+i\phi_i}E_i\right|^2= \sum_i |E_i|^2+\sum_{i\ne j} E_iE_j e^{i(\omega_i-\omega_j)t+i(\phi_i-\phi_j)}=  \sum_i |E_i|^2\;.
\end{align}
Sommando la (10.7.10) su tutti gli stati finali possibili, otteniamo la probabilità di transizione:
\begin{equation}
\gamma_{i\to f}=\frac{4\pi^2}{\hbar^2 c}I_{\omega}(\omega_0)\sum_f |\bra f|d_x|i\ket|^2\;.
\end{equation}
Notiamo che si può scrivere:
\begin{equation}
|\bra f|d_x|i\ket|^2=\bra f|d_x|i\ket\bra i|d_x|f\ket=\bra f|d_x \rho_i d_x|f\ket\;,
\end{equation}
dove $\rho_i$ è il proiettore:
\begin{equation}
\rho_i=\frac{1}{g_i}\sum_i |i\ket\bra i|\;,
\end{equation}
e $g_i$ è la degenerazione dello stato iniziale. Quindi:
\begin{align}
|\bra f|d_x|i\ket|^2 &= \bra f|d_x \frac{1}{g_i}\sum_i|i\ket\bra i|d_x|f\ket= \frac{1}{g_i}\sum_i \bra f|d_x|i\ket\bra i|d_x|f\ket= \frac{1}{g_i}\sum_i |\bra f|d_x|i\ket|^2\;.
\end{align}
Allora la probabilità di transizione diventa:
\begin{equation}
\gamma_{i\to f}=\frac{4\pi^2}{\hbar^2 c}I_{\omega}(\omega_0)\frac{1}{g_i}\sum_f\sum_i|\bra f|d_x|i\ket|^2\;,
\end{equation}
dato che $d_x=d_y=d_z$ otteniamo:
\begin{equation}
\gamma_{i\to f}=\frac{4}{3}\frac{\pi^2}{\hbar^2 c}I_{\omega}(\omega_0)\frac{1}{g_i}\sum_i\sum_f|\bra f|\mathbf{d}|i\ket|^2\;,
\end{equation}
moltiplicando e dividendo per la degenerazione dello stato finale otteniamo in definitiva la seguente espressione:
\begin{equation}
\gamma_{i\to f}=\frac{4}{3}\frac{\pi^2}{\hbar^2 c}I_{\omega}(\omega_0)g_f\overline{D^2}\;,
\end{equation}
per l'assorbimento. L'espressione per l'emissione si ottiene scambiando $g_f$ e $g_i$:
\begin{equation}
\gamma_{f\to i}=\frac{4}{3}\frac{\pi^2}{\hbar^2 c}I_{\omega}(\omega_0)g_i\overline{D^2}\;.
\end{equation}
Prendiamo adesso in esame un sistema a due livelli (1=fondamentale, 2=eccitato). La variazione dell'occupazione dello stato eccitato è dato da:
\begin{equation}
\dev{n_2}{t}=-\underbrace{B_{2\to 1}n_2I_{\omega}}_{\mbox{emissione stimolata}}+\underbrace{B_{1\to2}n_1I_{\omega}}_{\mbox{assorbimento stimolato}}-\underbrace{An_2}_{\mbox{emissione spontanea}}\;.
\end{equation}
All'equilibrio termodinamico la (10.7.20) deve essere nulla, quindi, ricordando che $I_{\omega}=cu(\omega)$:
\begin{equation}
cu(\omega)=\frac{An_2}{B_{1\to 2}n_1-B_{2\to 1}n_2}\;.
\end{equation}
Aggiungiamo la condizione che a $T\to\infty$ l'emissione spontanea sia trascurabile, cioè $B_{1\to 2}n_1=B_{2\to 1}n_2$, che si traduce in:
\begin{equation}
\frac{B_{1\to 2}}{B_{2\to 1}}=\frac{n_2}{n_1}=\frac{g_2}{g_1}e^{-(E_1-E_2)/kT}\;.
\end{equation}
Allora:
\begin{align}
cu(\omega) &= \frac{A/B_{2\to 1}}{\dfrac{B_{1\to 2}}{B_{2\to 1}}\dfrac{n_1}{n_2}-1}=\frac{A/B_{2\to 1}}{e^{\hbar\omega}-1}\;,
\end{align}
dove $\hbar\omega= E_1-E_2$. Questo risultato assomiglia alla legge di Planck. Se assumiamo nota la legge di Planck, allora:
\begin{align*}
u(\omega)\diff{\omega}&=\frac{1}{2\pi}2\frac{4\pi k^2\diff{k}}{8\pi^3}=\frac{1}{\pi^2}\frac{\omega^2\diff{\omega}}{c^3}\;,  \\
\frac{A}{cB_{2\to 1}}&\stackrel{!}{=}\frac{1}{\pi^2}\frac{\omega^2}{c^3}\hbar\omega\;, \\
A&= \frac{1}{\pi^2}\frac{\hbar\omega^3}{c^2}B_{2\to 1}\;.
\end{align*}
L'ultima espressione deve corrispondere al rate $\gamma$ che avevamo calcolato per i decadimenti: sostituendo l'espressione di $B_{2\to 1}$  troviamo dunque:
\begin{equation}
A=\frac{1}{\pi^2}\frac{\hbar\omega^3}{c^2}\frac{4}{3}\frac{\pi^2}{\hbar^2c}g_1\overline{D^2}=\frac{4}{3}\frac{\omega^3}{c^3}\frac{1}{\hbar}g_1\overline{D^2}\equiv \frac{1}{\tau}\;,
\end{equation}
come volevasi dimostrare. Nel limite di alte temperature, l'espressione di $cu(\omega)$ deve coincidere con la formula di Raylegh-Jeans:
\begin{equation}
cu(\omega)=\frac{A/B_{2\to 1}}{e^{\hbar\omega/kT}-1}\simeq \frac{A/B_{2\to 1}}{\hbar\omega/kT}=\frac{kT}{\hbar\omega}\frac{A}{B_{2\to 1}}\;.
\end{equation}
Partendo da ciò, siamo anche in grado di dimostrare la legge di Planck (assumendo che essa non sia nota). \\
La variazione del numero di fotoni tra i due livelli è invece data da:
\begin{equation}
\dev{n_{\gamma}}{t}=(B_{2\to 1}n_2-B_{1\to 2}n_1)I_{\omega}\;.
\end{equation}
che all'equilibrio termico è sempre minore o uguale a zero. Se non si è all'equilibrio termico si ha un'inversione delle popolazioni degli stati. \\
\textbf{Nota.} Il calcolo è lo stesso nel caso di accoppiamento di dipolo magnetico $-\boldsymbol{\mu}\cdot\mathbf{B}$. È sufficiente sostituire l'elemento di matrice di dipolo elettrico con quello di dipolo magnetico $d_{fi}\to \mu_{fi}$. \\
\\
In realtà l'Hamiltoniana di interazione con il campo EM è, al primo ordine e in gauge di Coulomb:
\begin{equation}
H_{\mathrm{int}}=-\frac{e\mathbf{p}}{mc}\mathbf{A}, \qquad \mathbf{A}=\mathbf{A}_0\sin(\omega t-\mathbf{k}\cdot\mathbf{x})\;.
\end{equation}
I campi sono legati al potenziale vettore $\mathbf{A}$ dalle relazioni:
\begin{align}
\mathbf{E} &= -\frac{1}{c}\pdev{\mathbf{A}}{t}=-\frac{\omega}{c}\mathbf{A}_0\cos(\omega t-\mathbf{k}\cdot\mathbf{x}) \notag\;, \\
\mathbf{B} &= \bnabla\wedge \mathbf{A}=-(\mathbf{k}\wedge\mathbf{A}_0)\cos(\omega t-\mathbf{k}\cdot\mathbf{x})\;.
\end{align}
Quindi in termini di ampiezze, si ha $E_0=\omega A_0/c$, cioè $A_0=cE_0/\omega$. Limitandoci alla fase di assorbimento possiamo scrivere:
\begin{equation}
\mathbf{A}=\mathbf{A}_0\left(e^{i\mathbf{k}\cdot\mathbf{x}-i\omega t}\right)\;.
\end{equation}
Dbbiamo allora calcolare:
\begin{equation}
\bra f|\frac{e\mathbf{p}\cdot\mathbf{A}_0}{mc}e^{i\mathbf{k}\cdot\mathbf{x}}|i\ket\;.
\end{equation}
Il dominio della funzione d'onda è dell'ordine $ka_B=2\pi a_B/\lambda$. L'approssimazione di dipolo è valida se $a_B\ll \lambda$, e si ottiene:
\begin{equation}
\bra f|\frac{e\mathbf{p}\cdot\mathbf{A}_0}{mc}e^{i\mathbf{k}\cdot\mathbf{x}}|i\ket\simeq \bra f|\frac{e\mathbf{p}\cdot\mathbf{A}_0}{mc}|i\ket\;.
\end{equation}
Essendo:
\begin{equation}
\mathbf{p}=m\dev{\mathbf{r}}{t}=m\frac{i}{\hbar}[H,\mathbf{r}]\;.
\end{equation}
Si ha:
\begin{equation}
\bra f|\mathbf{p}|i\ket=\frac{mi}{\hbar}(E_f-E_i)\bra f|\mathbf{r}|i\ket=im\omega_0\bra f|\mathbf{r}|i\ket\;,
\end{equation}
che sostituita nella 10.7.31 restituisce:
\begin{equation*}
\frac{e}{mc}\mathbf{A}_0m\omega_0\mathbf{r}_{fi}=\frac{e\omega_0}{c}\mathbf{A}_0\cdot\mathbf{r}_{fi}\;.
\end{equation*}
In risonanza $\omega_0=\omega$ e $\omega \mathbf{A}_0/c=\mathbf{E}_0$, cioè:
\begin{equation}
\frac{e}{mc}\mathbf{A}_0m\omega_0\mathbf{r}_{fi}= e\mathbf{r}_{fi}\cdot\mathbf{E}_0\equiv \mathbf{d}_{fi}\cdot\mathbf{E}_0\;.
\end{equation}
\\
Adesso il modello di Hamiltoniana che tratteremo è:
\begin{equation}
H=E_0+\left(\begin{matrix}
\dfrac{\hbar\omega_0}{2} & d\mathcal{E} \\
d\mathcal{E} & -\dfrac{\hbar\omega_0}{2}
\end{matrix}\right)\;,
\end{equation}
cioè la perturbazione è del tipo $V(t)=d\mathcal{E}\cos(\omega t)$. In prossimità della risonanza, possiamo trascurare cosa succede negli altri stati (se ve ne sono).
\begin{equation}
\dot{a}_k=-\frac{i}{\hbar}V_{ki}(t)e^{i\omega_{ki}t}a_i,\qquad |\psi(t)\ket=\sum_ja_j(t)e^{-iE_jt/\hbar}|j\ket\;.
\end{equation}
Nel nostro caso (indichiamo con $|1\ket$ lo stato eccitato e $|2\ket$ il fondamentale):
\begin{equation*}
\begin{cases}
\dot{a}_1=-\dfrac{i}{\hbar}d\mathcal{E}\cos(\omega t) e^{i\omega_0t}a_2=-\dfrac{i}{\hbar}\dfrac{d\mathcal{E}}{2}(e^{i\omega t}+e^{-i\omega t})e^{i\omega_0t}a_2\;, \\
\\
\dot{a}_2=-\dfrac{i}{\hbar}\dfrac{d\mathcal{E}}{2}(e^{i\omega t}+e^{-i\omega t})e^{-i\omega_0t}a_1\;.
\end{cases}
\end{equation*}
Trascuriamo i termini fuori risonanza, ma stavolta non eseguiamo lo sviluppo perturbativo (approssimazione di campo rotante):
\begin{equation}
\begin{cases}
\dot{a}_1=-\dfrac{i}{\hbar}\dfrac{d\mathcal{E}}{2}e^{-i\omega t}e^{i\omega_0t}a_2\;, \\
\\
\dot{a}_2=-\dfrac{i}{\hbar}\dfrac{d\mathcal{E}}{2}e^{i\omega t}e^{-i\omega_0t}a_1\;,
\end{cases}\qquad \Longrightarrow \qquad
H_{\mathrm{eff}}=\left(\begin{matrix}
\dfrac{\hbar\omega_0}{2} & \dfrac{d\mathcal{E}}{2}e^{-i\omega t} \\
\dfrac{d\mathcal{E}}{2}e^{i\omega t} & -\dfrac{\hbar\omega_0}{2}
\end{matrix}\right)\;.
\end{equation}
Mandiamo un segnale monocromatico in risonanza con la differenza di energia fra i due livelli, cioè poniamo $\omega=\omega_0$. Allora:
\begin{equation*}
\begin{cases}
\dot{a}_1 =-\dfrac{i}{\hbar}\dfrac{d\mathcal{E}}{2}a_2\equiv -i\dfrac{f}{2}a_2\;, \\
\\
\dot{a}_2 =-\dfrac{i}{\hbar}\dfrac{d\mathcal{E}}{2}a_1\equiv -i\dfrac{f}{2}a_1\;,
\end{cases}
\end{equation*}
dove abbiamo posto $f=d\mathcal{E}/\hbar$. Disaccoppiamo le equazioni derivando e sostituendo:
\begin{align*}
\ddot{a}_1 &= -i\frac{f}{2}\dot{a}_2=-\frac{f^2}{4}a_1\;, \\
\ddot{a}_2 &= -i\frac{f}{2}\dot{a}_1=-\frac{f^2}{4}a_2\;,
\end{align*}
le soluzioni sono oscillanti:
\begin{align}
a_1 &= c_1\cos\left(\frac{ft}{2}\right)+c_2\sin\left(\frac{ft}{2}\right)\;, \notag \\
a_2 &= c_1'\cos\left(\frac{ft}{2}\right)+c_2'\sin\left(\frac{ft}{2}\right)\;.
\end{align}
Supponiamo che all'istante $t=0$ si abbia $a_1(0)=1,a_2(0)=0$. Allora:
\begin{equation}
a_2(t)=\sin\left(\frac{ft}{2}\right)\qquad \Longrightarrow \qquad P_2(t)=\sin^2\left(\frac{ft}{2}\right)\;.
\end{equation}
Notiamo che se $t=T=\pi/f$, $P_2(T)=1$ e quindi siamo sicuri che il sistema si trovi nello stato fondamentale. \\
\begin{exm} $ \\ $
Consideriamo l'Hamiltoniana:
\begin{align*}
H &=\left(\begin{matrix}
\dfrac{\hbar\omega_0}{2} & \dfrac{\hbar f}{2}e^{-i\omega t} \\
\dfrac{\hbar f}{2}e^{i\omega t} & -\dfrac{\hbar\omega_0}{2}
\end{matrix}\right)  \\
&= \frac{\hbar\omega_0}{2}\sigma_z+\frac{\hbar f}{2}\sigma_x\cos(\omega t)+\frac{\hbar f}{2}\sigma_y\sin(\omega t) \\
&= \frac{\hbar}{2}[\omega_0\sigma_z+f(\sigma_x\cos(\omega t)+\sigma_y\sin(\omega t))]\;,
\end{align*}
dove la parentesi tonda rappresenta il campo rotante. Eseguiamo adesso una rotazione oraria:
$$
|\psi^R(t)\ket=R(t)|\psi(t)\ket,\qquad\qquad R(t)=e^{i\omega t\sigma_z/2}\;.
$$
In questo modo, il campo è visto fermo. Sappiamo che $|\psi(t)\ket=U(t,0)|\psi(0)\ket$, dove $U$ è l'operatore unitario di evoluzione temporale, che sotto la rotazione $R(t)$ diventa:
$$
U^R(t)=R(t)U(t,0)\adj{R}(0)=R(t)U(t,0)\;.
$$
Si ha allora:
\begin{align*}
i\hbar\frac{\partial}{\partial t}|\psi^R(t)\ket &= RH|\psi(t)\ket+i\hbar(\partial_tR)|\psi(t)\ket =RH\adj{R}|\psi^R(t)\ket+i\hbar(\partial_tR)\adj{R}|\psi^R(t)\ket\;.
\end{align*}
L'Hamiltoniana ruotata è:
\begin{align*}
H^{(R)}&=RH\adj{R}-\frac{\hbar\omega}{2}\sigma_z =  \frac{\hbar\omega_0}{2}\sigma_z+\frac{\hbar f}{2}\sigma_x-\frac{\hbar\omega}{2}\sigma_z=  \frac{\hbar}{2}(\omega_0-\omega)\sigma_z+\frac{\hbar f}{2}\sigma_x\;,
\end{align*}
che adesso non dipende più dal tempo. L'operatore di evoluzione temporare è semplicemente l'esponenziale:
\begin{align*}
U^R&=\exp\left[-\frac{i}{\hbar}\left(\frac{\hbar}{2}(\omega_0-\omega)\sigma_z+\frac{\hbar}{2}f\sigma_x\right)t\right]=\exp\left[-\frac{i}{2}\left((\omega_0-\omega)\sigma_z+f\sigma_x\right)t\right]\;,
\end{align*}
e:
$$
U=\adj{R}U^R=e^{-i\omega t\sigma_z/2}e^{-i[(\omega_0-\omega)\sigma_z+f\sigma_x]t/2}\;.
$$
Fissiamo:
\begin{align*}
&|1\ket =\begin{pmatrix}
1 \\
0
\end{pmatrix}\;,
&|2\ket=\begin{pmatrix}
0 \\
1
\end{pmatrix}\;,
\end{align*}
e poniamo $\Omega=\sqrt{(\omega_0-\omega)^2+f^2}$. Allora:
\begin{align*}
\bra 2|U(t)|1\ket &= e^{i\omega_0t/2}\bra 2|e^{-i[(\omega_0-\omega)\sigma_z+f\sigma_x]t/2}|1\ket \\
&= e^{i\omega_0t/2}\bra 1|\cos\left(\frac{\Omega t}{2}\right)+i\left(\frac{\omega_0-\omega}{\Omega}\sigma_z+\frac{f}{\Omega}\sigma_x\right)\sin\left(\frac{\Omega t}{2}\right) \\
&= i\frac{f}{\Omega}\sin\left(\frac{\Omega t}{2}\right)e^{i\omega_0t/2}\;.
\end{align*}
Da cui otteniamo una formula valida in generale, anche fuori risonanza:
\begin{equation}
P_{1\to 2}=\frac{f^2}{\Omega^2}\sin^2\left(\frac{\Omega t}{2}\right).
\end{equation}
\end{exm}
\section{Sezione d'urto per effetto fotoelettrico}
L'Hamiltoniana d'interazione del processo $\gamma+{}^2H\rightarrow p^+ +e^-$ è:
\begin{equation}
H_{\mathrm{int}}=\frac{e}{mc}\mathbf{A}\cdot\mathbf{p}\;,
\end{equation}
dove $\mathbf{A}=\boldsymbol{\epsilon}A_0\cos\omega t$. Fissiamo come energia iniziale l'energia dello stato fondamentale dell'idrogeno, $E_i=E_{1s}$ e come energia finale quella di un elettrone in campo coulombiano. Il rate differenziale di decadimenti è dato dalla regola d'oro di Fermi:
\begin{equation}
\diff{\gamma}=\frac{2\pi}{\hbar}\delta(E_f-\hbar\omega-E_{1s})\frac{e^2}{m^2c^2}\left|\boldsymbol{\epsilon}\cdot\frac{A_0}{2}\bra f|\mathbf{p}|i\ket\right|^2\frac{\diff^3{k}}{(2\pi)^3}\;.
\end{equation}
La sezione d'urto è definita come $\diff{\sigma}=\diff{\gamma}/\Phi$, dove $\Phi$ è il flusso di fotoni per unità di superficie e di tempo, ed è legato all'intensità della radiazione incidente dalla relazione $I=\hbar\omega \Phi$. \\
\textbf{Nota.} È utile ricordare in queste situazioni la definizione della costante di struttura fine $\alpha=e^2/\hbar c$ (in unità CGS), per esprimere $c$ in termini di $\alpha$ che è adimensionale: $c=e^2/\hbar\alpha$. \\
Dunque, supponendo che l'elettrone emesso sia sufficientemente veloce da poter essere trattato come particella libera, si ha:
\begin{equation}
\diff{\gamma}=\frac{2\pi}{\hbar}\frac{e^2}{4m^2c^2}\delta\left(\frac{\hbar^2k^2}{2m}-(\hbar\omega+E_{1s})\right)A_0^2|\boldsymbol{\epsilon}\cdot\mathbf{p}_{fi}|^2\frac{k^2\diff{k}\diff{\Omega}}{(2\pi)^3}\;,
\end{equation}
dove abbiamo espresso il $\diff^3{k}$ in coordinate polari. Adesso esprimiamo $A_0^2$ in termini del flusso $\Phi$:
\begin{equation}
A_0^2=\frac{c^2}{\omega^2}E_0^2=\frac{c^2}{\omega^2}\frac{8\pi}{c}I=\frac{8\pi c}{\omega^2}\hbar\omega\Phi=\frac{8\pi\hbar c}{\omega}\Phi\;,
\end{equation}
e integriamo su $k$ per eliminare la delta. Ricordiamo che se $x_0$ è uno zero di $f(x)$ vale l'identità:
\begin{equation}
\delta(f(x))=\frac{\delta(x_0)}{f'(x_0)}\;.
\end{equation}
Si ha pertanto:
\begin{equation}
\diff{\gamma}=\frac{2\pi}{\hbar}\frac{e^2}{4m^2c^2}\frac{1}{\dfrac{\hbar^2k}{m}}\frac{8\pi\hbar c}{\omega}\Phi|\boldsymbol{\epsilon}\cdot\mathbf{p}_{fi}|^2\frac{k^2\diff{\Omega}}{8\pi^3}\;.
\end{equation}
Dividendo per $\Phi$ otteniamo la sezione d'urto differenziale:
\begin{align}
\diff{\sigma} &= \frac{1}{2\pi}\frac{1}{c}\frac{e^2}{m}\frac{1}{\hbar^2}\frac{k^2}{\omega k}\diff{\Omega}|\boldsymbol{\epsilon}\cdot\mathbf{p}_{fi}|^2 \notag \\
&= \frac{1}{2\pi}\frac{\alpha\hbar}{e^2}\frac{e^2}{m}\frac{1}{\hbar^2}\frac{k}{\omega}\diff{\Omega}|\boldsymbol{\epsilon}\cdot\mathbf{p}_{fi}|^2 \notag \\
&= \frac{\alpha}{2\pi m\hbar}\frac{k}{\omega}\diff{\Omega}|\boldsymbol{\epsilon}\cdot\mathbf{p}_{fi}|^2\;.
\end{align}
La delta imponeva che:
\begin{align}
\hbar\omega &= \frac{\hbar^2k^2}{2m}+\frac{1}{2}\frac{e^4m}{\hbar^2}= \frac{me^4}{2\hbar^2}\left(1+\frac{\hbar^2k^2}{m}\frac{\hbar^2}{me^4}\right)= \frac{1}{2}\frac{me^4}{\hbar^2}(1+k^2a_B^2)\;,
\end{align}
dove $a_B$ è il raggio di Bohr. Il termine che moltiplica la parentesi è l'energia di ionizzazione del livello $1s$. Resta infine da scrivere l'elemento di matrice $\boldsymbol{\epsilon}\cdot\mathbf{p}_{fi}=\boldsymbol{\epsilon}\cdot\bra f|\mathbf{p}|i\ket$, con $|i\ket=\psi_{1s}(\mathbf{x})$ e $|f\ket=e^{i\mathbf{k}\cdot\mathbf{x}}$ (onda piana). Quindi:
\begin{align}
\boldsymbol{\epsilon}\cdot\bra f|\mathbf{p}|i\ket &= \boldsymbol{\epsilon}\cdot \int\diff^3{x}\,e^{-i\mathbf{k}\cdot\mathbf{x}}\mathbf{p}\psi_{1s}(\mathbf{x}) =  \hbar\mathbf{k}\cdot\boldsymbol{\epsilon}\int\diff^3{x}\,e^{-i\mathbf{k}\cdot\mathbf{x}}\psi_{1s}(\mathbf{x})\;.
\end{align}
L'integrale rappresenta la trasformata di Fourier della funzione d'onda dell'$1s$, che è $\psi_{1s}=(\pi a_B^3)^{-1/2}e^{-r/a_B}$. Sapendo che:
\begin{equation}
\mathcal{F}\left(\frac{e^{-\mu r}}{r}\right)=\frac{4\pi}{k^2+\mu^2}\;,
\end{equation}
ricaviamo che:
\begin{equation}
\mathcal{F}(e^{-\mu r})=-\frac{\partial}{\partial\mu}\frac{4\pi}{k^2+\mu^2}=\frac{8\pi\mu}{(k^2+\mu^2)^2}\;.
\end{equation}
Quindi:
\begin{align}
\boldsymbol{\epsilon}\cdot\mathbf{p}_{fi} &= \frac{\hbar\boldsymbol{\epsilon}\cdot\mathbf{k}}{\sqrt{\pi a_B^3}}\frac{8\pi/a_B}{(k^2+1/a_B^2)^2} \notag \\
&= \frac{\hbar\boldsymbol{\epsilon}\cdot\mathbf{k}}{\sqrt{\pi a_B^3}}\frac{8\pi a_B^3}{(1+k^2a_B^2)^2} \notag \\
&= \frac{\hbar(\boldsymbol{\epsilon}\cdot\mathbf{k})8\sqrt{\pi}a_B^{3/2}}{(1+k^2a_B^2)^2} \notag \\
&=\frac{8\sqrt{\pi}a_B^{3/2}}{(1+k^2a_B^2)^2}\hbar k(\boldsymbol{\epsilon}\cdot\hat{\mathbf{n}})\;,
\end{align}
dove $\boldsymbol{\epsilon}\cdot\hat{\mathbf{n}}$ è la direzione di volo. Alla luce di ciò, l'espressione della sezione d'urto diventa:
\begin{align}
\diff{\sigma} &= \frac{\alpha}{2\pi\hbar m}\frac{k}{\omega}\diff{\Omega}\frac{64\pi a_B^3}{(1+k^2a_B^2)^4}\hbar^2k^2|\boldsymbol{\epsilon}\cdot\hat{\mathbf{n}}|^2 \notag \\
&= \frac{32\alpha (ka_B)^3\hbar}{m\omega}|\boldsymbol{\epsilon}\cdot\hat{\mathbf{n}}|^2\diff{\Omega}\frac{1}{(1+k^2a_B^2)^4} \notag \\
&= f|\boldsymbol{\epsilon}\cdot\hat{\mathbf{n}}|^2\diff{\Omega}\;,
\end{align}
con $f$ costante. Possiamo fare le seguenti osservazioni:
\begin{enumerate}
\item dato che:
\begin{equation}
\int n_in_j\diff{\Omega}=\frac{4\pi}{3}\delta_{ij}\;,
\end{equation}
si ha:
\begin{equation}
\sigma=\int f\epsilon_i\epsilon_jn_in_j\diff{\Omega}=\frac{4\pi}{3}f|\boldsymbol{\epsilon}|^2\;,
\end{equation}
cioè la sezione d'urto totale non dipende dalla polarizzazione della radiazione incidente;
\item se mandiamo luce non polarizzata dobbiamo sostituire $\epsilon_i\epsilon_j\rightarrow \rho_i$, dove $\rho_i$ è la matrice di densità data da:
\begin{equation}
\rho_i=\frac{1}{2}(\delta_{ij}-\hat{\mathbf{z}}_i\cdot\hat{\mathbf{z}}_j)\;.
\end{equation}
Abbiamo
\begin{equation}
\diff{\sigma}=\sigma \frac{3}{4\pi}|\boldsymbol{\epsilon}\cdot\hat{\mathbf{n}}|^2\diff{\Omega}\;.
\end{equation}
Il termine che moltiplica $\sigma$ rappresenta una distribuzione angolare, per cui l'integrale sull'angolo solido deve fare uno. Otteniamo quindi per la distribuzione angolare la seguente espressione:
\begin{equation}
\frac{3}{4\pi}\frac{1}{2}(1-\cos^2\theta)=\frac{3}{8\pi}\sin^2\theta\;.
\end{equation}
Osserviamo che non abbiamo elettroni emessi lungo la direzione di propagazione dell'onda incidente in quanto il campo dell'onda è ortogonale a $\hat{\mathbf{z}}$ e quindi gli elettroni non vengono accelerati;
\item per un'onda polarizzata linearmente lungo $\hat{\mathbf{x}}$ si ha:
\begin{equation}
\diff{\sigma}=\sigma \frac{3}{4\pi}\diff{\Omega}\sin^2\theta\cos^2\varphi\;.
\end{equation}
\end{enumerate}
\section{Effetto Stark sull'atomo di idrogeno}
In teoria perturbativa, ricordiamo che lo shift energetico si scriveva come:
$$
\Delta E=\bra i|V|n\ket\frac{1}{E_0-E_n}\bra n|V|i\ket\equiv \bra \psi_0|V|\psi^{(1)}\ket\;,
$$
dove $\psi^{(1)}$ è la correzione al primo ordine dello stato $\psi_0$. Non sempre si conosce $\psi^{(1)}$, ma in alcuni casi, come l'effetto Stark sull'atomo di idrogeno, sì. L'Hamiltoniana $H_0$ e la perturbazione $V$ sono le solite:
\begin{equation}
H_0=\frac{\mathbf{p}^2}{2m}-\frac{e^2}{r},\qquad V=-\mathbf{d}\cdot\mathbf{E}=ezE\;.
\end{equation}
L'equazione di \Sch\; può essere sviluppata allora in serie:
\begin{align*}
H\psi &= (\mathcal{E}_0+\mathcal{E}_1+\mathcal{E}_2+\cdots)(\psi_0+\psi^{(1)}+\psi^{(2)}+\cdots)\;, \\
(H_0+V)(\psi_0+\psi^{(1)}+\psi^{(2)}+\cdots)&=\mathcal{E}_0\psi_0+\mathcal{E}_0\psi^{(1)}\;, \\
H_0\psi_0+H_0\psi^{(1)}+V\psi_0 &= \mathcal{E}_0\psi_0+\mathcal{E}_0\psi^{(1)}\;, \\
H_0\psi^{(1)}+V\psi_0 &= \mathcal{E}_0\psi^{(1)}\;.
\end{align*}
Sappiamo che $\psi_0=(\pi a^3)^{-1/2}e^{-r/a}$, $ezE=erE\cos\theta$. Cerchiamo allora una soluzione $\psi^{(1)}$ separata, della forma $\psi^{(1)}=R(r)\cos\theta$. Introducendo la \textit{polarizzabilità} $\alpha$ ($[\alpha]=a^3$ in CGS), possiamo scrivere $\Delta\mathcal{E}=-\frac{1}{2}\alpha E^2$. In coordinate polari si ha:
\begin{equation}
H_0=-\frac{\hbar^2}{2m}\left(\frac{1}{r^2}\frac{\partial}{\partial r}r^2\frac{\partial}{\partial r}-\frac{L(L+1)}{r^2}\right)-\frac{e^2}{r}\;.
\end{equation}
In particolare, $\psi^{(1)}\propto Y_{10}=\sqrt{\frac{3}{4\pi}}\cos\theta$, quindi, in unità atomiche:
\begin{equation}
H_0\psi^{(1)}=-\frac{1}{2}\left(\frac{1}{r^2}\frac{\partial}{\partial r}r^2\frac{\partial}{\partial r}-\frac{2}{r^2}\right)R(r)\cos\theta-\frac{1}{r}R(r)\cos\theta\;,
\end{equation}
dato che $Y_{10}$ è autostato di $L$ con autovalore 1. L'equazione allora diventa:
\begin{equation}
-\frac{1}{2}\left(\frac{1}{r^2}\frac{\partial}{\partial r}r^2\frac{\partial}{\partial r}-\frac{2}{r^2}\right)R(r)\cos\theta-\frac{R(r)}{r}\cos\theta+Er\cos\theta\psi_0+\frac{R(r)}{2}\cos\theta=0\;.
\end{equation}
Assumiamo che lo stato finale sia una deformazione dello stato iniziale, cioè $R(r)=e^{-r}f(r)/2\pi$:
\begin{equation}
2f-2rf'(r-1)-rf''+2Er^2=0\;.
\end{equation}
Cerchiamo infine per $f$ un'espressione polinomiale: $f(r)=a+br+cr^2$; sostituendo si trova la soluzione:
\begin{equation}
f(r)=-Er\left(1+\frac{r}{2}\right)\qquad\Longrightarrow\qquad \psi^{(1)}=-\psi_0\cos\theta Er\left(1+\frac{r}{2}\right)\;.
\end{equation}
Calcolando l'integrale per lo shift si trova invece:
\begin{equation}
\Delta\mathcal{E}=-\frac{9}{4}a^3E^2\;,
\end{equation}
da cui si ricava l'espressione per la polarizzabilità dell'atomo di idrogeno (in unità atomiche):
\begin{equation}
\alpha=\frac{9}{2}a^3\;.
\end{equation}
\section{Atomo di idrogeno con struttura del protone}
Consideriamo adesso nella descrizione dell'atomo di idrogeno la struttura del protone: esso ha spin 1/2, quindi genera un campo magnetico. L'interazione tra elettrone e il campo magnetico è data da:
\begin{equation}
H_I=\mu_B\mathbf{B}\cdot(\boldsymbol{\ell}+g\mathbf{s})\;.
\end{equation}
Il protone avrà un suo momento magnetico:
\begin{equation}
\boldsymbol{\mu}_N=g_p\frac{e\hbar}{2m_pc}\mathbf{I}\;,
\end{equation}
dove con $\mathbf{I}$ abbiamo indicato lo spin del protone. In questo caso, il momento angolare elettronico non si conserva, si conserva invece quello totale protone-elettrone.\\
Il potenziale vettore generato da $\boldsymbol{\mu}_N$ è:
\begin{equation}
\mathbf{A}=\frac{\boldsymbol{\mu}_N\wedge \mathbf{r}}{r^3}=-\boldsymbol{\mu}_N\wedge\nabla\left(\frac{1}{r}\right)\;,
\end{equation}
e il campo magnetico associato è:
\begin{equation}
\mathbf{B}=\nabla\wedge\mathbf{A}=-\nabla\wedge(\boldsymbol{\mu}_N\wedge\nabla)\frac{1}{r}=-\boldsymbol{\mu}_N\nabla^2\frac{1}{r}+\nabla(\boldsymbol{\mu}_N\cdot\nabla)\frac{1}{r}\;.
\end{equation}
Per $r\ne 0$:
\begin{equation}
\partial_i\partial_j\frac{1}{r}=\partial_i\left(-\frac{x_j}{r^3}\right)=-\frac{\delta_{ij}}{r^3}+\frac{3x_ix_j}{r^5}=-\frac{1}{r^3}\left(\delta_{ij}-\frac{3x_ix_j}{r^2}\right)\;,
\end{equation}
che è un tensore simmetrico a traccia nulla, mentre per $r=0$:
\begin{equation}
\partial_i\partial_j\frac{1}{r}=c\delta_{ij}\delta^3(r)\;.
\end{equation}
La traccia è $3c\delta^3(r)=\partial_i\partial_i\dfrac{1}{r}=\nabla^2\dfrac{1}{r}=4\pi\delta^3(r)$, da cui $c=4\pi/3$. In conclusione:
\begin{equation}
B_i=-\mu_i\frac{1}{r^3}\left(\delta_{ij}-\frac{3x_ix_j}{r^2}\right)+\frac{8}{3}\pi\mu_i\delta^3(r)\;.
\end{equation}
Mettiamoci nel caso di onda S. Il primo pezzo di $B_i$ è nullo, mentre il secondo contribuisce solo alle onde S. In più, $\boldsymbol{\ell}=0$. Allora l'Hamiltoniana di interazione è quindi:
\begin{equation}
H_I=\mu_B(\boldsymbol{\ell}+g\mathbf{s})g_p\mu_N\left[-\frac{I_j}{3}(\delta_{ij}-3n_in_j)+\frac{8}{3}\pi \delta^3(r)\mathbf{I}\right]\;.
\end{equation}
Indicheremo con $\mathbf{F}=\mathbf{J}+\mathbf{I}$ il momento angolare totale del sistema (che si conserva). Consideriamo lo stato fondamentale dell'atomo di idrogeno (1s) che ha degenerazione 4 (2 per lo spin dell'elettrone, e 2 per lo spin del protone). Gli stati possibili sono $|+,+\ket,|-,-\ket,|+,-\ket,|-,+\ket$. Calcoliamo adesso:
$$
\int r^2\diff{r}\diff{\Omega}\psi_{1s}\psi_{1s}\frac{1}{r^3}(\delta_{ij}-3n_in_j)=\int \diff{r}\frac{\psi_{1s}\psi_{1s}}{r}\left(4\pi\delta_{ij}-3\frac{4}{3}\pi\delta_{ij}\right)=0\;.
$$
La perturbazione allora sarà della forma:
\begin{equation}
V=\mu_B\mu_Ngg_p\frac{8}{3}\pi|\psi_{1s}(0)|^2\mathbf{s}\cdot\mathbf{I}\equiv A \mathbf{s}\cdot\mathbf{I}\;,
\end{equation}
dato che $\mathbf{L}=0$ per il protone e per l'elettrone, $\mathbf{F}=\mathbf{s}+\mathbf{I}$. Invertendo l'espressione:
\begin{equation}
\mathbf{F}^2=\mathbf{s}^2+2\mathbf{s}\cdot\mathbf{I}\quad \Longrightarrow\quad 2\mathbf{s}\cdot\mathbf{I}=\mathbf{F}^2-\mathbf{s}^2-\mathbf{I}^2\;.
\end{equation}
Possiamo riscrivere $V$ come:
$$
V=\frac{A}{2}(\mathbf{F}^2-\mathbf{s}-\mathbf{I}^2)\;.
$$
Gli autovalori di $\mathbf{s}^2$ e $\mathbf{I}^2$ sono rispettivamente $s(s+1)$ e $I(I+1)$. Dato che nel nostro caso $s=I=1/2$, otteniamo
\begin{equation}
V=\frac{A}{2}\left(\mathbf{F}^2-\frac{3}{2}\right)\;.
\end{equation}
Otteniamo quindi:
\begin{equation}
E_{F=1}=\frac{A}{2}\left(2-\frac{3}{2}\right)=\frac{A}{4}, \quad E_{F=0}=-\frac{3}{4}A\;,
\end{equation}
quindi $\Delta E=A$. Si ha inoltre, sperimentalmente:
\begin{equation}
\omega=\frac{\Delta E}{\hbar}=1\;420\;405\;751.768\pm 0.001\;\mbox{Hz}\;,
\end{equation}
a cui corrisponde una lunghezza d'onda:
\begin{equation}
\lambda=21.0605\;\mbox{cm}\;.
\end{equation}
\section{Ione $Z$ con due elettroni}
\begin{equation}
H=\frac{\mathbf{p}_1^2}{2}+\frac{\mathbf{p}_2^2}{2}-\frac{Ze^2}{r_1}-\frac{Ze^2}{r_2}+\frac{e^2}{|\mathbf{r_1}-\mathbf{r}_2|}\equiv H_0+\frac{e^2}{|\mathbf{r}_1-\mathbf{r}_2|}\;.
\end{equation}
L'Hamiltoniana $H_0$ avrà una funzione d'onda separabile $\Psi(\mathbf{r}_1,\mathbf{r}_2)=\psi_{1s}(\mathbf{r}_1)\psi_{1s}(\mathbf{r}_2)$. Sappiamo già che l'energia imperturbata è, in unità naturali, $E_0=-Z^2$, mentre la correzione al primo ordine è:
\begin{equation}
E^{(1)}=E_0+\frac{5}{8}Z=2\frac{Z^2}{2}-2Z^2+\frac{5}{8}Z\simeq -2.75\;\mbox{u}\; (Z=2)\;.
\end{equation}
Per migliorare la nostra approssimazione possiamo usare il metodo variazionale: l'autostato di $H_0$ è dato da:
\begin{equation}
\Psi(\mathbf{r}_1,\mathbf{r}_2)=\left(\frac{Z^{3/2}}{\sqrt{\pi}}\right)^2e^{-Zr_1}e^{-Zr_2}\;.
\end{equation}
Prendiamo quindi come parametro su cui effettuare il metodo variazionale una carica effettiva $Z_1$, cioè riscriviamo la funzione d'onda come:
\begin{equation}
\Psi(\mathbf{r}_1,\mathbf{r}_2)=Ce^{-Z_1r_1}e^{-Z_1r_2}\;.
\end{equation}
L'energia cinetica era inizialmente $2\cdot\dfrac{Z^2}{2}$, e adesso diventa $2\cdot\dfrac{Z_1^2}{2}$, mentre l'energia potenziale iniziale, $-2Z^2$ diventa adesso $-2ZZ_1$. In totale quindi:
\begin{equation}
E(Z_1)=2\frac{Z_1^2}{2}-2ZZ_1+\frac{5}{8}Z_1\;.
\end{equation}
Il mimino è dato da:
\begin{equation}
\pdev{E(Z_1)}{Z_1}=2Z_1-2Z+\frac{5}{8}=0\qquad \Longrightarrow\qquad Z_1=Z-\frac{5}{16}\;.
\end{equation}
Allora:
\begin{equation}
E_{\mathrm{min}}=-\left(Z-\frac{5}{16}\right)^2=-2.848\;\mbox{u}\quad (Z=2)\;.
\end{equation}
\chapter{Sistemi con più particelle identiche}
\section{Simmetria e antisimmetria della funzione d'onda}
Uno spinore in generale si può scrivere $\psi(x)=\left(\begin{matrix}
f(x) \\
g(x)
\end{matrix}\right)\equiv \psi(x,\sigma)$ dove $x$ è la variabile orbitale e $\sigma=1,2$ indica la componente. Scriveremo $\psi(q)$, $q=(x,\sigma)$. Se abbiamo uno stato $\psi=a(q_1)b(q_2)$, cioè fattorizzato, allora le distribuzioni di probabilità delle singole particelle sono indipendenti, cioè $|\psi|^2=|a(q_1)|^2|b(q_2)|^2$. Possiamo definire diversi tipi di densità di probabilità: $\delta(q-q_1)$, che rappresenta la densità di probabilità della particella 1, $\delta(q-q_2)$, che rappresenta la densità di probabilità della particella 2, oppure $\delta_T=\delta(q-q_1)+\delta(q-q_2)$, che rappresenta la densità di probabilità di beccare una delle due particelle (non importa quale). \\
Se la funzione d'onda è fattorizzabile, $\psi=\psi_1(q_1)\psi_2(q_2)$, con $\psi_1\in\ham_1$ e $\psi_2\in\ham_2$, allora $\psi\in \ham_1\otimes\ham_2$. \\
In Meccanica Quantistica, $n$ particelle sono identiche se e solo se ogni operatore è simmetrico rispetto a qualunque permutazione delle coordinate $q_n$ (inclusi i numeri quantici). Nel caso $n=2$, il gruppo delle permutazioni ha $n!=2$ elementi, ossia l'identità e lo scambio $P_{12}$, entrambi operatori unitari. Le permutazioni commutano con qualunque operatore. Infatti, sia $O(q_1,q_2)$ un operatore, allora:
\begin{equation}
P_{12}O(q_1,q_2)P_{12}^{-1}=O(q_2,q_1)=O(q_1,q_2)\qquad \Longrightarrow \qquad P_{12}O=OP_{12}\;.
\end{equation}
Proviamo a diagonalizzare $P_{12}$: dato che è unitario, dovrà essere:
\begin{equation}
P_{12}\psi(q_1,q_2)=\psi(q_2,q_1)=e^{i\varphi}\psi(q_1,q_2)\;,
\end{equation}
dato che $P_{12}^2=1$, $\varphi$ può assumere unicamente i valori $0,\pi$. Allora:
\begin{equation}
P_{12}\psi(q_1,q_2)=\begin{cases}
\psi(q_1,q_2)\qquad (\varphi=0)\quad\longrightarrow\quad\psi\;\mbox{simmetrica}\;, \\
\\
-\psi(q_1,q_2)\qquad (\varphi=\pi)\quad\longrightarrow\quad\psi\;\mbox{antisimmetrica}\;.
\end{cases}
\end{equation}
Ogni funzione d'onda deve necessariamente essere autostato delle permutazioni.\\
Possiamo, data una qualunque funzione d'onda $\psi$, scrivere sempre:
\begin{equation}
\psi=\alpha\underbrace{\psi_S}_{\mbox{simmetrica}}+\beta\underbrace{\psi_A}_{\mbox{antisimmetrica}}\;.
\end{equation}
Lo spazio delle funzioni simmetriche è ortogonale a quello delle funzioni antisimmetriche. Abbiamo cioè decomposto lo spazio di Hilbert: $\ham=\ham_S+\ham_A$ e non esiste alcun operatore che consente di passare da una funzione simmetrica ad una antisimmetrica o viceversa. Allora prese due particelle descritte dalle funzioni d'onda $\psi_1,\psi_2$ tali che:
\begin{align*}
\psi_1 &= \alpha_1\varphi_1^S+\beta_1\varphi_1^A\;, \\
\psi_2 &= \alpha_2\varphi_2^S+\beta_2\varphi_2^A\;,
\end{align*}
abbiamo:
\begin{equation}
\bra\psi_1|\psi_2\ket=\alpha_1\alpha_2^*\int\varphi_1^S\varphi_2^{S*}+\beta_1\beta_2^*\int\varphi_1^A\varphi_2^{A*}\;.
\end{equation}
Quindi si perderebbe l'informazione sulle fasi dei singoli $\alpha_i,\beta_i$, cioè risulterebbe impossibile misurarla. Si conclude che tutte le particelle di uno stesso tipo devono essere solamente simmetriche o solamente antisimmetriche. \\
\textbf{Postulato di simmetrizzazione.} \\
Le particelle aventi spin semintero sono descritte da funzioni d'onda totalmente antisimmetriche, mentre quelle aventi spin intero sono descritte da funzioni d'onda completamente simmetriche.
\begin{dfn} Uno stato che non può essere fattorizzato si dice \textit{entangled}.
\end{dfn}
Consideriamo uno stato (simmetrico o antisimmetrico):
\begin{equation}
\psi(x_1,x_2)=\frac{a(x_1)b(x_2)\pm a(x_2)b(x_1)}{\sqrt{2}}\;,
\end{equation}
e calcoliamo il valor medio della densità $\rho=\delta(x-x_1)+\delta(x-x_2)$:
\begin{equation}
\int \frac{1}{\sqrt{2}}(a(x_1)b(x_2)\pm a(x_2)b(x_1))(\delta(x-x_1)+\delta(x-x_2))\frac{1}{\sqrt{2}}(a(x_1)b(x_2)\pm a(x_2)b(x_1))\;.
\end{equation}
Notiamo che:
\begin{align}
&a(x_1)b(x_2)(\delta(x-x_1)+\delta(x-x_2))(a(x_1)b(x_2)\pm a(x_2)b(x_1)= \\ \notag
&\pm a(x_2)b(x_1)(\delta(x-x_1)+\delta(x-x_2))(a(x_1)b(x_2)\pm a(x_2)b(x_1))\;.
\end{align}
Quindi possiamo scrivere:
\begin{align}
\bra \psi|\rho|\psi\ket &= \int_{x_1x_2}a(x_1)b(x_2)[\delta(x-x_1)+\delta(x-x_2)](a(x_1)b(x_2)\pm a(x_2)b(x_1)) \\
&= |a(x)|^2+|b(x)|^2\pm 2a(x)b(x)\int a(y)b(y)\diff{y}\;,
\end{align}
dove è comparso un termine di interferenza, il cui peso dipende da quanto sono sovrapposte le due funzioni d'onda. Questo discorso si estende con facilità al caso di $n$ particelle semplicemente definendo i due proiettori:
\begin{align}
\mathcal{S} &= \frac{1}{n!}\sum P\;, \\ \notag 
\mathcal{A} &= \frac{1}{n!}\sum (-1)^pP\;,
\end{align}
dove $p$ è il numero di permutazioni. Possiamo scrivere nel caso di $n$ particelle funzioni d'onda totalmente simmetriche o antisimmetriche.
\section{Simmetrizzazione degli stati}
La simmetrizzazione ha un effetto importante sugli autostati dell'Hamiltoniana, in quanto la degenerazione si riduce dato che le funzioni d'onda possono essere solamente simmetriche o antisimmetriche. Supponiamo di avere un sistema di fermioni non interagenti, descritto dall'Hamiltoniana:
\begin{equation}
H=\sum_i H_0(q_i),\qquad H_0=\frac{\mathbf{p}^2}{2m}+V\;.
\end{equation}
$H$ è separabile, quindi i suoi autostati saranno della forma $\Psi=\varphi_{a_1}(q_1)\cdot\cdots\cdot\varphi_{a_n}(q_n)$ con autovalore $E=E_{a_1}+\cdots+E_{a_n}$ e degenerazione $n!$. Di queste $n!$ però dobbiamo tenere solamente quelle totalmente antisimmetriche (i fermioni hanno spin semintero). Nel caso $a_i\ne a_j$ per $i\ne j$, allora esiste una sola funzione totalmente antisimmetrica, ossia:
\begin{equation}
\Psi=\frac{1}{\sqrt{n!}}\sum (-1)^p\varphi_{a_1}(q_1)\cdots\varphi_{a_n}(q_n)\;.
\end{equation}
In particolare, si ha $\varphi_{a_i}\ne\varphi_{a_j}$ per $i\ne j$, in altre parole in ogni stato di $H_0$ vi può essere un solo fermione (principio di Pauli). Notiamo che:
\begin{equation}
\Psi=\frac{1}{\sqrt{n}}\left|\begin{matrix}
\varphi_{a_1}(q_1) & \cdots & \varphi_{a_1}(q_n) \\
\varphi_{a_2}(q_1) & \cdots & \varphi_{a_2}(q_n) \\
\vdots & {} & \vdots \\
\varphi_{a_n}(q_1) & \cdots & \varphi_{a_n}(q_n)
\end{matrix}\right|\;.
\end{equation}
\subsection{Particelle distinguibili}
Supponiamo di avere due particelle distinguibili con spin zero che collidono. Sappiamo che la sezione d'urto si scrive $\diff{\sigma}=|F|^2\diff{\Omega}$ dove $f=-\dfrac{m}{2\pi\hbar^2}\bra f|H_I|i\ket$ (in approssimazione di Born). Nel sistema del centro di massa le due particelle avranno sempre impulsi opposti, quindi gli stati iniziali e finali si scriveranno:
\begin{align*}
|i\ket&=|\mathbf{p},-\mathbf{p}\ket\;, \\
|f\ket&=|\mathbf{p}',-\mathbf{p}'\ket\;.
\end{align*}
L'ampiezza $f$ dipenderà in questo caso dall'angolo polare $\theta$ tra le direzioni di $\mathbf{p}$ e $\mathbf{p}'$ e dal tipo di interazione (operatore $S$): $f(\theta)=\bra \mathbf{p}',-\mathbf{p}'|S|\mathbf{p},-\mathbf{p}\ket$ e la sezione d'urto della particella 1 o della particella 2 sarà rispettivamente proporzionale a $|f(\theta)|^2$ e $|f(\pi-\theta)|^2$. Nel caso in cui avessimo dei rivelatori ciechi, cioè non sensibili al tipo di particella (ad esempio calorimetri), allora la sezione d'urto sarebbe proporzionale a $|f(\theta)|^2+|f(\pi-\theta)|^2$.
\subsection{Particelle indistinguibili}
Se le particelle sono indistinguibili come due particelle $\alpha$ (spin zero), gli stati devono essere simmetrici, quindi in questo caso:
\begin{align}
|i\ket &= \frac{|\mathbf{p},-\mathbf{p}\ket+|-\mathbf{p},\mathbf{p}\ket}{\sqrt{2}}\;, \notag \\
|f\ket &= \frac{|\mathbf{p}',-\mathbf{p}'\ket+|-\mathbf{p}',\mathbf{p}'\ket}{\sqrt{2}}\;.
\end{align}
Di conseguenza:
\begin{align}
F = \bra i|S|f\ket &= \frac{1}{2}(\bra\mathbf{p}',-\mathbf{p}|+\bra -\mathbf{p}',\mathbf{p}|)S(|\mathbf{p},-\mathbf{p}'\ket+|-\mathbf{p},\mathbf{p}\ket) \notag \\
&=\frac{1}{2}[f(\theta)+f(\pi-\theta)+f(\pi-\theta)+f(\theta)]=f(\theta)+f(\pi-\theta)  \notag \\
&= f(\theta)+f(\pi-\theta)\;,
\end{align}
e quindi $P=|f(\theta)+f(\pi-\theta)|^2$. \\
Nel caso di $n$ fermioni, avevamo scritto la funzione d'onda totale come:
$$
\Psi=\frac{1}{\sqrt{n!}}\sum (-1)^P\varphi_{a_1}(Pq_1)\cdots\varphi_{a_n}(Pq_n)=\sqrt{n!}\mathcal{A}\varphi_{a_1}(q_1)\cdots\varphi_{a_n}(q_n)\;,
$$
dove $\mathcal{A}=\sum (-1)^PP$ è il proiettore sugli stati antisimmetrici. Esistono sostanzialmente due tipi di operatori: quelli ad una particella, cioè tali che:
\begin{equation}
\lag_1=\sum_i\lag(q_i)\;,
\end{equation}
con $\lag(q_i)$ che agisce solamente sulle coordinate di una singola particella; e quelli a due particelle (ad esempio l'interazione coulombiana):
\begin{equation}
\mathcal{U}=\sum_{i<j}V(q_i,q_j)\;.
\end{equation}
Scriviamo adesso gli elementi di matrice degli operatori ad una particella (in un sistema a $n$ particelle), cominciando da quelli diagonali ($|\Psi\ket=\sqrt{n!}\mathcal{A}|\psi_0\ket$):
\begin{align}
\bra\Psi|\lag_1|\Psi\ket &= n!\bra \psi_0|\mathcal{A}\lag_1\mathcal{A}|\psi_0\ket \qquad (\lag_1\;\mbox{commuta con}\;\mathcal{A}) \notag \\
&= n!\bra\psi_0|\lag_1\mathcal{A}^2|\psi_0\ket=\bra\psi_0|\lag_1\mathcal{A}|\psi_0\ket \notag \\
&= \int_{q_1\cdots q_n} \varphi_{a_1}^*(q_1)\cdots\varphi_{a_n}^*(q_n)(\lag(q_1)+\cdots+\lag(q_n))\sum_p(-1)^p\varphi_{a_1}(Pq_1)\cdots\varphi_{a_n}(Pq_n)\;.
\end{align}
Facciamo l'ulteriore ipotesi che le $\varphi_{a_i}$ siano autostati di $H$ (con $\varphi_{a_i}\perp\varphi_{a_j}$ per $i\ne j$). Consideriamo il termine:
\begin{align*}
&\int \varphi_{a_1}^*(q_1)\cdots\varphi_{a_n}^*(q_n)\underbrace{\lag(q_1)}_{\mbox{agisce solo su}\; q_1}(\varphi_{a_1}(q_1)\cdots\varphi_{a_n}(q_n) \\
&= \int \varphi_{a_1}^*(q_1)\lag(q_1)\varphi_{a_1}(q_1)\cdot\prod_{i\ne 1}\underbrace{\int|\varphi_{a_i}(q_i)|^2}_{=1\;\forall i}=\bra a_i|\lag(q_1)|a_i\ket\;.
\end{align*}
Tutti gli altri sono nulli in quanto compare sempre un prodotto scalare tra due autostati ortogonali dell'Hamiltoniana. Quindi:
\begin{equation}
\bra\Psi|\lag_1|\Psi\ket=\sum_i\bra a_i|\lag(q_i)|a_i\ket\;.
\end{equation}
Per gli operatori a due particelle vale un risultato analogo:
\begin{equation}
\bra\Psi|\mathcal{U}|\Psi\ket=\sum_{i<j}(\bra ij|V|ij\ket-\bra ij|V|ji\ket)=\frac{1}{2}\sum_{i,j}(\bra ij|V|ij\ket-\bra ij|V|ji\ket)\;.
\end{equation}
\chapter{Seconda quantizzazione}
\section{Rappresentazione di Fock}
Supponiamo di conoscere gli autostati e i relativi autovalori di un'Hamiltoniana di singola particella $H_0=\dfrac{\mathbf{p}^2}{2m}+V(r)$, $|i\ket$ tali che $H_0|i\ket=E_i|i\ket$ (trascuriamo lo spin). Fissato un autostato qualunque, può verificarsi il caso in cui nessuna particella occupa lo stato, che indicheremo con $|\Omega\ket$. Vogliamo adesso creare una particella nello stato j-esimo. A tal scopo definiamo un operatore di creazione tale che $\adj{a}_j|\Omega\ket=|1_j\ket$ (cioè una particella nello stato j-esimo), con la condizione $\bra 1_i|1_j\ket=\delta_{ij}$, e un operatore di distruzione $a_j|1_j\ket=|\Omega\ket$ che soddisfano la seguente algebra:
\begin{align}
[a_i,a_j] &= 0 \qquad \forall i,j \notag\;, \\
[\adj{a}_i,\adj{a}_j] &= 0 \qquad \forall i,j \notag\;, \\
[a_i,\adj{a}_j]&=\delta_{ij}\;.
\end{align}
Quindi $|\Omega\ket$ (vuoto) è definito come lo stato per cui $a_i|\Omega\ket=0$ per ogni $i$. In generale, se dal vuoto vogliamo creare $n_i$ particelle nello stato $i$-esimo ($i=1,2,\ldots$) scriveremo lo stato in \textit{rappresentazione di Fock}:
\begin{equation}
\frac{(\adj{a}_1)^{n_1}}{\sqrt{n_1!}}\frac{(\adj{a}_2)^{n_2}}{\sqrt{n_2!}}\cdots|\Omega\ket\;.
\end{equation}
L'energia totale sarà:
\begin{equation}
E=\sum_i n_iE_i\;,
\end{equation}
dove $n_i$ è l'occupazione dell'$i$-esimo stato e $E_i$ è l'energia di esso. Ricordando che (oscillatore armonico) l'operatore $\adj{a}a$ aveva autovalori $n$, possiamo riscrivere l'Hamiltoniana come:
\begin{equation}
H=\sum_i E_i\adj{a}_ia_i\;.
\end{equation}
Prendiamo un operatore $A$ di cui sono noti gli elementi di matrice su una singola particella, cioè $A_{ji}\equiv\bra j|A|i\ket$. Come diventa $A$ in rappresentazione di Fock? Si ha:
\begin{equation}
A^{(F)}=\sum_{r,s}\adj{a}_rA_{rs}a_s\;.
\end{equation}
Verifichiamo:
\begin{equation}
(A^{(F)})_{ji}=\bra\Omega| a_j\sum_{r,s}\adj{a}_rA_{rs}a_s\adj{a}_i|\Omega\ket\;.
\end{equation}
Dalle regole di commutazione possiamo sostituire:
\begin{align}
a_j\adj{a}_r &= \adj{a}_ra_j+\delta_{jr} \notag\;, \\
a_s\adj{a}_i &= \adj{a}_ia_s+\delta_{is}\;,
\end{align}
ottenendo:
\begin{align}
(A^{(F)})_{ij}&= \bra\Omega|\left[\sum_{r,s}(\adj{a}_ra_j+\delta_{jr})A_{rs}(\adj{a}_ia_s+\delta_{is})\right]|\Omega\ket=\bra\Omega|\sum_{r,s}\delta_{jr}A_{rs}\delta_{is}|\Omega\ket \notag \\
&= A_{ji}\bra\Omega|\Omega\ket=A_{ji}\;.
\end{align}
Per i fermioni si definiscono due operatori analoghi, $b_i$ e $\adj{b}_i$ tali che:
$$
b_i|\Omega\ket=0 \qquad \qquad \adj{b}_i|\Omega\ket=|1_i\ket\;.
$$
L'algebra a cui obbediscono è:
\begin{align}
\{b_i,b_j\} &= 0 \qquad \forall i,j \notag\;, \\
\{\adj{b}_i,\adj{b}_j\} &= 0 \qquad \forall i,j\notag\;, \\
\{b_i,\adj{b}_j\}&=\delta_{ij}\;,
\end{align}
dove $\{A,B\}\equiv AB+BA$ è l'anticommutatore. In questa algebra è implicito il principio di esclusione di Pauli, infatti se $i=j$ si ha $0=\{\adj{b}_i,\adj{b}_i\}=2(\adj{b}_i)^2$, da cui $(\adj{b}_i)^2=0$, ossia non vi può essere più di un fermione in uno stato. È implicita anche la disparità dei fermioni, infatti $\adj{b}_i\adj{b}_j|\Omega\ket=-\adj{b}_j\adj{b}_i|\Omega\ket$.
\section{Quantizzazione del campo elettromagnetico}
Vogliamo adesso ricavare l'Hamiltoniana del campo EM partendo dalla conoscenza delle equazioni di Heisenberg. \\
Sappiamo che il potenziale vettore $\mathbf{A}$ deve soddisfare l'equazione delle onde:
\begin{equation}
\frac{1}{c^2}\pdev[2]{\mathbf{A}}{t}-\nabla^2\mathbf{A}=0\;,
\end{equation}
la cui soluzione è, classicamente:
\begin{equation}
\mathbf{A}(\mathbf{x},t)=\int\frac{\diff^3{k}}{(2\pi)^3} N(\omega)\left[\mathbf{e}_{\lambda}a_{\lambda}(\mathbf{k})e^{i\mathbf{k}\cdot\mathbf{x}-i\omega t}+\mathbf{e}^*_{\lambda}\adj{a_{\lambda}}e^{-i\mathbf{k}\cdot\mathbf{x}-i\omega t}\right]\;,
\end{equation}
con $\lambda=1,2$. $\mathbf{e}_{\lambda}$ rappresenta la polarizzazione dell'onda. Solitamente il potenziale si sceglie in gauge di Coulomb, cioè tale che $\nabla\cdot\mathbf{A}=0$; questa condizione in trasformata di Fourier si traduce nell'imporre che la trasformata sia ortogonale al vettore d'onda $\mathbf{k}$. Inoltre se scegliamo un versore lungo $\mathbf{k}$ otteniamo l'ulteriore condizione che $\mathbf{k}\cdot\mathbf{e}_{\lambda}=0$, cioè la polarizzazione dell'onda è anch'essa ortogonale al vettore d'onda. Si verifica che il potenziale $\mathbf{A}$ espresso dalla (12.2.2) è effettivamente soluzione dell'equazione di d'Alembert per sostituzione e ricordando che $\omega=c|\mathbf{k}|$. \\
Nella trattazione quantistica dobbiamo interpretare $\mathbf{A}$ come operatore, la quale cosa si riduce a interpretare come operatori $a_{\lambda}(\mathbf{k}),\adj{a_{\lambda}}(\mathbf{k})$. $\mathbf{A}$ dipende dal tempo, quindi sarà un operatore di Heisenberg. Ponendo:
\begin{align}
a_{\lambda}(\mathbf{k},t)&= a_{\lambda}(\mathbf{k})e^{-i\omega t} \notag\;, \\
\adj{a_{\lambda}}(\mathbf{k},t) &= \adj{a_{\lambda}}(\mathbf{k})e^{-i\omega t}\;,
\end{align}
otteniamo che l'evoluzione temporale degli operatori $a_{\lambda}$ e $\adj{a_{\lambda}}$ è la stessa degli operatori di creazione e distruzione che avevano già visto per l'oscillatore armonico. È ragionevole, dunque, aspettarsi che l'Hamiltoniana che generi delle evoluzioni di Heisenberg di questo tipo sia della forma:
\begin{equation}
H=\int \frac{\diff^3{k}}{(2\pi)^3}\hbar\omega\sum \adj{a_{\lambda}}(\mathbf{k})a_{\lambda}(\mathbf{k})\;,
\end{equation}
unitamente alla regola di commutazione $[a,\adj{a}]$ che si traduce in:
\begin{equation}
[a_{\lambda}(\mathbf{k}),\adj{a}_{\lambda'}(\mathbf{k}')]=(2\pi)^3\delta_{\lambda\lambda'}\delta^3(\mathbf{k}-\mathbf{k}')\;.
\end{equation}
L'Hamiltoniana (12.2.4) genera effettivamente l'evoluzione $\mathbf{A}(\mathbf{x},t)$. Resta in conclusione da dimostrare che $H$ sia l'Hamiltoniana del campo EM, cioè:
\begin{equation}
\int \frac{\diff^3{k}}{(2\pi)^3}\hbar\omega\adj{a_{\lambda}}(\mathbf{k})a_{\lambda}(\mathbf{k})=\frac{1}{8\pi}\int\diff^3{x}(\mathbf{E}^2+\mathbf{B}^2)\;.
\end{equation}
Si ha:
\begin{align}
\mathbf{E} &= -\frac{1}{c}\pdev{\mathbf{A}}{t} = \frac{i}{c}\int\frac{\diff^3{k}}{(2\pi)^3}N\left[
\mathbf{e}_{\lambda}a_{\lambda}(\mathbf{k})\omega e^{i(\mathbf{k}\cdot\mathbf{x}-\omega t)}-
\mathbf{e}_{\lambda}^* \adj{a_{\lambda}}(\mathbf{k})\omega e^{-i(\mathbf{k}\cdot\mathbf{x}-\omega t)}\right] \notag\;, \\
\mathbf{B} &= \nabla\wedge\mathbf{A}=i\int\frac{\diff^3{k}}{(2\pi)^3}N\left[(\mathbf{k}\wedge\mathbf{e}_{\lambda})a_{\lambda}(\mathbf{k})e^{i(\mathbf{k}\cdot\mathbf{x}-\omega t)}-
(\mathbf{k}\wedge\mathbf{e}_{\lambda}^*)\adj{a_{\lambda}}(\mathbf{k})e^{-i(\mathbf{k}\cdot\mathbf{x}-\omega t)}\right]\;.
\end{align}
Consideriamo adesso il primo termine misto del quadrato di $\mathbf{E}$:
\begin{equation}
\int\diff^3{x}\iint \frac{\diff^3{k}}{(2\pi)^3}\frac{\diff^3{q}}{(2\pi)^3}\left[
\mathbf{e}_{\lambda}(\mathbf{k})a_{\lambda}\mathbf{e}_{\lambda}^*(\mathbf{q})\adj{a_{\lambda'}}(\mathbf{q})\omega(\mathbf{k})\omega(\mathbf{q})e^{i(\mathbf{k}-\mathbf{q})\cdot\mathbf{x}}e^{-i(\omega_k-\omega_q)t}\right]\;.
\end{equation}
Integrando sulle $x$ l'esponenziale $e^{i(\mathbf{k}-\mathbf{q})\cdot\mathbf{x}}$ porta un termine $(2\pi)^3\delta^3(\mathbf{k}-\mathbf{q})$, che sparisce integrando su $\mathbf{q}$: quindi rimaniamo con:
\begin{equation}
\int\frac{\diff^3{k}}{(2\pi)^3}\left(\mathbf{e}_{\lambda}\mathbf{k}\mathbf{e}_{\lambda'}^*(\mathbf{k})a_{\lambda}(\mathbf{k})\adj{a_{\lambda'}}(\mathbf{k})\omega_k^2\right)\;.
\end{equation}
Il prodotto tra i versori di polarizzazione fa $\delta_{\lambda\lambda'}$, quindi sommando su $\lambda$ rimane solo il termine con $\lambda=\lambda'$:
\begin{equation}
\int \frac{\diff^3{k}}{(2\pi)^3}\omega^2 a_{\lambda}(\mathbf{k})\adj{a_{\lambda}}(\mathbf{k})\;.
\end{equation}
Tutti i termini misti (inclusi quelli del campo magnetico) sono di questa forma. Inoltre si può dimostrare, facendo i conti, che i termini in $a_{\lambda}^2$ e $(\adj{a_{\lambda}})^2$ si elidono tutti. Allora:
\begin{equation}
H=\frac{1}{8\pi}\int\diff^3{\mathbf{x}}(\mathbf{E}^2+\mathbf{B}^2)=\frac{1}{8\pi}\int\frac{\diff^3{k}}{(2\pi)^3}4N^2\frac{\omega^2}{c^2}\left[\frac{1}{2}\sum_{\lambda}(\adj{a_{\lambda}}a_{\lambda}+a_{\lambda}\adj{a_{\lambda}})\right]\;.
\end{equation}
Scegliamo la normalizzazione $N(\omega)=c\sqrt{\dfrac{2\pi\hbar}{\omega}}$, così da ottenere:
\begin{equation}
H=\int\frac{\diff^3{k}}{(2\pi)^3}\hbar\omega\sum_{\lambda}\adj{a_{\lambda}}a_{\lambda}\;.
\end{equation}
In realtà ci sarebbe da considerare anche un termine contenente il commutatore tra i due operatori. Tuttavia, dato che l'energia è definita a meno di una costante, possiamo scegliere tale costante in modo da annullare il termine contenente il commutatore. Abbiamo in definitiva dimostrato che le due Hamiltoniane coincidono. \\
Vogliamo adesso passare ad una rappresentazione negli spazi di Fock. Definiamo uno stato vuoto $|\Omega\ket$ tale che $\adj{a_{\lambda}}(\mathbf{k})|\Omega\ket=|\mathbf{k},\lambda\ket$. Verifichiamone la consistenza:
\begin{equation}
H\adj{a_{\lambda}}(\mathbf{k})|\Omega\ket=H|\mathbf{k},\lambda\ket=\hbar\omega_k |\mathbf{k},\lambda\ket=
\hbar\omega_k\adj{a_{\lambda}}(\mathbf{k})|\Omega\ket\;.
\end{equation}
L'operatore impulso è dato da:
\begin{equation}
\mathbf{P}=\frac{1}{4\pi c}\int\mathbf{E}\wedge\mathbf{B}\diff^3{x}=\int\frac{\diff^3{k}}{(2\pi)^3}\hbar\mathbf{k}\sum_{\lambda}\adj{a_{\lambda}}(\mathbf{k})a_{\lambda}(\mathbf{k})\;.
\end{equation}
Si ha:
\begin{equation}
\mathbf{P}\adj{a_{\lambda}}(\mathbf{k})|\Omega\ket=\hbar\mathbf{k}\adj{a_{\lambda}}(\mathbf{k})|\Omega\ket\;.
\end{equation}
Quindi $\hbar\mathbf{k}$ rappresenta effettivamente l'impulso del fotone. \\
In definitiva, il potenziale vettore si scrive come:
\begin{equation}
\mathbf{A}(\mathbf{x},t)=\int \frac{\diff^3{k}}{(2\pi)^3}c\sqrt{\frac{2\pi\hbar}{\omega}}\left(\mathbf{e}_{\lambda}a_{\lambda}(\mathbf{k})e^{i(\mathbf{k}\cdot\mathbf{x}-\omega t)}+\mathbf{e}_{\lambda}^*\adj{a_{\lambda}}(\mathbf{k})e^{-i(\mathbf{k}\cdot\mathbf{x}-\omega t)}\right)\;.
\end{equation}
Consideriamo adesso l'operatore hermitiano:
\begin{equation}
\varphi(\mathbf{x},t)=\int\frac{\diff^3{k}}{(2\pi)^3}\frac{1}{\sqrt{2\omega_k}}\left[ae^{i(\mathbf{k}\cdot\mathbf{x}-\omega t)}+\adj{a}e^{-i(\mathbf{k}\cdot\mathbf{x}-\omega t)}\right]\;.
\end{equation}
Sia $x$ il quadrivettore posizione: $x^2=t^2-\mathbf{x}^2$. Calcoliamo $[\varphi(x),\varphi(y)]$. Ovviamente, se $x$ è al di fuori del cono-luce di $y$ il commutatore deve fare zero perché i due eventi sono causalmente distinti. Supponiamo $y=0$ e $x^2<0$. Dobbiamo pertanto calcolare (poniamo $\mathbf{k}\cdot\mathbf{x}-\omega t=-k^{\mu}x_{\mu}\equiv -kx$):
\begin{equation}
\left[\int\frac{\diff^3{k}}{(2\pi)^3}\frac{1}{\sqrt{2\omega_k}}(a(\mathbf{k})e^{-ikx}+\adj{a}(\mathbf{k})e^{ikx}) \int\frac{\diff^3{q}}{(2\pi)^3}\frac{1}{\sqrt{2\omega_q}}(a(\mathbf{q})+\adj{a}(\mathbf{q}))\right]=\int\frac{\diff^3{k}}{(2\pi)^3}\frac{1}{2\omega_k}(e^{-ikx}-e^{ikx})\;.
\end{equation}
Il prodotto scalare $kx$ è un invariante relativistico, ma anche $\diff^3{k}/(2\omega_k)$ lo è, infatti:
\begin{equation}
\frac{\diff^3{k}}{2\omega_k}=\int\diff^4{k}\delta(k^2)\theta(k_0)\;,
\end{equation}
con:
\begin{equation}
\delta(k^2)=\delta(k_0^2-\mathbf{k}^2)=\frac{1}{2|k_0|}\delta(k_0-|\mathbf{k})+\frac{1}{2k_0}\delta(k_0+|\mathbf{k}|)\;,
\end{equation}
che è un invariante di Lorentz. In definitiva la quantità:
\begin{equation}
\int\frac{\diff^3{k}}{(2\pi)^3}\frac{1}{2\omega_k}e^{-ikx}\equiv \Delta(x)\;,
\end{equation}
è un invariante relativistico. Il commutatore che volevamo calcolare si scrive allora $[\varphi(x),\varphi(0)]=\Delta(x)-\Delta(-x)$. Dato che $x^2<0$, esiste $\Lambda_1$ trasformazione di Lorentz tale che $\Lambda_1\mathbf{x}=-\mathbf{x}$ e $\Delta(x)$ è un invariante, segue immediatamente che $\Delta(x)=\Delta(-x)$ e dunque, come ci aspettavamo, $\Delta(x)-\Delta(-x)=0$. Quindi la presenza dell'operatore $\adj{a}$ fa sì che non sia violato il principio di causalità.
\section{Elettromagnetismo nella materia in gauge di Coulomb}
In unità CGS le equazioni di Maxwell, che legano i campi alle sorgenti, sono:
\begin{align}
\nabla\cdot\mathbf{E}(\mathbf{r},t)=4\pi\rho(\mathbf{r},t) \qquad &\qquad \nabla\cdot\mathbf{B}(\mathbf{r},t)=0\;, \notag \\
\nabla\wedge\mathbf{B}(\mathbf{r},t)=\frac{1}{c}\pdev{\mathbf{E}(\mathbf{r},t)}{t}+\frac{4\pi}{c}\mathbf{j}(\mathbf{r},t) \qquad & \qquad \nabla\wedge \mathbf{E}(\mathbf{r},t)=-\frac{1}{c}\pdev{\mathbf{B}(\mathbf{r},t)}{t}\;,
\end{align}
mentre l'equazione del moto in presenza di campo EM è quella di Lorentz:
\begin{equation}
m\pdev[2]{\mathbf{r}_a(t)}{t}=q_a\left[\mathbf{E}(\mathbf{r}_a(t),t)+\frac{1}{c}\mathbf{v}_a\wedge\mathbf{B}(\mathbf{r}_a(t),t)\right]\;,
\end{equation}
con:
\begin{align}
\rho(\mathbf{r},t)&=\sum_a q_a\delta^3(\mathbf{r}-\mathbf{r}_a(t)) \notag\;, \\
\mathbf{j}(\mathbf{r},t) &=\sum_a q_a\mathbf{v}_a\delta^3(\mathbf{r}-\mathbf{r}_a(t))\;.
\end{align}
Dalle equazioni di Maxwell discende l'equazione di continuità, che esprime la conservazione della corrente: $\partial_t\rho+\nabla\cdot\mathbf{j}=0$. Il sistema, nel complesso, ammette tre integrali primi: energia, impulso totale e momento angolare (quest'ultimo non viene riportato in quanto non utile), che sono rispettivamente:
\begin{align}
H&=\sum_a \frac{1}{2}m_a\mathbf{v}_a^2+\frac{1}{8\pi}\int\diff^3{r}\,(\mathbf{E}^2+\mathbf{B}^2) \;,\\
\mathbf{P}&= \sum_a m_a\mathbf{v}_a+\frac{1}{4\pi c}\int\diff^3{r}\,(\mathbf{E}\wedge\mathbf{B})\;.
\end{align}
Introducendo il quadripotenziale $\mathcal{A}_{\mu}=(\phi,\mathbf{A})$, le equazioni di Maxwell omogenee sono immediatamente risolte:
\begin{align}
\mathbf{E} &= -\frac{1}{c}\pdev{\mathbf{A}}{t}-\nabla\phi \notag\;, \\
\mathbf{B} &= \nabla\wedge\mathbf{A}\;,
\end{align}
mentre quelle disomogenee assumono la forma:
\begin{align}
&\nabla^2\phi = -4\pi\rho(\mathbf{r},t)-\frac{1}{c}\frac{\partial}{\partial t}\nabla\cdot\mathbf{A} \notag\;, \\
&\left(\frac{1}{c^2}\frac{\partial^2}{\partial t^2}-\nabla^2\right)\mathbf{A} = \frac{4\pi}{c}\mathbf{j}(\mathbf{r},t)-\nabla\left(\nabla\cdot\mathbf{A}+\frac{1}{c}\pdev{\phi}{t}\right)\;.
\end{align}
Il sistema presenta inoltre un'invarianza per trasformazioni di gauge:
\begin{equation}
\begin{cases}
\mathbf{A}\longmapsto \mathbf{A}+\nabla\Lambda\;, \\
\\
\phi\longmapsto\phi-\dfrac{1}{c}\dfrac{\partial\Lambda}{\partial t}\;.
\end{cases}
\end{equation}
In particolare, si usa scegliere la funzione scalare $\Lambda$ in modo tale che il potenziale vettore soddisfi la gauge di Coulomb $\bnabla\cdot\mathbf{A}=0$. Un altro modo di vedere la cosa è passare in trasformata di Fourier:
\begin{equation}
\mathbf{v}(\mathbf{r},t)=\int\frac{\diff^3{k}}{(2\pi)^3}\hat{\mathbf{v}}(\mathbf{k},t)e^{i\mathbf{k}\cdot\mathbf{r}}\;,
\end{equation}
e decomporre il vettore trasformato in una parte trasversa $\hat{\mathbf{v}}_T$ e una longitudinale $\hat{\mathbf{v}}_L$, con:
\begin{equation}
\hat{\mathbf{v}}_L=\frac{(\mathbf{k}\cdot\hat{\mathbf{v}})\mathbf{k}}{\mathbf{k}^2}\equiv \hat{k}\hat{\mathbf{v}}_L\;.
\end{equation}
Avremo dunque due componenti per il potenziale vettore (d'ora in poi, tutte le quantità sono intese come trasformate di Fourier): $\mathbf{A}_T,\mathbf{A}_L$ con $\mathbf{A}_L=\hat{k}A_L$ e $\mathbf{j}_L=\hat{k}j_L$. La parte trasversa e longitudinale soddisfano rispettivamente le equazioni:
\begin{align}
\left(\frac{1}{c^2}\frac{\partial^2}{\partial t^2}+\mathbf{k}^2\right)\mathbf{A}_T(\mathbf{k},t)&=-\frac{4\pi}{c}\mathbf{j}_T(\mathbf{k},t)\;, \\
\frac{1}{c^2}\ddot{A}_L &= \frac{4\pi}{c}j_L-\frac{ik}{c}\dot{\phi}(\mathbf{k},t)\;.
\end{align}
Derivando l'espressione del potenziale scalare:
\begin{equation}
\phi(\mathbf{k},t)=\frac{4\pi}{\mathbf{k}^2}\rho(\mathbf{k},t)+\frac{ik}{c\mathbf{k}^2}\dot{A}_L\;,
\end{equation}
e sostituendola nella (12.3.12) otteniamo:
\begin{align*}
\frac{1}{c^2}\ddot{A}_L&=\frac{4\pi}{c}j_L-\frac{ik}{c}\left(\frac{4\pi}{c}\dot{\rho}+\frac{ik}{c}\frac{1}{k^2}\ddot{A}_L\right) \\
&= \frac{4\pi}{c}j_L-\frac{4i\pi}{kc}\dot{\rho}+\frac{1}{c^2}\ddot{A}_L\;,
\end{align*}
da cui segue appunto l'equazione di continuità $\dot{\rho}(\mathbf{k},t)+ikj_L(\mathbf{k},t)=0$. Quindi, se è vero che la corrente è conservata l'equazione (12.3.12) è automaticamente verificata. Abbiamo perciò dimostrato che possiamo scegliere arbitrariamente $A_L$ (in particolare, possiamo sceglierlo nullo). Questo implica che dei quattro gradi di libertà apparentemente necessari ai fini della descrizione del sistema (ossia le quattro componenti di $\mathcal{A}_{\mu}$), uno è già determinato, quindi ne rimangono tre. In più, mettendosi in gauge di Coulomb, l'equazione per $\phi$ si riduce a quella di Poisson, quindi anche la componente 0 del quadripotenziale è univocamente determinata una volta assegnate le sorgenti. In definitiva, il sistema avrà solo due gradi di libertà. \\
Vogliamo adesso scrivere l'Hamiltoniana; partiamo innanzitutto dall'espressione dell'impulso (12.3.5). Decomponiamo il campo elettrico in parte trasversale e longitudinale (ricordando che $\mathbf{B}$ è solo trasversale in quanto rotore di $\mathbf{A}$):
\begin{equation}
\mathbf{P}=\sum_a m_a\mathbf{v}_a+\frac{1}{4\pi c}\int\diff^3{r}(\mathbf{E}_T\wedge\mathbf{B})+\frac{1}{4\pi c}\int\diff^3{r}(\mathbf{E}_L\wedge\mathbf{B})\;.
\end{equation}
Il termine contenente la parte trasversale può essere riscritto come:
\begin{equation}
\frac{1}{4\pi c}\int\diff^3{r}(\mathbf{E}_T\wedge\mathbf{B})=-\frac{1}{4\pi c}\int\diff^3{r}\;\nabla\phi\wedge(\nabla\wedge\mathbf{A})\;,
\end{equation}
la cui componente $i$-esima è:
\begin{equation}
-\frac{1}{4\pi c}\int\diff^3{r}(\partial_j\phi\partial_iA_j-\partial_jA_i)\;.
\end{equation}
Il primo addendo dell'integrando, integrato per parti, conterrà un termine in $\partial_j\partial_iA_j=\partial_i\partial_jA_j=\partial_i\bnabla\cdot~\mathbf{A}=0$, in quanto siamo in gauge di Coulomb. Il secondo addendo restituisce, integrando per parti, il Laplaciano di $\phi$, quindi, sfruttando l'equazione di Poisson si ottiene:
\begin{equation}
\frac{1}{4\pi c}\int\diff^3{r}(\mathbf{E}_L\wedge\mathbf{B})=\frac{1}{4\pi c}\int \nabla^2\phi\mathbf{A}\diff^3{r}=\frac{1}{c}\int\rho(\mathbf{r})\mathbf{A}\diff^3{r}=\sum_a \frac{q_a}{c}\mathbf{A}(\mathbf{r}_a)\;.
\end{equation}
Quindi:
\begin{align}
\mathbf{P} &= \sum_a\left[m_a\mathbf{v}_a+\frac{q_a}{c}\mathbf{A}(\mathbf{r}_a)\right]+\frac{1}{4\pi c}\int\diff^3{r}(\mathbf{E}_L\wedge\mathbf{B}) \notag \\
&= \sum_a \mathbf{p}_a+\frac{1}{4\pi c}\int\diff^3{r}+\frac{1}{4\pi c}\int\diff^3{r}(\mathbf{E}_L\wedge\mathbf{B})\;.
\end{align}
Adesso consideriamo l'energia espressa in (12.3.4) (che non è detto ancora che coincida con l'Hamiltoniana). La parte EM è:
\begin{equation*}
H=\frac{1}{8\pi}\int\diff^3{r}\mathbf{E}_L^2+\frac{1}{8\pi}\int\diff^3{r}(\mathbf{E}_T^2+\mathbf{B}^2)\;.
\end{equation*}
Il primo termine si può riscrivere come:
\begin{equation}
\frac{1}{8\pi}\int\diff^3{r}(\nabla\phi)^2=\frac{1}{8\pi}\int\diff^3{r} 4\pi\phi\rho(\mathbf{r})=\frac{1}{2}\int\diff^3{r}\diff^3{r'}\frac{\rho(\mathbf{r})\rho(\mathbf{r}')}{|\mathbf{r}-\mathbf{r}'|}\;.
\end{equation}
Quindi l'energia si scrive come:
\begin{equation}
H=\sum_a \frac{1}{2m_a}\left(\mathbf{p}_a-\frac{q_a}{c}\mathbf{A}(\mathbf{r}_a)\right)^2+\underbrace{\frac{1}{2}\iint \frac{\rho(\mathbf{r})\rho(\mathbf{r}')}{|\mathbf{r}-\mathbf{r}'|}\diff^3{r}\diff^3{r'}}_{\mbox{interazione Coulombiana}}+\frac{1}{8\pi}\int (\mathbf{E}_L^2+\mathbf{B}^2)\diff^3{r}\;.
\end{equation}
Questa verifica le regole di commutazione proprie dell'Hamiltoniana, quindi rappresenta effettivamente l'Hamiltoniana di interazione luce-materia.
\section{Quantizzazione canonica}
In gauge di Coulomb i campi EM in funzione del potenziale vettore sono dati da:
\begin{align*}
\mathbf{E}&=-\frac{1}{c}\dot{\mathbf{A}}\;, \\
\mathbf{B}&=\nabla\wedge\mathbf{A}\;.
\end{align*}
In trasformata di Fourier:
\begin{align}
\mathbf{E}(\mathbf{x},t) &=\int \frac{\diff^3{k}}{(2\pi)^3}\mathbf{E}_k(t)e^{i\mathbf{k}\cdot\mathbf{x}}\;, \\
\mathbf{A}(\mathbf{x},t) &=\int \frac{\diff^3{k}}{(2\pi)^3}\mathbf{A}_k(t)e^{i\mathbf{k}\cdot\mathbf{x}}\;,
\end{align}
con $\mathbf{k}\cdot\mathbf{A}_k=0$. Per le trasformate valgono le relazioni:
\begin{equation}
\mathbf{E}_k=-\frac{1}{c}\dot{\mathbf{A}_k},\qquad \mathbf{B}_k=i\mathbf{k}\wedge\mathbf{A}_k\;.
\end{equation}
Per quanto riguarda l'energia ($A_k=a_k+ib_k$):
\begin{align}
\mathcal{E} &= \frac{1}{8\pi}\int(|\mathbf{E}_k|^2+|\mathbf{B}_k|^2)\frac{\diff^3{k}}{(2\pi)^3}=\frac{1}{8\pi}\int\left(\frac{1}{c^2}|\dot{\mathbf{A}_k}|^2+k^2|\mathbf{A}_k|^2\right)\frac{\diff^3{k}}{(2\pi)^3} \\
&=\frac{1}{8\pi}\int\left(\frac{1}{c^2}\dot{a}_k^2+\frac{1}{c^2}\dot{b}_k^2+k^2(a_k^2+b_k^2)\right)\frac{\diff^3{k}}{(2\pi)^3}\;,
\end{align}
che descrive un insieme di oscillatori con frequenza $\omega=kc$. \\
Prendiamo adesso ad esempio un sistema unidimensionale (corda vibrante). L'equazione della corda vibrante è quella di d'Alembert:
\begin{equation}
\pdev[2]{\varphi(x,t)}{t}-c^2\pdev[2]{\varphi(x,t)}{x}=0,\qquad c=\sqrt{\frac{T}{\mu}}\;,
\end{equation}
dove $T$ è la tensione della corda e $\mu$ è la densità lineare di massa. La Lagrangiana che genera questa equazione è:
\begin{equation}
\lag=\int\left[\frac{1}{2}\mu(\partial_t\varphi)^2-\frac{T}{2}(\partial_x\varphi)^2\right]\diff{x}\;.
\end{equation}
Le coordinate lagrangiane sono in questo caso le $\varphi(x,t)$, i cui impulsi canonicamente coniugati sono dati da:
\begin{equation}
\Pi(x,t)\equiv \frac{\delta\lag}{\delta\dot{\varphi}(x,t)}=\mu\dot{\varphi}(x,t)\;.
\end{equation}
Noti gli impulsi, siamo in grado di scrivere l'Hamiltoniana:
\begin{equation}
H=\int\diff{x}\Pi(x,t)\varphi(x,t)-\lag=\int\diff{x}\left[\frac{1}{2\mu}\Pi^2+\frac{T}{2}(\partial_x\varphi)^2\right]\;.
\end{equation}
Le relazioni di commutazione canoniche sono $[Q_i,P_j]=i\hbar\delta_{ij}$, che in questo caso si esprimono come:
\begin{equation}
[\varphi(x,t),\Pi(x,t)]=i\hbar\delta(x-y)\;.
\end{equation}
Dato che $\varphi$ soddisfa l'equazione delle onde, possiamo scriverla come sovrapposizione di onde piane:
\begin{equation}
\varphi(x,t)=\int\frac{\diff{k}}{2\pi}N_{\omega}\left[a(k)e^{ikx-i\omega t}+\adj{a}(k)e^{-ikx+i\omega t}\right]\;,
\end{equation}
da cui:
\begin{equation}
\Pi(x,t)=\mu\dot{\varphi}=-i\mu\int\frac{\diff{k}}{2\pi}\omega N_{\omega}\left[a(k)e^{ikx-i\omega t}-\adj{a}(k)e^{-ikx+i\omega t}\right]\;.
\end{equation}
Il commutatore deve valere indipendentemente dal tempo, quindi possiamo porre $t=0$. Si verifica che, se scegliamo $N_{\omega}=\sqrt{\dfrac{\hbar}{2\mu\omega_k}}$ e assumiamo la regola di commutazione $[a(k),\adj{a}(k')]=2\pi\delta(k-k')$, allora $\varphi$ e $\Pi$ soddisfano la regola di commutazione canonica. Inoltre, l'Hamiltoniana potrà essere scritta nella forma $\hbar\omega\adj{a}a$.
\section{Invarianza di gauge}
In Meccanica Classica le equazione del moto in presenza di campo EM sono invarianti per trasformazioni di gauge:
\begin{equation}
\begin{cases}
\mathbf{A}\longmapsto \mathbf{A}+\nabla\Lambda\;, \\
\\
\phi\longmapsto \phi-\dfrac{1}{c}\dfrac{\partial\Lambda}{\partial t}\;.
\end{cases}
\end{equation}
Come si manifesta l'invarianza di gauge in Meccanica Quantistica? Prendiamo due Hamiltoniane di particella libera che differiscono per una trasformazione di gauge:
\begin{align}
H_1 &= \frac{1}{2m}\left(\mathbf{p}-\frac{e}{c}\mathbf{A}_1\right)^2+e\phi_1 \notag \;,\\
H_2 &= \frac{1}{2m}\left(\mathbf{p}-\frac{e}{c}\mathbf{A}_2\right)^2+e\phi_2 \notag\;, \\
&\begin{cases}
\mathbf{A}_1=\mathbf{A}_2+\nabla\Lambda\;, \\
\\
\phi_1=\phi_2-\dfrac{1}{c}\dfrac{\partial\Lambda}{\partial t}\;.
\end{cases}
\end{align}
Sappiamo che se due Hamiltoniane sono legate da una trasformazione unitaria, allora le equazioni del moto che esse generano sono le medesime. Se $S$ è un operatore unitario e $\psi'=S\psi$, allora $H'=SHS^{-1}+i\hbar\dfrac{\partial S}{\partial t}S^{-1}$. Se scegliamo:
\begin{equation}
S=\exp\left(i\frac{e\Lambda}{\hbar c}\right)\;,
\end{equation}
otteniamo:
\begin{align*}
i\hbar\pdev{S}{t}&= i\hbar\left(\frac{ie}{\hbar c}\pdev{\Lambda}{t}\right)=-\frac{e}{c}\pdev{\Lambda}{t}\;, \\
\frac{1}{2m}S\left(\mathbf{p}-\frac{e}{c}\mathbf{A}\right)S^{-1}&=\frac{1}{2m}e^{ie\Lambda/\hbar c}\left(\frac{\hbar}{i}\nabla-\frac{e}{c}\mathbf{A}\right)e^{-ie\Lambda/\hbar c} \\
&=\left(\frac{\hbar}{i}\nabla-\frac{e}{c}\mathbf{A}+\frac{\hbar}{i}\left(-\frac{ie}{\hbar c}\right)\bnabla\Lambda\right) \\
&=\left(\frac{\hbar}{i}\nabla-\frac{e}{c}\mathbf{A}-\frac{e}{c}\bnabla\Lambda\right)\;.
\end{align*}
Quindi:
\begin{equation}
H_2'=\frac{1}{2m}\left(\mathbf{p}-\frac{e}{c}\mathbf{A}_2-\frac{e}{c}\bnabla\Lambda\right)^2+e\phi_2-\frac{e}{c}\pdev{\Lambda}{t}=\frac{1}{2m}\left(\mathbf{p}-\frac{e}{c}\mathbf{A}_1\right)^2+e\phi_1\equiv H_1\;.
\end{equation}
Quindi una trasformazione di gauge sui potenziali equivale ad una trasformazione di fase sulle funzioni d'onda. In termini covarianti, le trasformazioni di gauge si scrivono come:
\begin{equation}
A_{\mu}^{(1)}=A_{\mu}^{(2)}-\partial_{\mu}\Lambda\;.
\end{equation}
Osserviamo che se eseguiamo una trasformazione di gauge sui potenziali e la trasformazione di fase inversa sugli stati, l'Hamiltoniana del sistema rimane invariata. Cosa implica questa invarianza? \\
Definiamo la \textbf{derivata covariante}:
\begin{equation}
\mathbf{D}=\frac{\hbar}{i}\left(\nabla-\frac{ie}{\hbar c}\mathbf{A}\right)\;.
\end{equation}
Posto $g\equiv e/\hbar c$, una trasformazione di gauge si scriverà come $\psi\to e^{ig\Lambda}\psi$ e:
\begin{equation}
\mathbf{D}\psi\longrightarrow (\mathbf{D}\psi)'=(\nabla-ig\mathbf{A}+g\nabla\Lambda)e^{ig\Lambda}\psi\equiv e^{ig\Lambda}\mathbf{D}\psi\;.
\end{equation}
Cosa comporta geometricamente questo cambiamento di fase? Consideriamo trasformazioni di gauge indipendenti dal tempo: $\Lambda\equiv\Lambda(\mathbf{x})$, allora la trasformazione:
\begin{equation}
\psi(x)\longrightarrow e^{ig\Lambda(x)}\psi(x)\;,
\end{equation}
corrisponde ad un cambiamento di fase punto per punto. Cerchiamo una funzione $U(y,x)$ tale che $\psi(y)\sim U(y,x)\psi(x)$, cioè tale che:
\begin{align*}
\psi(x) &\longrightarrow e^{i\alpha(x)}\psi(x)\;, \\
\psi(y)=U(y,x)\psi(x) &\longrightarrow e^{i\alpha(y)}\psi(y)\;.
\end{align*}
Il problema sta nel fatto che $U$ sarà in generale funzione del particolare cammino con cui da $x$ si va a $y$. Prendiamo adesso due punti vicini, $x^{\mu}$ e $x^{\mu}+\varepsilon^{\mu}$. Dato che $U$ deve essere unitario, per $\varepsilon^{\mu}$ piccolo si ha:
\begin{equation}
U(x^{\mu}+\varepsilon^{\mu},x^{\mu})=1+igA_{\mu}\varepsilon^{\mu}\;.
\end{equation}
Per definizione di sviluppo in serie dovrà essere:
\begin{equation}
\frac{\partial U}{\partial \varepsilon^{\mu}}=igA_{\mu}\;.
\end{equation}
Una proprietà di $U$ deve essere l'additività: se $x,y,z$ sono tre punti appartenenti allo stesso cammino $C$, allora:
$$
U_C(y,x)=U(y,z)U(z,x)\;.
$$
Questa condizione si realizza scrivendo:
\begin{equation}
U_C(x,x_0)=\exp\left[ig\int_{x_0}^x A_{\mu}(\xi^{\mu})\diff{\xi^{\mu}}\right]\;,
\end{equation}
e con una trasformazione di gauge:
\begin{equation}
U\longmapsto \exp\left[ig\int_x^y(A_{\mu}+\partial_{\mu}\Lambda)\diff{\xi^{\mu}}\right]=e^{ig\Lambda(y)}U(y,x)e^{-ig\Lambda(x)}\;.
\end{equation}
Quindi la derivata si scrive:
\begin{equation*}
\psi(x+\diff{x})-U(x+\diff{x},x)\psi(x)\simeq \psi(x)+\partial_{\mu}\psi\diff{x^{\mu}}-(1+igA_{\mu}\diff{x^{\mu}})\psi(x)=(\partial_{\mu}-igA_{\mu})\psi\diff{x^{\mu}}\;,
\end{equation*}
che è proprio la derivata covariante. La derivata covariante è un esempio di \textit{accoppiamento minimale} (invariante di gauge). La condizione per cui $U$ non dipenda dal particolare cammino è:
\begin{align}
&\oint A_{\mu}\diff{\xi^{\mu}}=0 \qquad &\qquad \int F_{\mu\nu}\diff{\sigma^{\mu\nu}}=0\qquad \mbox{(4 dimensioni)} \;,\notag \\
&\oint \mathbf{A}\cdot\diff{\boldsymbol{\xi}}=0 \qquad &\qquad \int (\nabla\wedge\mathbf{A})\diff{\sigma}=0 \quad \mbox{(3 dimensioni)}\;.
\end{align}
In generale non vale il viceversa, ossia se $F_{\mu\nu}=0$ non è detto che la circuitazione sia nulla. Vale solo se lo spazio è semplicemente connesso.
\section{Simmetrie interne}
Le simmetrie interne sono le simmetrie di un sistema diverse da quelle dei gruppi di Lorentz e Galileo. Una ad esempio è lo spin isotopico in $\mathrm{SU}(2)$. Il gruppo di isospin avrà tre generatori $T_1,T_2,T_3$ tali che $[H_S,\mathbf{T}]=0$, questo implica che è possibile classificare gli stati tramite gli autovalori di $\mathbf{T}^2$ e $T_3$. \\
La carica di una particella è data da $Q=T_3+\dfrac{1}{2}(B+S)$ dove $B$ è il numero barionico e $S$ è la stranezza della particella.
\chapter{Atomi}
(Mi sono perso due lezioni)
\section{Configurazioni elettroniche}
La degenerazione $d$ di un livello atomico è data da:
\begin{equation}
d=\underbrace{2}_{\mbox{spin}}\cdot \underbrace{(2\ell +1)}_{\mbox{momento angolare}}\;.
\end{equation}
Il numero di configurazioni possibili è $\dbinom{d}{k}$, dove $k$ è il numero di elettroni. Se un guscio è completo, allora la configurazione è unica, mentre se abbiamo più gusci incompleti si moltiplicano i singoli numeri di configurazioni. Questa degenerazione sarà rotta dalle perturbazioni. Quella di cui va sempre tenuto conto è l'interazione coulombiana tra gli elettroni. In ogni caso, l'Hamiltoniana esatta sarà invariante sotto rotazioni, in quanto:
\begin{equation}
H=\;\mbox{parte cinetica}\;-\sum_i \frac{Z}{r_i}+\sum_{i<j}\frac{1}{|\mathbf{r}_i-\mathbf{r}_j|}\;.
\end{equation}
Di conseguenza, gli autostati di $H$ saranno autostati anche di $L^2$ e $L_z$ (momento angolare totale) e di $S^2$ e $S_z$.
\subsection*{Elettroni equivalenti}
Due o più elettroni si dicono equivalenti se occupano lo stesso orbitale. Prendiamo ad esempio due elettroni nello stato $2p$. Per scrivere le possibili configurazioni elettroniche seguiamo questo procedimento:
\begin{enumerate}
\item scriviamo gli stati possibili per un solo elettrone, nella forma $L_z,S_z$, che saranno nel nostro caso:
\begin{align*}
&a)\; 1,+\qquad b)\; 0,+\qquad c)\; -1,+ \\
&a')\; 1,-\qquad b')\; 0,-\qquad c')\; -1,-\;;
\end{align*}
\item organizziamo le coppie in una tabella a seconda del valore di $L_z$ (in questo passaggio possiamo trascurare le coppie che danno valori di $L_z$ o $S_z$ negativi, in quanto sono contate automaticamente):

\begin{table}[h]
\centering
\begin{tabular}{c|c|c}
\toprule
\multicolumn{1}{c|}{$L_z=2,S_z$} &
\multicolumn{1}{c|}{$L_z=1,S_z$} &
\multicolumn{1}{c}{$L_z=0,S_z$} \\
\midrule
$a+a',\;0$ & $a+b,\; 1$ & $a+c,\; 1$ \\
{} & $a'+b,\; 0$ & $a'+c,\;0$ \\
{} & $a+b', \;0$ & $b'+b, \;0$ \\
{} & {} & $a+c',\; 0$ \\
\bottomrule

\end{tabular}

\end{table}
\item infine si scrivono gli stati. Partiamo dall'unico avente $L_z=2, S_z=0$: questo apparterrà sicuramente al ${}^1D$. Gli altri stati appartenenti a ${}^1D$ si trovano applicando $L_-$, e quindi ve ne sarà uno avente $L_z=1,S_z=0$ e un altro avente $L_z=0,S_z=0$. Eliminate quindi le coppie corrispondenti (non importa quali in caso di ambiguità in quanto stiamo solo contando), passiamo alla prima di quelle rimaste, cioè $a+b$, che ha $L_z=1,S_z=1$ e quindi sarà un ${}^3P$. In questo, vi saranno anche gli stati $L_z=1,S_z=0,-1$. Eliminate anche queste, rimane la coppia $a+c'$ che ha $L_z=0,S_z=0$, e quindi sarà un ${}^1S$. In sintesi, gli stati possibili sono ${}^1D,{}^3P,{}^1S$. Tramite la regola di Hund (che vale solo per elettroni equivalenti) troviamo che lo stato fondamentale è ${}^1S$.
\end{enumerate}
\subsection{Tre elettroni equivalenti}
Prendiamo adesso il caso $2p^3$, ossia tre elettroni equivalenti nello stato $2p$. Gli stati possibili sono gli stessi di prima, quindi possiamo direttamente scrivere la tabella:

\begin{table}[h]
\centering
\begin{tabular}{c|c|c}
\toprule
\multicolumn{1}{c|}{$L_z=2, S_z$} &
\multicolumn{1}{c|}{$L_z=1, S_z$} &
\multicolumn{1}{c}{$L_z=0, S_z$} \\
\midrule
$a+a'+b,\; 1/2$ & $a+a'+c,\; 1/2$ & $a+b+c,\; 3/2$ \\
{} & $a+b+b',\; 1/2$ & $a+b+c',\; 1/2$ \\
{} & {} & $a+b'+c,\; 1/2$ \\
{} & {} & $a'+b+c,\; 1/2$ \\
\bottomrule
\end{tabular}
\end{table}
$a+a'+b$, avente $L_z=2, S_z=1/2$ appartiene a ${}^2D$, insieme a $a+a'+c,a+b+c'$. Poi avremo ${}^2P$ e infine ${}^4S$. Lo spin più alto ce l'ha il ${}^4S$, che per Hund sarà dunque il fondamentale. \\
Per quattro o cinque elettroni è molto semplice, in quanto si dimostra che la configurazione è equivalente al complementare a 6 (quindi $2p^4$ è uguale a $2p^2$). Per dimostrare questo fatto, consideriamo l'operatore di creazione $\adj{b_{m,\sigma}}$, che sotto rotazione trasforma come:
\begin{equation}
\adj{b_{\alpha}} \longrightarrow \sum_{\alpha'} R_{\alpha'\alpha}\adj{b_{\alpha'}}\;.
\end{equation}
Consideriamo cinque elettroni: $\adj{b_2}\adj{b_3}\adj{b_4}\adj{b_5}\adj{b_6}|\Omega\ket$ e applichiamo $b_1\adj{b_1}$. Si ha:
\begin{enumerate}
\item $b_1\adj{b_1}$ è invariante sotto rotazioni;
\item $b_1\adj{b_1}\cdots\adj{b_6}|\Omega\ket$ trasforma come $b_1$ in quanto $\adj{b_1}\cdots\adj{b_6}|\Omega\ket$ è il guscio completo, e dunque è invariante sotto rotazioni. Pertanto quello che determina la configurazione è $b_1$ (che crea una lacuna, ossia un elettrone di carica positiva sovrapposto ad un elettrone normale).
\end{enumerate}
Calcoliamo adesso il valor medio dell'Hamiltoniana:
\begin{equation}
H=\sum \lag(i)+\sum_{i<j}\frac{1}{|\mathbf{r}_i-\mathbf{r}_j|}\;,
\end{equation}
su un singolo determinante di Slater:
\begin{align}
\bra\psi|H|\psi\ket &= \sum_{i=1}^Z\bra i|\lag|i\ket+\frac{1}{2}\sum_{i,j}(\bra ij|V|ij\ket-\bra ij|V|ji\ket) \notag \\
&= \sum \int\varphi_i(q)\left(-\frac{1}{2}\nabla^2-\frac{Z}{r_i}\right)\varphi_i(q)\diff{q}+\frac{1}{2}\sum_{i,j}\left[\int\diff{q}\diff{q'}\varphi_i(q)\varphi_j(q')V(q,q')\varphi_i(q)\varphi_j(q')-\right. \notag \\
&-\left.\int \diff{q}\diff{q'}\varphi_i(q)\varphi_j(q')V(q,q')\varphi_j(q)\varphi_i(q')\right]\;.
\end{align}
Per stimare l'energia del fondamentale, applichiamo il principio variazionale con il vincolo che gli stati siano normalizzati, ossia $\left(\int\varphi^2\diff{q}\right)-1=0$. Eseguendo la derivata variazionale otteniamo:
\begin{equation}
\left(-\frac{1}{2}\nabla^2-\frac{Z}{r_a}\right)\varphi_a(q)+\int\diff{q'}\sum_j \varphi_j^2(q)V(q,q')\varphi_a(q)-\sum_j\int\diff{q'}\varphi_a(q')\varphi_j(q')V(q,q')\varphi_j(q)-2\epsilon_a\varphi_a(q)=0\;.
\end{equation}
\section{Equazione di Hartree-Fock}
\textbf{Schema generale}
\begin{itemize}
\item Singola configurazione (\emph{Hartree-Fock Single Configuration});
\item autostati di $H$ hanno $L^2$ e $S^2$ definito (termini spettrali);
\end{itemize}
Vediamo la scrittura dell'equazione di H-F nei seguenti casi:
\begin{enumerate}
\item singolo determinante di Slater (gas nobili e alcalini);
\item un solo guscio incompleto.
\end{enumerate}
L'energia su un singolo determinante è:
\begin{equation}
H=\underbrace{\sum_i \hat{\lag}(i)}_{\mbox{singola particella}}+\frac{1}{2}\sum_{i,j}\underbrace{\left[\int_{q,q'}\psi_i^*(q)\psi_j^*(q')V\psi_i(q)\psi_j(q')\right.}_{\mbox{termine diretto}}-\underbrace{\left.\int_{q,q'}\psi_i^*(q)\psi_j^*(q')V\psi_j(q)\right]}_{\mbox{termine di scambio}}\psi_i(q')\;.
\end{equation}
Gli orbitali saranno invece della forma:
\begin{equation}
\psi_i(q)=rP_a(r)Y_{lm}\chi_s(\sigma)\;,
\end{equation}
dove $P_a(r)$ è la funzione d'onda radiale ridotta, $Y_{lm}$ è l'armonica sferica corrispondente all'orbitale e $\chi_s(\sigma)$ è uno spinore. La degenerazione sarà, nel caso di guscio completo, $q_a=2(2\ell_a+1)$. \\
Occupiamoci del contributo di singola particella:
\begin{equation}
\sum_a q_a\int_r P_a(r)\left(-\frac{1}{2}\frac{\diff^2}{\diff^2{r}}+\frac{1}{2}\frac{\ell_a(\ell_a+1)}{r^2}-\frac{Z}{r}\right)P_a(r)\;,
\end{equation}
dove la somma è fatta sugli orbitali. Definiamo un'energia media:
\begin{equation}
\bra\psi|V|\psi\ket=\sum_a \binom{q_a}{2}\overline{U}_{aa}+\sum_{a<b}q_aq_b\overline{U}_{ab}\;.
\end{equation}
Per i gusci completi si ha:
\begin{equation}
\binom{q_a}{2}=\frac{q_a(q_a-1)}{2}=\frac{1}{2}2(2\ell_a+1)(4\ell_a+2-1)=(4\ell_a+1)(2\ell_a+1)\;.
\end{equation}
Nel caso di elettroni equivalenti, il termine diretto è invece:
\begin{equation}
\sum_{m,m'}\int_{\Omega_1,\Omega_2,r}P_a^2(r)P_a^2(r')Y_{lm}^*(\Omega_1)Y_{lm'}^*(\Omega_2)\frac{1}{|\mathbf{r}-\mathbf{r}'|}Y_{lm}(\Omega_1)Y_{lm'}(\Omega_2)\sum_{ss'}\chi_s^*(\sigma)\chi_{s'}^*(\sigma')\chi_s(\sigma)\chi_{s'}(\sigma')\;.
\end{equation}
La parte di spin dà:
\begin{equation}
\sum_{s,s'}\chi_s^*(\sigma)\chi_{s'}^*(\sigma')\chi_s(\sigma)\chi_{s'}(\sigma')=\sum_{s,s'}1\cdot 1=4\;.
\end{equation}
Lo sviluppo dell'interazione coulombiana è il solito:
\begin{equation}
\frac{1}{|\mathbf{r}-\mathbf{r}'|}=\frac{1}{r_>}\sum_k\left(\frac{r_<}{r_>}\right)^k\frac{4\pi}{2k+1}\sum_{M=-k}^kY_{kM}(\Omega_1)Y_{kM}^*(\Omega_2)\;,
\end{equation}
e i due integrali angolari diventano del tipo:
\begin{align}
&\sum_M\int\diff{\Omega_1} Y_{lm}^*(\Omega_1)Y_{lm}(\Omega_1)Y_{kM}(\Omega_1) \notag\;, \\
&\sum_M\int\diff{\Omega_2} Y_{lm'}^*(\Omega_2)Y_{lm'}(\Omega_2)Y^*_{kM}(\Omega_2)\;.
\end{align}
Per le regola di selezione $m+M=m$, quindi $M=0$ e $0\le k\le 2\ell$. Se $M=0$:
\begin{equation}
\sum_m Y_{lm}^*(\Omega_1)Y_{lm}(\Omega_2)=\frac{2\ell+1}{4\pi}\;,
\end{equation}
dato che non dipende da $\theta,\varphi$, l'integrale angolare in $\Omega_1$ fa zero, a meno che non sia $k=0$ (simmetria sferica). La parte radiale sarà del tipo (nel nostro caso sarà $a=b$ e $k=0$):
\begin{equation}
F^k[a,b]=\int_{r_1,r_2} P_a^2(r_1)P_b^2(r_2)\frac{1}{r_>}\left(\frac{r_<}{r_>}\right)^k\;.
\end{equation}
Definiamo adesso:
\begin{equation}
c^k(l_i,m_i;l_r,m_r)=\sqrt{\frac{4\pi}{2\ell+1}}\int\diff{\Omega}\,Y_{l_im_i}^*Y_{l_r,m_r}Y_{km}\;.
\end{equation}
In generale:
\begin{align}
&|l_r-l_i|\le k\le l_r+l_i \notag\;, \\
&m_r+m=m_i\;.
\end{align}
Sfruttando le somme dei $c^0$ si ha per la parte diretta:
\begin{equation}
2(2\ell+1)^2F^0[n\ell,n\ell]\;.
\end{equation}
Passiamo adesso al termine di scambio. La parte di spin adesso diventa:
\begin{equation}
\sum_{s,s'}\chi^*_s(\sigma)\chi^*_{s'}(\sigma')\chi_s(\sigma')\chi_{s'}(\sigma)=\sum_{s,s'}\delta_{ss'}\delta_{ss'}=2\;,
\end{equation}
in quanto adesso solo gli spinori paralleli contribuiscono. \\
La parte angolare si tratta allo stesso modo di prima, e si ottiene:
\begin{equation}
-(2\ell+1)F^0(n\ell,n\ell)-(2\ell+1)\sum_{k>1}c^k(\ell,0,\ell,0;k,0)F^k[a;a]\;.
\end{equation}
I termini in $F^0$ si sommano per dare:
\begin{equation}
2(2\ell+1)^2-(2\ell+1)=(2\ell+1)(4\ell+1)=\binom{q_a}{2}\;.
\end{equation}
In definitiva si ha per l'energia media:
\begin{equation}
\overline{U}_{aa}=F^0[a,a]-\frac{1}{4\ell_a+1}\sum_{k>1}c^k(\ell_a,0,\ell_a,0;k,0)F^k[a,a]\;.
\end{equation}
Per gli elettroni non equivalenti, posto:
\begin{equation}
G^k[a,b]=\int_{r_1,r_2}P_a(r_1)P_a(r_2)\frac{1}{r_>}\left(\frac{r_<}{r_>}\right)^kP_a(r_2)P_b(r_2)\;,
\end{equation}
si ha:
\begin{equation}
\overline{U}_{ab}=F^0(n_a,\ell_a,n_b,\ell_b)-\frac{1}{2}\frac{1}{\sqrt{(2\ell_a+1)(2\ell_b+1)}}\sum_k c^k(\ell_a,0,\ell_b,0;k,0)G^k[a,b]\;.
\end{equation}
L'energia media dà automaticamente l'espressione per gas nobili e metalli alcalini (anche per ioni con la stessa configurazione elettronica). \\
\\
Nel caso di orbitali non completi, supponiamo di avere sempre la stessa configurazione elettronica. Avremo allora $\dbinom{d}{k}$ determinanti di Slater organizzati secondo gli autostati di $L^2,L_z,S^2,S_z$. Possiamo seguire due strade:
\begin{itemize}
\item diagonalizzare $L,S$ e calcolare l'energia fra i due orbitali risultanti;
\item calcolare la matrice $V$ sui vari determinanti e diagonalizzarla.
\end{itemize}
Per la configurazione $p^2$ (eg. Carbonio):
\begin{equation}
E_{\mathrm{mean}}+\left(\begin{matrix}
{}^3P & {}^1S & {}^1D \\
-\frac{3}{25}F^2[p,p] & 0 & 0 \\
0 & \frac{12}{25}F^2[p,p] & 0 \\
0 & 0 & \frac{3}{25}F^2[p,p]
\end{matrix}\right)\;.
\end{equation}
Quindi il fondamentale è ${}^3P$, come avevamo già visto. \textbf{Nota}: $\sum \mbox{molteplicità}\times\delta E=0$ (traccia). \\
Applicando il metodo variazionale ricaviamo la forma generale dell'equazione di Hartree-Fock:
\begin{align}
&\lag_aP_a+(q_a-1)\sum_{k=0} f_k(a)\frac{1}{r}Y^k(a,a;r)P_a+\sum_{b\ne a}q_b\left[\frac{1}{r}Y^0(b,b;r)P_a+\sum_{k=0}g_k(a,b)\frac{1}{r}Y^k(a,b;r)P_b(r)\right] \notag \\
&=\epsilon_aP_a+\sum_bq_b\epsilon_{ab}P_b\;.
\end{align}
\begin{itemize}
\item Il potenziale $Y^0(a,b;r)$ ha la forma di un potenziale generato da una distribuzione di carica sferica;
\item i potenziali $Y^k$ corrispondono a deformazioni degli shell;
\item normalmente gli $\epsilon_{ab}$ sono nulli. Possono tener conto della non-ortogonalità nel calcolo iterativo.
\end{itemize}
Adesso l'equazione di Hartree-Fock può essere risolta tramite la seguente procedura iterativa:
\begin{enumerate}
\item si scelgono dei valori iniziali per le funzioni d'onda orbitali e per $\epsilon_a$;
\item si calcola il termine di scambio nell'equazione;
\item si risolve il sistema di equazioni differenziali disomogenee (ITER);
\item moltiplicando la parte sinistra di ogni equazione per i nuovi $P_a$, ricalcolando il termine di scambio ed integrando si ottengono dei nuovi valori di $\epsilon_a$;
\item si ricomincia dal punto (ITER).
\end{enumerate}
\section{Elio (stato fondamentale)}
Orbitale $1s^2$, singoletto. La funzione d'onda orbitale è:
\begin{equation}
\psi(x,y)=f_{1s}(x)f_{1s}(y)\;.
\end{equation}
Nello sviluppo dell'interazione coulombiana:
\begin{equation}
\frac{1}{|x-y|}=\frac{1}{r_>}\sum_k\left(\frac{r_<}{r_>}\right)^k\frac{4\pi}{2k+1}\sum_{m=-k}^{k}Y_{km}(\Omega_1)Y^*_{km}(\Omega_2)
\end{equation}
sopravvive solo l'onda $S$ ($k=0$):
\begin{equation}
E[f]=2\int\diff{r}f(r)\left(-\frac{1}{2}f''-\frac{Z}{r}f\right)+\int_{x,y}f(x)f(y)\frac{1}{r_>}f(x)f(y)\diff{x}\diff{y}\;.
\end{equation}
Il vincolo è $C[f]=2\epsilon\left(\int f^2-1\right)$. Allora:
\begin{equation}
\frac{\delta(E-C)}{\delta f}=0\longrightarrow \int\diff{y}f^2(y)\frac{1}{\max(x,y)}-\frac{1}{2}f''(x)-\frac{Z}{x}f+\int\diff{y}f^2(y)\frac{1}{r_>}f(x)=\epsilon f(x)\;,
\end{equation}
da cui $E\simeq -2.86$ au.
\section{Correzioni dovute allo spin}
In assenza di campi esterni, l'Hamiltoniana di un atomo commuta con $\mathbf{J}$, quindi gli stati stazionari possono comunque essere classificati secondo gli autovalori di $\mathbf{J}^2,J_z$ e avranno degenerazione $2j+1$. Se consideriamo lo spin, l'Hamiltoniana sarà quella di accoppiamento $\ell-s$:
\begin{equation}
H_{\ell s}=-\frac{e\hbar^2}{2m^2c^2}\frac{1}{r}\dev{V}{r}\boldsymbol{\ell}\cdot\mathbf{s}=-\frac{Ze^2\hbar^2}{2m^2c^2}\frac{1}{r^3}\boldsymbol{\ell}\cdot\mathbf{s}\;.
\end{equation}
Per un atomo dovrò sommare su tutti gli elettroni:
\begin{equation}
H_{\ell s}=\sum_i -\frac{Ze^2\hbar^2}{2m^2c^2}\frac{1}{r_i^3}\boldsymbol{\ell}_i\cdot\mathbf{s}_i\;.
\end{equation}
Inoltre gli elettroni in movimento generano una corrente e quindi un campo magnetico a cui lo spin risponde (\emph{spin other orbitals}):
\begin{equation}
H_{soo}=\sum_{a<b}\frac{e^2\hbar^2}{2m^2c^2}\frac{1}{r_{ab}^3}\left[-(\mathbf{s}_a+2\mathbf{s}_b)\cdot(\mathbf{r}_{ab}\wedge\mathbf{p}_a)+(\mathbf{s}_b+2\mathbf{s}_a)\cdot(\mathbf{r}_{ab}\wedge\mathbf{p}_b)\right]\;.
\end{equation}
In più ci sarà l'interazione spin-spin:
\begin{equation}
H_{ss}=\sum_{a<b}\frac{e^2}{m^2c^2}\frac{1}{r_{ab}^3}\left[\mathbf{s}_a\cdot\mathbf{s}_b-\frac{3(\mathbf{s}_a\cdot\mathbf{r}_{ab})(\mathbf{s}_b\cdot\mathbf{r}_{ab})}{r^2_{ab}}\right]\;.
\end{equation}
$H_{soo}$ e $H_{ss}$ hanno elementi non nulli solo per le coppie di elettroni appartenenti a gusci non completi, che sono comunque in numero ristretto e non crescono con $Z$, come $H_{\ell s}$, che in particolare sarà il termine dominante. \\
Il campo coulombiano ha una lunghezza caratteristica $a_Z\sim 1/Z$, quindi l'ordine di grandezza di $H_{\ell s}$ è:
$$
Z\alpha^2\frac{1}{a_Z^3}|\psi_{a_Z}|^2 a_Z^3\;,
$$
con $\psi_{a_Z}\sim \sqrt{Z}$ (in prossimità del nucleo). Quindi $H_{\ell s}\sim Z^2\alpha^2$. Considerando che $H_{\ell s}$ comunque non contribuisce su shell chiusi, possiamo scrivere:
\begin{equation}
H_{\ell s}=\sum_i A(r_i)\boldsymbol{\ell}_i\cdot\mathbf{s}_i\;,
\end{equation}
con il termine $A(r_i)$ che può tener conto eventualmente dello schermaggio (ma non ci interessa in questo caso). Dato che $A(r_i)$ ha lo stesso valore sugli elettroni di uno stesso shell, possiamo considerarlo costante:
\begin{equation}
H_{\ell s}=A\sum_i\boldsymbol{\ell}_i\cdot\mathbf{s}_i\longrightarrow H_{\mathrm{eff}}=A\mathbf{L}\cdot\mathbf{S}\qquad \mbox{(Wigner-Eckart)}\;.
\end{equation}
Gli stati di partenza hanno degenerazione $(2\ell+1)(2s+1)$, $H_{\mathrm{eff}}$ è diagonale nella base $|J,J_z\ket$, con $|L-S|\le J\le L+S$ e, a fissi $L,S$:
$$
\mathbf{L}\cdot\mathbf{S}=\frac{j(j+1)-\ell(\ell+1)-s(s+1)}{2}\;.
$$
Allora:
\begin{equation}
E_j=C+\frac{A}{2}j(j+1)\;,
\end{equation}
dove $C$ è l'energia del centro di massa e $A$ tiene conto di tutte le costanti. Notiamo che $\Delta=E_j-E_{j-1}=jA$. Come determiniamo il segno della costante $A$? Supponiamo che gli elettroni siamo meno della metà di $d=2(2\ell+1)$. Nello stato fondamentale si ha $\mathbf{S}_a=\dfrac{\mathbf{S}}{n}$ per la regola di Hund, quindi:
\begin{equation}
H_{\mathrm{eff}}=A\sum_i\boldsymbol{\ell}_i\cdot\frac{\mathbf{S}}{n}=\frac{Ze^2}{2m^2c^2r^3}\frac{\mathbf{L}\cdot\mathbf{S}}{n}\;,
\end{equation}
dato che $\mathbf{L}\cdot\mathbf{S}$ è positivo, segue che anche $A>0$. In conclusione, per atomi aventi lo shell esterno occupato per meno della metà di $d$ la costante $A$ è positiva. Invece, se l'occupazione è più della metà di $d$, osserviamo che:
\begin{equation}
A\sum_a\boldsymbol{\ell}_i\cdot\mathbf{s}_i=A\left(\sum_{\mathrm{tutti}}-\sum_{\mathrm{tutti}-d}\right)=-A\sum_{\mathrm{tutti}-d}\;,
\end{equation}
in quanto sulla configurazione di guscio completo $\boldsymbol{\ell}\cdot\mathbf{s}$ è nullo. Concludiamo che in questo caso $A<0$.
\section{Campo magnetico}
In presenza di campo magnetico, sappiamo che l'Hamiltoniana di interazione è:
\begin{equation}
H_I=\sum_i \frac{e\hbar}{2mc}(\boldsymbol{\ell}_i+2\mathbf{s}_i)\cdot\mathbf{B}\;.
\end{equation}
Se $\mu_BB\ll\Delta_{FS}$ (separazione tra i livelli di struttura fine), allora è possibile considerare separatamente i livelli di struttura fine, considerando gli autostati di struttura fine come autostati imperturbati e $H_I$ come perturbazione. Posto $\mathbf{B}=B\hat{\mathbf{z}}$, si ha:
$$
H_I=\mu_B(L_z+2S_z)B\;.
$$
Notiamo che:
\begin{equation}
\mathbf{L}+2\mathbf{S}=\mathbf{J}+\mathbf{S}=\mathbf{J}\frac{1+c_s}{g_j}\;,
\end{equation}
dove:
\begin{equation}
g_j=1+\frac{j(j+1)-\ell(\ell+1)+s(s+1)}{2j(j+1)}\;,
\end{equation}
è il fattore di Landé. Un livello con $J$ fissato si splitta in $2J+1$ livelli in presenza di campo magnetico, separati da un gap $\Delta=g_j\mu_BB$. \\
Consideriamo il caso $L=1,S=1/2$. La degenerazione è $d=(2L+1)(2S+1)=6$. Per interazione $L-S$ il livello si splitta in due livelli di struttura fine, uno con $J=3/2$, l'altro con $J=1/2$. In presenza di campo magnetico, il livello a $J=3/2$ si separa in 4 livelli, mentre quello a $J=1/2$ in due.
\chapter{Teoria della scattering}
\section{Scattering elastico}
Consideriamo uno scattering elastico tra un flusso di particelle incidenti contro un bersaglio la cui massa verrà considerata infinita. Vogliamo sapere quante particelle vengono rivelate dopo lo scattering ad un angolo $\theta$ (angolo di scattering). Supporremo che il potenziale di interazione sia centrale e tratteremo solo il caso stazionario. Lo stato iniziale è un'onda piana $e^{ikz}$. Indicando con $\diff{N}/\diff{t}$ il flusso di particelle per unità di tempo, possiamo scrivere:
\begin{equation}
\dev{N}{t}=\jmath\diff{\sigma}\;,
\end{equation}
dove $j$ è la corrente di funzione d'onda ed ha le dimensioni di un flusso di particelle per unità di tempo e di superficie, quindi la costante di proporzionalità $\diff{\sigma}$ avrà le dimensioni di un'area e viene chiamata \emph{sezione d'urto differenziale}. Per un'onda piana si ha:
\begin{equation}
\boldsymbol{\jmath}=\frac{\hbar}{2mi}(\psi^*\nabla\psi-\psi\nabla\psi^*)=\frac{\hbar\mathbf{k}}{2m}=\mathbf{v}\;,
\end{equation}
dove $\mathbf{v}$ è la velocità del fascio incidente, quindi $\jmath=v$. Lo stato finale, a grande distanza dal bersaglio, sarà un'onda sferica uscente, quindi ci aspettiamo una funzione d'onda del tipo:
\begin{equation}
\psi=e^{ikz-i\omega t}+f(\theta)\frac{e^{ikr-i\omega t}}{r}\;.
\end{equation}
Gli stati stazionario si ottengono imponendo che la derivata parziale della fase rispetto a $k$ sia nulla. Per l'onda incidente si ha:
\begin{equation}
z-\pdev{\omega}{k}t=0\;,
\end{equation}
$\partial\omega/\partial k$ è la velocità di gruppo dell'onda. A $t\to -\infty$, si ha $z=-\infty$, mentre a $t\to+\infty$ si ha $z=+\infty$, che è coerente. L'equazione di \Sch\; da risolvere è:
\begin{equation}
-\frac{\hbar^2}{2m}\nabla^2\psi+V(r)\psi=E\psi\;.
\end{equation}
Scrivendo $E=\hbar^2k^2/(2m)$, possiamo riscrivere:
\begin{equation}
\nabla^2\psi+k^2\psi=\frac{2m}{\hbar^2}V(r)\psi\;.
\end{equation}
La condizione al contorno è la condizione di Sommerfeld (valida per un potenziale che si annulla all'infinito):
\begin{equation}
\lim_{r\to\infty} r\left(\pdev{\varphi}{r}-ik\varphi\right)=0\;,
\end{equation}
dove $\varphi=\psi-e^{ikz}$ ($\psi$ è la soluzione). \\
Il numero di particelle al secondo che passano attraverso un rivelatore è:
\begin{equation}
\jmath_r\cdot \diff{S}\;,
\end{equation}
dove $\jmath_r$ è il flusso di particelle per unità di tempo e superficie radiale (a grandi distanze) e $\diff{S}$ è la superficie sottesa dall'angolo solido corrispondente. Abbiamo quindi:
\begin{equation}
\jmath_r=\frac{\hbar}{2mi}\left(\psi^*\pdev{\psi}{r}-\psi\pdev{\psi^*}{r}\right)=\frac{\hbar}{2mi}2ik|f(\theta)|^2\frac{1}{r^2}=v\frac{|f(\theta)|^2}{r^2}\;.
\end{equation}
L'elemento d'area è legato all'elemento di angolo solido dalla relazione $\diff{S}=r^2\diff{\Omega}$. Allora:
\begin{equation}
\dev{N}{t}=\jmath_r\diff{S}=v\frac{|f(\theta)|^2}{r^2}r^2\diff{\Omega}=v|f(\theta)|^2\diff{\Omega}\;.
\end{equation}
Quindi la sezione d'urto elastica differenziale è:
\begin{equation}
\diff{\sigma}=\frac{1}{\jmath_{inc}}\dev{N}{t}=|f(\theta)|^2\diff{\Omega}\;.
\end{equation}
e quella totale:
\begin{equation}
\sigma=\int |f(\theta)|^2\diff{\Omega}\;.
\end{equation}




\end{document}